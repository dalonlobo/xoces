[{"keywordlist": [], "level": 1, "startpage": 0, "endpage": 0, "topicname": "Cover Page"}, {"keywordlist": [], "level": 1, "startpage": 1, "endpage": 2, "topicname": "Half Title Page"}, {"keywordlist": [], "level": 1, "startpage": 3, "endpage": 3, "topicname": "Title Page"}, {"keywordlist": [], "level": 1, "startpage": 4, "endpage": 4, "topicname": "Copyright Page"}, {"keywordlist": [], "level": 1, "startpage": 5, "endpage": 6, "topicname": "Dedication"}, {"keywordlist": [], "level": 1, "startpage": 7, "endpage": 26, "topicname": "Contents"}, {"keywordlist": [], "level": 1, "startpage": 27, "endpage": 30, "topicname": "Preface"}, {"keywordlist": ["generalize", "unsupervised learning", "SmartASS", "CTR", "object detection", "click-through rate", "e-commerce", "eigenfaces", "hidden", "document classi\ufb01cation", "scalar product", "Net\ufb02ix", "\ufb01sheririsDemo", "features", "misclassi\ufb01cation rate", "dimensionality reduction", "nominal", "curseDimensionality", "imputation", "response variable", "market basket analysis", "polynomial regression", "latent", "linregPolyVsDegree", "Mechanical Turk", "logit", "gaussPlotDemo", "object localization", "CV", "NaN", "principal components analysis", "ham", "non-parametric model", "sparse", "instance-based learning", "knnVoronoi", "autoclass", "face detection", "exploratory data analysis", "weight vector", "memory-based learning", "frequent itemset mining", "linearly separable", "knnClassifyDemo", "handwriting recognition", "machine learning", "linregWedgeDemo2", "email spam \ufb01ltering", "MNIST", "Gaussian", "function approximation", "shuffledDigitsDemo", "under\ufb01ts", "logistic regression", "feature extraction", "probability theory xxvii", "inductive bias", "predictive", "categorical", "Bernoulli", "collaborative \ufb01ltering", "generalization", "Euclidean distance", "MAP estimate", "curse of dimensionality", "KNN", "systems biology", "parametric model", "maximum a posteriori", "squashing function", "over\ufb01t", "digital cameras", "bias", "nearest neighbor", "validation set", "reward", "pcaDemo3d", "multiple output model", "generalization error", "image classi\ufb01cation", "Watson", "newsgroupsVisualize", "supervised learning", "association rules", "decision boundary", "residual error", "model based clustering", "leave-one out cross validation", "density estimation", "latent factors", "StreetView", "MATLAB, xxviii matrix completion", "JamBayes", "covariates", "PCA", "linear regression", "big data", "sigmoidPlot", "missing", "latent semantic analysis", "reinforcement learning", "bag of words", "co-occurrence matrix", "model selection", "pattern recognition", "kmeansHeightWeight", "clustering", "spam", "scatter plot", "ggmLassoDemo", "indicator function", "visualizing", "folds", "multiclass classi\ufb01cation", "logregSATdemo", "Voronoi tessellation", "face recognition", "decision rule", "sigmoid", "Jeopardy", "descriptive", "basis function expansion", "ordinal regression", "risk averse", "logistic", "U-shaped curve", "mnist1NNdemo", "design matrix", "unknown", "classi\ufb01cation", "binary classi\ufb01cation", "knowledge discovery", "crowd sourcing", "invariant", "no free lunch theorem", "attributes", "LOOCV", "missing data", "regression", "cross validation", "pcaImageDemo", "image inpainting", "sliding window detector", "bell curve", "long tail", "mode", "iris", "training set", "INDEX TO KEYWORDS object detection", "normal", "multi-label classi\ufb01cation"], "level": 1, "startpage": 31, "endpage": 56, "topicname": "1 Introduction"}, {"keywordlist": ["unsupervised learning", "features", "nominal", "response variable", "machine learning", "probability theory xxvii", "predictive", "categorical", "reward", "supervised learning", "covariates", "big data", "reinforcement learning", "pattern recognition", "descriptive", "ordinal regression", "classi\ufb01cation", "knowledge discovery", "attributes", "regression", "long tail", "training set"], "level": 2, "startpage": 31, "endpage": 32, "topicname": "1.1 Machine learning: what and why?"}, {"keywordlist": ["unsupervised learning", "features", "nominal", "response variable", "predictive", "categorical", "reward", "supervised learning", "covariates", "reinforcement learning", "pattern recognition", "descriptive", "ordinal regression", "classi\ufb01cation", "knowledge discovery", "attributes", "regression", "long tail", "training set"], "level": 3, "startpage": 32, "endpage": 32, "topicname": "1.1.1 Types of machine learning"}, {"keywordlist": ["generalize", "SmartASS", "CTR", "object detection", "click-through rate", "document classi\ufb01cation", "\ufb01sheririsDemo", "object localization", "ham", "face detection", "exploratory data analysis", "handwriting recognition", "email spam \ufb01ltering", "MNIST", "function approximation", "shuffledDigitsDemo", "feature extraction", "generalization", "MAP estimate", "maximum a posteriori", "digital cameras", "multiple output model", "image classi\ufb01cation", "Watson", "newsgroupsVisualize", "StreetView", "bag of words", "co-occurrence matrix", "spam", "scatter plot", "multiclass classi\ufb01cation", "face recognition", "Jeopardy", "risk averse", "design matrix", "binary classi\ufb01cation", "invariant", "sliding window detector", "mode", "iris", "INDEX TO KEYWORDS object detection", "multi-label classi\ufb01cation"], "level": 2, "startpage": 33, "endpage": 38, "topicname": "1.2 Supervised learning"}, {"keywordlist": ["generalize", "SmartASS", "CTR", "click-through rate", "document classi\ufb01cation", "\ufb01sheririsDemo", "ham", "exploratory data analysis", "handwriting recognition", "email spam \ufb01ltering", "MNIST", "function approximation", "shuffledDigitsDemo", "feature extraction", "generalization", "MAP estimate", "maximum a posteriori", "multiple output model", "image classi\ufb01cation", "Watson", "newsgroupsVisualize", "bag of words", "co-occurrence matrix", "spam", "scatter plot", "multiclass classi\ufb01cation", "Jeopardy", "risk averse", "design matrix", "binary classi\ufb01cation", "mode", "iris", "multi-label classi\ufb01cation"], "level": 3, "startpage": 33, "endpage": 37, "topicname": "1.2.1 Classification"}, {"keywordlist": ["object detection", "object localization", "face detection", "digital cameras", "StreetView", "face recognition", "invariant", "sliding window detector", "INDEX TO KEYWORDS object detection"], "level": 3, "startpage": 38, "endpage": 38, "topicname": "1.2.2 Regression"}, {"keywordlist": ["e-commerce", "eigenfaces", "hidden", "Net\ufb02ix", "dimensionality reduction", "imputation", "market basket analysis", "latent", "linregPolyVsDegree", "Mechanical Turk", "NaN", "principal components analysis", "sparse", "autoclass", "frequent itemset mining", "collaborative \ufb01ltering", "systems biology", "pcaDemo3d", "association rules", "model based clustering", "density estimation", "latent factors", "MATLAB, xxviii matrix completion", "JamBayes", "PCA", "missing", "latent semantic analysis", "model selection", "kmeansHeightWeight", "clustering", "ggmLassoDemo", "visualizing", "unknown", "crowd sourcing", "missing data", "pcaImageDemo", "image inpainting"], "level": 2, "startpage": 39, "endpage": 45, "topicname": "1.3 Unsupervised learning"}, {"keywordlist": ["hidden", "Mechanical Turk", "model selection", "kmeansHeightWeight", "clustering", "crowd sourcing"], "level": 3, "startpage": 40, "endpage": 40, "topicname": "1.3.1 Discovering clusters"}, {"keywordlist": ["e-commerce", "eigenfaces", "dimensionality reduction", "latent", "principal components analysis", "autoclass", "pcaDemo3d", "model based clustering", "latent factors", "PCA", "latent semantic analysis", "visualizing", "pcaImageDemo"], "level": 3, "startpage": 41, "endpage": 42, "topicname": "1.3.2 Discovering latent factors"}, {"keywordlist": ["systems biology", "JamBayes", "ggmLassoDemo"], "level": 3, "startpage": 43, "endpage": 43, "topicname": "1.3.3 Discovering graph structure"}, {"keywordlist": ["Net\ufb02ix", "imputation", "market basket analysis", "NaN", "sparse", "frequent itemset mining", "collaborative \ufb01ltering", "association rules", "MATLAB, xxviii matrix completion", "missing", "unknown", "missing data", "image inpainting"], "level": 3, "startpage": 44, "endpage": 45, "topicname": "1.3.4 Matrix completion"}, {"keywordlist": ["scalar product", "misclassi\ufb01cation rate", "curseDimensionality", "polynomial regression", "logit", "gaussPlotDemo", "CV", "non-parametric model", "instance-based learning", "knnVoronoi", "weight vector", "memory-based learning", "linearly separable", "knnClassifyDemo", "linregWedgeDemo2", "Gaussian", "under\ufb01ts", "logistic regression", "inductive bias", "Bernoulli", "Euclidean distance", "curse of dimensionality", "KNN", "parametric model", "squashing function", "over\ufb01t", "bias", "nearest neighbor", "validation set", "generalization error", "decision boundary", "residual error", "leave-one out cross validation", "linear regression", "sigmoidPlot", "indicator function", "folds", "logregSATdemo", "Voronoi tessellation", "decision rule", "sigmoid", "basis function expansion", "logistic", "U-shaped curve", "mnist1NNdemo", "no free lunch theorem", "LOOCV", "cross validation", "bell curve", "normal"], "level": 2, "startpage": 46, "endpage": 56, "topicname": "1.4 Some basic concepts in machine learning"}, {"keywordlist": ["non-parametric model", "knnVoronoi", "KNN", "parametric model", "nearest neighbor"], "level": 3, "startpage": 46, "endpage": 46, "topicname": "1.4.1 Parametric vs non-parametric models"}, {"keywordlist": ["non-parametric model", "instance-based learning", "knnVoronoi", "memory-based learning", "knnClassifyDemo", "KNN", "parametric model", "nearest neighbor", "indicator function"], "level": 3, "startpage": 46, "endpage": 47, "topicname": "1.4.2 A simple non-parametric classifier: K-nearest neighbors"}, {"keywordlist": ["curseDimensionality", "Euclidean distance", "curse of dimensionality", "Voronoi tessellation"], "level": 3, "startpage": 48, "endpage": 48, "topicname": "1.4.3 The curse of dimensionality"}, {"keywordlist": ["scalar product", "gaussPlotDemo", "weight vector", "linregWedgeDemo2", "inductive bias", "residual error", "linear regression"], "level": 3, "startpage": 49, "endpage": 49, "topicname": "1.4.4 Parametric models for classification and regression"}, {"keywordlist": ["scalar product", "polynomial regression", "gaussPlotDemo", "weight vector", "linregWedgeDemo2", "Gaussian", "inductive bias", "bias", "residual error", "linear regression", "basis function expansion", "bell curve", "normal"], "level": 3, "startpage": 49, "endpage": 50, "topicname": "1.4.5 Linear regression"}, {"keywordlist": ["logit", "logistic regression", "Bernoulli", "squashing function", "sigmoidPlot", "logregSATdemo", "sigmoid", "logistic"], "level": 3, "startpage": 51, "endpage": 51, "topicname": "1.4.6 Logistic regression"}, {"keywordlist": ["misclassi\ufb01cation rate", "linearly separable", "over\ufb01t", "decision boundary", "decision rule"], "level": 3, "startpage": 52, "endpage": 52, "topicname": "1.4.7 Overfitting"}, {"keywordlist": ["misclassi\ufb01cation rate", "linearly separable", "under\ufb01ts", "over\ufb01t", "validation set", "generalization error", "decision boundary", "decision rule", "U-shaped curve"], "level": 3, "startpage": 52, "endpage": 53, "topicname": "1.4.8 Model selection"}, {"keywordlist": ["CV", "leave-one out cross validation", "folds", "mnist1NNdemo", "no free lunch theorem", "LOOCV", "cross validation"], "level": 3, "startpage": 54, "endpage": 56, "topicname": "1.4.9 No free lunch theorem"}, {"keywordlist": ["entropy", "naive Bayes classi\ufb01ers", "change of variables", "mammogram", "erf", "changeOfVarsDemo1d", "poissonPlotDemo", "degrees of freedom", "isotropic", "marginal distribution", "source coding", "mutualInfoAllPairsMixed", "mean", "miMixedDemo", "discriminative classi\ufb01er", "probability simplex", "precision", "channel coding", "gampdf", "Kullback-Leibler divergence", "iid", "robustDemo", "false alarm", "Erlang distribution", "Zipf\u2019s law", "sensitivity", "Cauchy", "uncertainty", "variance", "error correction", "joint distribution", "discretize", "plutocracies", "Jensen-Shannon divergence", "mutual information", "empirical measure", "conditionally independent", "atomic bomb", "quantileDemo", "binomial", "gamma distribution", "multivariate Gaussian", "mutually independent", "linearity of expectation", "discrete", "beta function", "pmf", "centralLimitDemo", "rule of total probability", "pointwise mutual information", "seqlogoDemo", "binomDistPlot", "sequence logo", "Jacobian matrix", "pairwise independent", "heavy tails", "Markov chain Monte Carlo", "quantize", "generative classi\ufb01er", "defender\u2019s fallacy", "binary entropy function", "multinomial coefficient", "bits", "cross entropy", "frequentist", "median", "visDirichletGui", "binomial coefficient", "Pareto distribution", "mcEstimatePi", "MCMC", "Bayes rule", "dirichletHistogramDemo", "standard error", "samples", "KL divergence", "data compression", "standard normal", "Dirac delta function", "biosequence analysis", "double sided exponential", "Student t distribution", "polar", "power law", "multivariate normal", "relative entropy", "full", "false positive", "Cartesian", "precision matrix", "information", "class-conditional density", "chain rule", "studentLaplacePdfPlot", "sifting property", "discrete random variable", "correlation coefficient", "Exponential distribution", "Poisson", "cdf", "World Health Organization", "product rule", "Lorentz", "betaPlotDemo", "long tails", "cumulative distribution function", "Chi-squared distribution", "pdf", "independent and identically distributed", "Dirac measure", "quantile", "Monte Carlo integration", "covariance", "empirical distribution", "MI", "one-hot encoding", "sum rule", "tail area probabilities", "Markov models", "multinoulli distribution", "joint probability distribution", "base rate fallacy", "Jensen\u2019s inequality", "discreteProbDistFig", "Bayesian xxvii", "Monte Carlo", "concentration matrix", "DNA sequences", "state space", "uniform distribution", "gammaRainfallDemo", "error function", "maximum entropy", "marginally independent", "MVN", "gamma function", "gammaPlotDemo", "covariance matrix", "central-limit theorem", "dirichlet3dPlot", "maximal information coefficient", "diagonal", "central limit theorem", "correlation matrix", "standard deviation", "bernoulliEntropyFig", "Information inequality", "gaussPlot2Ddemo", "unconditionally independent", "Laplace distribution", "conditional entropy", "probability density function", "consensus sequence", "Dirichlet distribution", "prosecutor\u2019s fallacy", "principle of insufficient reason", "level sets", "quartiles", "beta distribution", "expected value", "motif", "dummy encoding", "paretoPlot", "inverse gamma", "probability mass function", "information theory", "spherical", "nats", "conditional probability", "multinomial", "sparsity", "multivariate Student t", "convex", "axis aligned", "Bayes Theorem", "mcAccuracyDemo"], "level": 1, "startpage": 57, "endpage": 94, "topicname": "2 Probability"}, {"keywordlist": ["uncertainty", "frequentist", "information", "Bayesian xxvii"], "level": 2, "startpage": 57, "endpage": 57, "topicname": "2.1 Introduction"}, {"keywordlist": ["naive Bayes classi\ufb01ers", "mammogram", "marginal distribution", "mean", "discriminative classi\ufb01er", "false alarm", "sensitivity", "variance", "joint distribution", "conditionally independent", "quantileDemo", "pmf", "rule of total probability", "generative classi\ufb01er", "median", "Bayes rule", "false positive", "class-conditional density", "chain rule", "discrete random variable", "cdf", "product rule", "cumulative distribution function", "pdf", "quantile", "sum rule", "tail area probabilities", "Markov models", "base rate fallacy", "discreteProbDistFig", "state space", "uniform distribution", "marginally independent", "unconditionally independent", "probability density function", "quartiles", "expected value", "probability mass function", "conditional probability", "Bayes Theorem"], "level": 2, "startpage": 58, "endpage": 63, "topicname": "2.2 A brief review of probability theory"}, {"keywordlist": ["pmf", "discrete random variable", "discreteProbDistFig", "state space", "probability mass function"], "level": 3, "startpage": 58, "endpage": 58, "topicname": "2.2.1 Discrete random var"}, {"keywordlist": ["pmf", "discrete random variable", "discreteProbDistFig", "state space", "probability mass function"], "level": 3, "startpage": 58, "endpage": 58, "topicname": "2.2.2 Fundamental rules"}, {"keywordlist": ["mammogram", "marginal distribution", "sensitivity", "joint distribution", "rule of total probability", "Bayes rule", "chain rule", "product rule", "sum rule", "conditional probability", "Bayes Theorem"], "level": 3, "startpage": 59, "endpage": 59, "topicname": "2.2.3 Bayes rule"}, {"keywordlist": ["discriminative classi\ufb01er", "false alarm", "conditionally independent", "generative classi\ufb01er", "false positive", "class-conditional density", "base rate fallacy", "marginally independent", "unconditionally independent"], "level": 3, "startpage": 60, "endpage": 61, "topicname": "2.2.4 Independence and conditional independence"}, {"keywordlist": ["naive Bayes classi\ufb01ers", "cdf", "cumulative distribution function", "pdf", "Markov models", "uniform distribution", "probability density function"], "level": 3, "startpage": 62, "endpage": 62, "topicname": "2.2.5 Continuous random variables"}, {"keywordlist": ["mean", "variance", "quantileDemo", "median", "quantile", "tail area probabilities", "quartiles", "expected value"], "level": 3, "startpage": 63, "endpage": 63, "topicname": "2.2.6 Quantiles"}, {"keywordlist": ["mean", "variance", "quantileDemo", "median", "quantile", "tail area probabilities", "quartiles", "expected value"], "level": 3, "startpage": 63, "endpage": 63, "topicname": "2.2.7 Mean and variance"}, {"keywordlist": ["poissonPlotDemo", "empirical measure", "binomial", "discrete", "seqlogoDemo", "binomDistPlot", "sequence logo", "multinomial coefficient", "binomial coefficient", "biosequence analysis", "Poisson", "Dirac measure", "empirical distribution", "one-hot encoding", "multinoulli distribution", "DNA sequences", "standard deviation", "consensus sequence", "motif", "dummy encoding", "multinomial"], "level": 2, "startpage": 64, "endpage": 67, "topicname": "2.3 Some common discrete distributions"}, {"keywordlist": ["binomial", "binomial coefficient", "standard deviation"], "level": 3, "startpage": 64, "endpage": 64, "topicname": "2.3.1 The binomial and Bernoulli distributions"}, {"keywordlist": ["discrete", "seqlogoDemo", "binomDistPlot", "sequence logo", "multinomial coefficient", "biosequence analysis", "one-hot encoding", "multinoulli distribution", "DNA sequences", "consensus sequence", "motif", "dummy encoding", "multinomial"], "level": 3, "startpage": 65, "endpage": 66, "topicname": "2.3.2 The multinomial and multinoulli distributions"}, {"keywordlist": ["poissonPlotDemo", "empirical measure", "Poisson", "Dirac measure", "empirical distribution"], "level": 3, "startpage": 67, "endpage": 67, "topicname": "2.3.3 The Poisson distribution"}, {"keywordlist": ["poissonPlotDemo", "empirical measure", "Poisson", "Dirac measure", "empirical distribution"], "level": 3, "startpage": 67, "endpage": 67, "topicname": "2.3.4 The empirical distribution"}, {"keywordlist": ["erf", "degrees of freedom", "precision", "gampdf", "robustDemo", "Erlang distribution", "Zipf\u2019s law", "Cauchy", "plutocracies", "gamma distribution", "beta function", "heavy tails", "Pareto distribution", "standard normal", "Dirac delta function", "double sided exponential", "Student t distribution", "power law", "studentLaplacePdfPlot", "sifting property", "Exponential distribution", "Lorentz", "betaPlotDemo", "long tails", "Chi-squared distribution", "gammaRainfallDemo", "error function", "maximum entropy", "gamma function", "gammaPlotDemo", "central limit theorem", "Laplace distribution", "beta distribution", "inverse gamma", "sparsity"], "level": 2, "startpage": 68, "endpage": 73, "topicname": "2.4 Some common continuous distributions"}, {"keywordlist": ["erf", "precision", "standard normal", "error function", "central limit theorem"], "level": 3, "startpage": 68, "endpage": 68, "topicname": "2.4.1 Gaussian (normal) distribution"}, {"keywordlist": ["degrees of freedom", "robustDemo", "Cauchy", "Dirac delta function", "Student t distribution", "studentLaplacePdfPlot", "sifting property", "Lorentz", "maximum entropy"], "level": 3, "startpage": 69, "endpage": 70, "topicname": "2.4.2 Degenerate pdf"}, {"keywordlist": ["gampdf", "gamma distribution", "double sided exponential", "gammaRainfallDemo", "gammaPlotDemo", "Laplace distribution", "sparsity"], "level": 3, "startpage": 71, "endpage": 71, "topicname": "2.4.3 The Laplace distribution"}, {"keywordlist": ["gampdf", "gamma distribution", "double sided exponential", "gammaRainfallDemo", "gammaPlotDemo", "Laplace distribution", "sparsity"], "level": 3, "startpage": 71, "endpage": 71, "topicname": "2.4.4 The gamma distribution"}, {"keywordlist": ["Erlang distribution", "beta function", "Exponential distribution", "Chi-squared distribution", "gamma function", "beta distribution", "inverse gamma"], "level": 3, "startpage": 72, "endpage": 72, "topicname": "2.4.5 The beta distribution"}, {"keywordlist": ["Zipf\u2019s law", "plutocracies", "heavy tails", "Pareto distribution", "power law", "betaPlotDemo", "long tails"], "level": 3, "startpage": 73, "endpage": 73, "topicname": "2.4.6 Pareto distribution"}, {"keywordlist": ["isotropic", "probability simplex", "mutual information", "multivariate Gaussian", "visDirichletGui", "dirichletHistogramDemo", "multivariate normal", "full", "precision matrix", "correlation coefficient", "covariance", "joint probability distribution", "concentration matrix", "MVN", "covariance matrix", "dirichlet3dPlot", "diagonal", "correlation matrix", "gaussPlot2Ddemo", "Dirichlet distribution", "level sets", "paretoPlot", "spherical", "multivariate Student t", "axis aligned"], "level": 2, "startpage": 74, "endpage": 78, "topicname": "2.5 Joint probability distributions"}, {"keywordlist": ["correlation coefficient", "covariance", "joint probability distribution", "covariance matrix", "correlation matrix", "paretoPlot"], "level": 3, "startpage": 74, "endpage": 75, "topicname": "2.5.1 Covariance and correlation"}, {"keywordlist": ["isotropic", "mutual information", "multivariate Gaussian", "multivariate normal", "full", "precision matrix", "concentration matrix", "MVN", "diagonal", "spherical", "multivariate Student t"], "level": 3, "startpage": 76, "endpage": 76, "topicname": "2.5.2 The multivariate Gaussian"}, {"keywordlist": ["isotropic", "mutual information", "multivariate Gaussian", "multivariate normal", "full", "precision matrix", "concentration matrix", "MVN", "diagonal", "spherical", "multivariate Student t"], "level": 3, "startpage": 76, "endpage": 76, "topicname": "2.5.3 Multivariate Student t distribution"}, {"keywordlist": ["probability simplex", "visDirichletGui", "dirichletHistogramDemo", "dirichlet3dPlot", "gaussPlot2Ddemo", "Dirichlet distribution", "level sets", "axis aligned"], "level": 3, "startpage": 77, "endpage": 78, "topicname": "2.5.4 Dirichlet distribution"}, {"keywordlist": ["change of variables", "iid", "linearity of expectation", "Jacobian matrix", "polar", "Cartesian", "independent and identically distributed"], "level": 2, "startpage": 79, "endpage": 81, "topicname": "2.6 Transformations of random variables"}, {"keywordlist": ["linearity of expectation"], "level": 3, "startpage": 79, "endpage": 79, "topicname": "2.6.1 Linear transformations"}, {"keywordlist": ["change of variables", "Jacobian matrix"], "level": 3, "startpage": 80, "endpage": 80, "topicname": "2.6.2 General transformations"}, {"keywordlist": ["iid", "polar", "Cartesian", "independent and identically distributed"], "level": 3, "startpage": 81, "endpage": 81, "topicname": "2.6.3 Central limit theorem"}, {"keywordlist": ["changeOfVarsDemo1d", "atomic bomb", "centralLimitDemo", "Markov chain Monte Carlo", "mcEstimatePi", "MCMC", "samples", "Monte Carlo integration", "Monte Carlo", "central-limit theorem", "mcAccuracyDemo"], "level": 2, "startpage": 82, "endpage": 85, "topicname": "2.7 Monte Carlo approximation"}, {"keywordlist": ["changeOfVarsDemo1d", "Monte Carlo integration"], "level": 3, "startpage": 83, "endpage": 83, "topicname": "2.7.1 Example: change of variables, the MC way"}, {"keywordlist": ["mcEstimatePi"], "level": 3, "startpage": 84, "endpage": 84, "topicname": "2.7.2 Example: estimating \u03c0 by Monte Carlo integration"}, {"keywordlist": ["mcEstimatePi", "central-limit theorem", "mcAccuracyDemo"], "level": 3, "startpage": 84, "endpage": 85, "topicname": "2.7.3 Accuracy of Monte Carlo approximation"}, {"keywordlist": ["entropy", "source coding", "mutualInfoAllPairsMixed", "miMixedDemo", "channel coding", "Kullback-Leibler divergence", "error correction", "discretize", "Jensen-Shannon divergence", "mutually independent", "pointwise mutual information", "pairwise independent", "quantize", "defender\u2019s fallacy", "binary entropy function", "bits", "cross entropy", "standard error", "KL divergence", "data compression", "relative entropy", "World Health Organization", "MI", "Jensen\u2019s inequality", "maximal information coefficient", "bernoulliEntropyFig", "Information inequality", "conditional entropy", "prosecutor\u2019s fallacy", "principle of insufficient reason", "information theory", "nats", "convex"], "level": 2, "startpage": 86, "endpage": 94, "topicname": "2.8 Information theory"}, {"keywordlist": ["entropy", "source coding", "channel coding", "error correction", "bits", "standard error", "data compression", "information theory", "nats"], "level": 3, "startpage": 86, "endpage": 86, "topicname": "2.8.1 Entropy"}, {"keywordlist": ["Kullback-Leibler divergence", "Jensen-Shannon divergence", "binary entropy function", "cross entropy", "KL divergence", "relative entropy", "Jensen\u2019s inequality", "bernoulliEntropyFig", "Information inequality", "principle of insufficient reason", "convex"], "level": 3, "startpage": 87, "endpage": 88, "topicname": "2.8.2 KL divergence"}, {"keywordlist": ["mutualInfoAllPairsMixed", "miMixedDemo", "discretize", "mutually independent", "pointwise mutual information", "pairwise independent", "quantize", "defender\u2019s fallacy", "World Health Organization", "MI", "maximal information coefficient", "conditional entropy", "prosecutor\u2019s fallacy"], "level": 3, "startpage": 89, "endpage": 94, "topicname": "2.8.3 Mutual information"}, {"keywordlist": ["Polya urn", "INDEX TO KEYWORDS hyper-parameters", "plug-in approximation", "data overwhelms the prior", "zero count problem", "identi\ufb01able in the limit", "DCM", "screening", "maximum likelihood estimate", "strong sampling assumption", "Dirichlet", "black swan paradox", "Bernoulli product model", "Karl Popper", "pseudo counts", "aha", "error bar", "concept", "positive examples", "size principle", "naiveBayesPredict", "weighted average", "Dirichlet Compound Multinomial", "MLE", "log-sum-exp", "ranking", "binomial distribution", "similar", "number game", "hypothesis space", "belief state", "feature selection", "unk", "likelihood ratio", "stemming", "scienti\ufb01c method", "iff", "concept learning", "sufficient statistics", "Laplace\u2019s rule of succession", "numbersGame", "burstiness", "personalized recommendation", "logsumexp", "Bayes model averaging", "naiveBayesBowDemo", "negative examples", "online learning", "betaBinomPostPredDemo", "stop words", "fuzzy set theory", "beta-binomial", "equivalent sample size", "Lagrangian", "background knowledge", "version space", "binary independence model", "posterior predictive distribution", "convex combination", "suspicious coincidences", "binomialBetaPosteriorDemo", "induction", "naive Bayes classi\ufb01er", "consistent estimators", "language modeling", "Document classi\ufb01cation", "numerical under\ufb02ow", "Lagrange multiplier", "over\ufb01tting", "Occam\u2019s razor", "multivariate Bernoulli naive Bayes", "add-one smoothing", "generalization gradient", "effective sample size", "extension", "conjugate prior", "naiveBayesFit", "mixture", "subjective", "\ufb01ltering", "sparse data problem"], "level": 1, "startpage": 95, "endpage": 126, "topicname": "3 Generative Models for Discrete Data"}, {"keywordlist": ["concept", "positive examples", "number game", "concept learning", "negative examples", "fuzzy set theory"], "level": 2, "startpage": 95, "endpage": 95, "topicname": "3.1 Introduction"}, {"keywordlist": ["data overwhelms the prior", "identi\ufb01able in the limit", "maximum likelihood estimate", "strong sampling assumption", "aha", "concept", "positive examples", "size principle", "weighted average", "MLE", "similar", "number game", "hypothesis space", "belief state", "likelihood ratio", "scienti\ufb01c method", "iff", "concept learning", "numbersGame", "Bayes model averaging", "negative examples", "fuzzy set theory", "background knowledge", "version space", "posterior predictive distribution", "suspicious coincidences", "induction", "consistent estimators", "Occam\u2019s razor", "generalization gradient", "extension", "subjective"], "level": 2, "startpage": 95, "endpage": 101, "topicname": "3.2 Bayesian concept learning"}, {"keywordlist": ["strong sampling assumption", "size principle", "likelihood ratio", "version space", "suspicious coincidences", "Occam\u2019s razor", "extension", "subjective"], "level": 3, "startpage": 97, "endpage": 97, "topicname": "3.2.1 Likelihood"}, {"keywordlist": ["strong sampling assumption", "size principle", "likelihood ratio", "version space", "suspicious coincidences", "Occam\u2019s razor", "extension", "subjective"], "level": 3, "startpage": 97, "endpage": 97, "topicname": "3.2.2 Prior"}, {"keywordlist": ["data overwhelms the prior", "identi\ufb01able in the limit", "maximum likelihood estimate", "aha", "MLE", "iff", "numbersGame", "background knowledge", "consistent estimators"], "level": 3, "startpage": 98, "endpage": 100, "topicname": "3.2.3 Posterior"}, {"keywordlist": ["weighted average", "belief state", "scienti\ufb01c method", "Bayes model averaging"], "level": 3, "startpage": 101, "endpage": 101, "topicname": "3.2.4 Posterior predictive distribution"}, {"keywordlist": ["plug-in approximation", "over\ufb01tting", "mixture"], "level": 3, "startpage": 102, "endpage": 102, "topicname": "3.2.5 A more complex prior"}, {"keywordlist": ["INDEX TO KEYWORDS hyper-parameters", "plug-in approximation", "zero count problem", "black swan paradox", "Karl Popper", "pseudo counts", "error bar", "binomial distribution", "sufficient statistics", "Laplace\u2019s rule of succession", "personalized recommendation", "online learning", "equivalent sample size", "convex combination", "binomialBetaPosteriorDemo", "over\ufb01tting", "add-one smoothing", "effective sample size", "conjugate prior", "mixture", "sparse data problem"], "level": 2, "startpage": 102, "endpage": 107, "topicname": "3.3 The beta-binomial model"}, {"keywordlist": [], "level": 3, "startpage": 103, "endpage": 103, "topicname": "3.3.1 Likelihood"}, {"keywordlist": ["INDEX TO KEYWORDS hyper-parameters", "binomial distribution", "sufficient statistics", "conjugate prior"], "level": 3, "startpage": 104, "endpage": 104, "topicname": "3.3.2 Prior"}, {"keywordlist": ["pseudo counts", "error bar", "online learning", "equivalent sample size", "convex combination", "binomialBetaPosteriorDemo", "effective sample size"], "level": 3, "startpage": 105, "endpage": 106, "topicname": "3.3.3 Posterior"}, {"keywordlist": ["zero count problem", "black swan paradox", "Karl Popper", "Laplace\u2019s rule of succession", "personalized recommendation", "add-one smoothing", "sparse data problem"], "level": 3, "startpage": 107, "endpage": 107, "topicname": "3.3.4 Posterior predictive distribution"}, {"keywordlist": ["Dirichlet", "unk", "stemming", "betaBinomPostPredDemo", "stop words", "beta-binomial", "Lagrangian", "language modeling", "Lagrange multiplier"], "level": 2, "startpage": 108, "endpage": 111, "topicname": "3.4 The Dirichlet-multinomial model"}, {"keywordlist": ["Dirichlet", "betaBinomPostPredDemo"], "level": 3, "startpage": 109, "endpage": 109, "topicname": "3.4.1 Likelihood"}, {"keywordlist": ["Dirichlet", "betaBinomPostPredDemo"], "level": 3, "startpage": 109, "endpage": 109, "topicname": "3.4.2 Prior"}, {"keywordlist": ["Dirichlet", "betaBinomPostPredDemo", "Lagrangian", "Lagrange multiplier"], "level": 3, "startpage": 109, "endpage": 110, "topicname": "3.4.3 Posterior"}, {"keywordlist": ["unk", "stemming", "stop words", "language modeling"], "level": 3, "startpage": 111, "endpage": 111, "topicname": "3.4.4 Posterior predictive"}, {"keywordlist": ["Polya urn", "DCM", "screening", "Bernoulli product model", "naiveBayesPredict", "Dirichlet Compound Multinomial", "log-sum-exp", "ranking", "feature selection", "burstiness", "logsumexp", "naiveBayesBowDemo", "binary independence model", "naive Bayes classi\ufb01er", "Document classi\ufb01cation", "numerical under\ufb02ow", "multivariate Bernoulli naive Bayes", "naiveBayesFit", "\ufb01ltering"], "level": 2, "startpage": 112, "endpage": 126, "topicname": "3.5 Naive Bayes classifiers"}, {"keywordlist": ["naiveBayesBowDemo", "naiveBayesFit"], "level": 3, "startpage": 113, "endpage": 114, "topicname": "3.5.1 Model fitting"}, {"keywordlist": [], "level": 3, "startpage": 115, "endpage": 115, "topicname": "3.5.2 Using the model for prediction"}, {"keywordlist": ["naiveBayesPredict", "log-sum-exp", "feature selection", "logsumexp", "numerical under\ufb02ow"], "level": 3, "startpage": 116, "endpage": 116, "topicname": "3.5.3 The log-sum-exp trick"}, {"keywordlist": ["naiveBayesPredict", "log-sum-exp", "feature selection", "logsumexp", "numerical under\ufb02ow"], "level": 3, "startpage": 116, "endpage": 116, "topicname": "3.5.4 Feature selection using mutual information"}, {"keywordlist": ["Polya urn", "DCM", "screening", "Bernoulli product model", "Dirichlet Compound Multinomial", "ranking", "burstiness", "binary independence model", "Document classi\ufb01cation", "\ufb01ltering"], "level": 3, "startpage": 117, "endpage": 126, "topicname": "3.5.5 Classifying documents using bag of words"}, {"keywordlist": ["conditionally conjugate", "splineBasisDemo", "gaussHeightWeight", "shrunkenCentroidsFit", "shrunkenCentroidsSRBCTdemo", "diagonal covariance LDA", "rule of iterated expectation", "sensorFusionUnknownPrec", "inverse chi-squared distribution", "multi-class logistic regression", "\ufb01nite difference matrix", "gaussPlot2d", "quadratic discriminant analysis", "Sherman-Morrison-Woodbury formula", "paired t-test", "pointwise marginal credibility intervals", "shrinkcovDemo", "linear Gaussian system", "discrimAnalysisPredict", "Schur complement", "plug-in", "diagonal LDA", "gaussInterpNoisyDemo", "normal inverse chi-squared", "sphereing", "softmaxDemo2", "standard error of the mean", "tridiagonal", "shared", "credible interval", "pooled empirical variance", "moment parameters", "nearest centroids classi\ufb01er", "rdaFit", "Kalman \ufb01lter", "NIXdemo2", "Standardizing", "parameter tying", "canonical parameters", "wiPlotDemo", "inverse Wishart", "trace", "LDA", "multiple imputation", "intrinsic Gaussian random \ufb01eld", "GDA", "gaussCondition2Ddemo2", "cyclic permutation property", "signal detection theory", "ill-conditioned", "Normal-inverse-wishart", "regularized discriminant analysis", "SVD", "cancerHighDimClassifDemo", "kernel density estimation", "Boltzmann distribution", "trace trick", "functional data analysis", "shrinkage", "bayesTtestDemo", "INDEX TO KEYWORDS Bayes factor", "Mahalanobis distance", "multivariate Gamma function", "completing the square", "nearest shrunken centroids", "inverse Gamma", "multivariate gamma function", "Tikhonov regularization", "discriminant analysis", "parameter sharing", "temperature", "eigenvalue spectrum", "discrimAnalysisDboundariesDemo", "gaussInferParamsMean1d", "Whitening", "sample standard deviation", "discrimAnalysisFit", "d-prime", "signal-to-noise ratio", "positive de\ufb01nite", "sensorFusion2d", "gaussInterpDemo", "shrinkage estimation", "gaussSeqUpdateSigma1D", "matrix determinant lemma", "natural parameters", "tied", "semi-conjugate", "regularized estimation", "shrinkcov", "softmax", "discrimAnalysisHeightWeightDemo", "p-value", "gaussImputationDemo", "exponential family", "information form", "gaussInferParamsMean2d", "t statistic", "rank one update", "NIX", "NIW", "matrix inversion lemma", "interpolate", "Wishart", "eigendecomposition", "sensor fusion", "partitioned inverse formula", "t-test", "discriminability", "\ufb01xed point", "linear discriminant analysis", "multinomial logistic regression"], "level": 1, "startpage": 127, "endpage": 178, "topicname": "4 Gaussian Models"}, {"keywordlist": ["trace", "cyclic permutation property", "trace trick", "Mahalanobis distance", "eigendecomposition"], "level": 2, "startpage": 127, "endpage": 130, "topicname": "4.1 Introduction"}, {"keywordlist": [], "level": 3, "startpage": 127, "endpage": 127, "topicname": "4.1.1 Notation"}, {"keywordlist": ["Mahalanobis distance", "eigendecomposition"], "level": 3, "startpage": 127, "endpage": 128, "topicname": "4.1.2 Basics"}, {"keywordlist": ["trace", "cyclic permutation property", "trace trick"], "level": 3, "startpage": 129, "endpage": 130, "topicname": "4.1.3 MLE for an MVN"}, {"keywordlist": ["GDA", "discriminant analysis"], "level": 3, "startpage": 131, "endpage": 131, "topicname": "4.1.4 Maximum entropy derivation of the Gaussian *"}, {"keywordlist": ["gaussHeightWeight", "shrunkenCentroidsFit", "shrunkenCentroidsSRBCTdemo", "diagonal covariance LDA", "multi-class logistic regression", "quadratic discriminant analysis", "discrimAnalysisPredict", "diagonal LDA", "softmaxDemo2", "shared", "pooled empirical variance", "nearest centroids classi\ufb01er", "rdaFit", "parameter tying", "LDA", "GDA", "signal detection theory", "ill-conditioned", "regularized discriminant analysis", "SVD", "Boltzmann distribution", "nearest shrunken centroids", "discriminant analysis", "parameter sharing", "temperature", "discrimAnalysisDboundariesDemo", "discrimAnalysisFit", "d-prime", "tied", "softmax", "discriminability", "linear discriminant analysis", "multinomial logistic regression"], "level": 2, "startpage": 131, "endpage": 139, "topicname": "4.2 Gaussian discriminant analysis"}, {"keywordlist": ["gaussHeightWeight", "quadratic discriminant analysis", "nearest centroids classi\ufb01er"], "level": 3, "startpage": 132, "endpage": 132, "topicname": "4.2.1 Quadratic discriminant analysis (QDA)"}, {"keywordlist": ["softmaxDemo2", "shared", "discrimAnalysisDboundariesDemo", "tied"], "level": 3, "startpage": 133, "endpage": 133, "topicname": "4.2.2 Linear discriminant analysis (LDA)"}, {"keywordlist": ["multi-class logistic regression", "LDA", "Boltzmann distribution", "temperature", "softmax", "linear discriminant analysis", "multinomial logistic regression"], "level": 3, "startpage": 134, "endpage": 135, "topicname": "4.2.3 Two-class LDA"}, {"keywordlist": ["discrimAnalysisPredict", "signal detection theory", "ill-conditioned", "discrimAnalysisFit", "d-prime", "discriminability"], "level": 3, "startpage": 136, "endpage": 136, "topicname": "4.2.4 MLE for discriminant analysis"}, {"keywordlist": ["discrimAnalysisPredict", "signal detection theory", "ill-conditioned", "discrimAnalysisFit", "d-prime", "discriminability"], "level": 3, "startpage": 136, "endpage": 136, "topicname": "4.2.5 Strategies for preventing overfitting"}, {"keywordlist": ["diagonal covariance LDA", "parameter tying", "regularized discriminant analysis", "SVD", "parameter sharing"], "level": 3, "startpage": 137, "endpage": 137, "topicname": "4.2.6 Regularized LDA *"}, {"keywordlist": ["diagonal LDA", "pooled empirical variance", "rdaFit"], "level": 3, "startpage": 138, "endpage": 138, "topicname": "4.2.7 Diagonal LDA"}, {"keywordlist": ["shrunkenCentroidsFit", "shrunkenCentroidsSRBCTdemo", "nearest shrunken centroids"], "level": 3, "startpage": 139, "endpage": 139, "topicname": "4.2.8 Nearest shrunken centroids classifier *"}, {"keywordlist": ["\ufb01nite difference matrix", "Sherman-Morrison-Woodbury formula", "pointwise marginal credibility intervals", "Schur complement", "tridiagonal", "moment parameters", "canonical parameters", "multiple imputation", "intrinsic Gaussian random \ufb01eld", "gaussCondition2Ddemo2", "cancerHighDimClassifDemo", "gaussInterpDemo", "matrix determinant lemma", "natural parameters", "gaussImputationDemo", "exponential family", "information form", "rank one update", "matrix inversion lemma", "interpolate", "partitioned inverse formula"], "level": 2, "startpage": 140, "endpage": 148, "topicname": "4.3 Inference in jointly Gaussian distributions"}, {"keywordlist": [], "level": 3, "startpage": 141, "endpage": 141, "topicname": "4.3.1 Statement of the result"}, {"keywordlist": ["\ufb01nite difference matrix", "pointwise marginal credibility intervals", "tridiagonal", "intrinsic Gaussian random \ufb01eld", "gaussCondition2Ddemo2", "gaussInterpDemo", "interpolate"], "level": 3, "startpage": 141, "endpage": 144, "topicname": "4.3.2 Examples"}, {"keywordlist": ["moment parameters", "canonical parameters", "multiple imputation", "natural parameters", "gaussImputationDemo", "exponential family", "information form"], "level": 3, "startpage": 145, "endpage": 145, "topicname": "4.3.3 Information form"}, {"keywordlist": ["Sherman-Morrison-Woodbury formula", "Schur complement", "matrix determinant lemma", "rank one update", "matrix inversion lemma", "partitioned inverse formula"], "level": 3, "startpage": 146, "endpage": 148, "topicname": "4.3.4 Proof of the result *"}, {"keywordlist": ["linear Gaussian system", "Kalman \ufb01lter", "functional data analysis", "shrinkage", "Tikhonov regularization", "gaussInferParamsMean1d", "signal-to-noise ratio", "sensorFusion2d", "gaussInferParamsMean2d", "sensor fusion"], "level": 2, "startpage": 149, "endpage": 154, "topicname": "4.4 Linear Gaussian systems"}, {"keywordlist": ["linear Gaussian system"], "level": 3, "startpage": 149, "endpage": 149, "topicname": "4.4.1 Statement of the result"}, {"keywordlist": ["Kalman \ufb01lter", "shrinkage", "gaussInferParamsMean1d", "signal-to-noise ratio", "sensorFusion2d", "gaussInferParamsMean2d", "sensor fusion"], "level": 3, "startpage": 150, "endpage": 153, "topicname": "4.4.2 Examples"}, {"keywordlist": ["functional data analysis", "Tikhonov regularization"], "level": 3, "startpage": 154, "endpage": 154, "topicname": "4.4.3 Proof of the result *"}, {"keywordlist": ["splineBasisDemo", "gaussInterpNoisyDemo", "inverse Wishart", "multivariate gamma function", "positive de\ufb01nite", "Wishart"], "level": 2, "startpage": 155, "endpage": 156, "topicname": "4.5 Digression: The Wishart distribution *"}, {"keywordlist": ["inverse Wishart", "multivariate gamma function"], "level": 3, "startpage": 156, "endpage": 156, "topicname": "4.5.1 Inverse Wishart distribution"}, {"keywordlist": ["wiPlotDemo", "kernel density estimation"], "level": 3, "startpage": 157, "endpage": 157, "topicname": "4.5.2 Visualizing the Wishart distribution *"}, {"keywordlist": ["conditionally conjugate", "rule of iterated expectation", "sensorFusionUnknownPrec", "inverse chi-squared distribution", "gaussPlot2d", "paired t-test", "shrinkcovDemo", "plug-in", "normal inverse chi-squared", "sphereing", "standard error of the mean", "credible interval", "NIXdemo2", "Standardizing", "wiPlotDemo", "Normal-inverse-wishart", "kernel density estimation", "bayesTtestDemo", "INDEX TO KEYWORDS Bayes factor", "multivariate Gamma function", "completing the square", "inverse Gamma", "eigenvalue spectrum", "Whitening", "sample standard deviation", "shrinkage estimation", "gaussSeqUpdateSigma1D", "semi-conjugate", "regularized estimation", "shrinkcov", "discrimAnalysisHeightWeightDemo", "p-value", "t statistic", "NIX", "NIW", "t-test", "\ufb01xed point"], "level": 2, "startpage": 157, "endpage": 178, "topicname": "4.6 Inferring the parameters of an MVN"}, {"keywordlist": [], "level": 3, "startpage": 158, "endpage": 158, "topicname": "4.6.1 Posterior distribution of \u03bc"}, {"keywordlist": ["inverse chi-squared distribution", "shrinkcovDemo", "inverse Gamma", "eigenvalue spectrum", "shrinkage estimation", "gaussSeqUpdateSigma1D", "regularized estimation", "shrinkcov"], "level": 3, "startpage": 158, "endpage": 161, "topicname": "4.6.2 Posterior distribution of \u03a3 *"}, {"keywordlist": ["conditionally conjugate", "paired t-test", "normal inverse chi-squared", "standard error of the mean", "credible interval", "NIXdemo2", "Normal-inverse-wishart", "INDEX TO KEYWORDS Bayes factor", "multivariate Gamma function", "sample standard deviation", "semi-conjugate", "t statistic", "NIX", "NIW", "t-test"], "level": 3, "startpage": 162, "endpage": 167, "topicname": "4.6.3 Posterior distribution of \u03bc and \u03a3 *"}, {"keywordlist": ["rule of iterated expectation", "sensorFusionUnknownPrec", "gaussPlot2d", "plug-in", "sphereing", "Standardizing", "bayesTtestDemo", "completing the square", "Whitening", "discrimAnalysisHeightWeightDemo", "p-value", "\ufb01xed point"], "level": 3, "startpage": 168, "endpage": 178, "topicname": "4.6.4 Sensor fusion with unknown precisions *"}, {"keywordlist": ["blank slate", "preferences", "shrinkageDemoBaseball", "PRhand", "precision recall curve", "conservation of probability mass", "central interval", "robust priors", "rational behavior", "highest posterior density", "betaHPD", "false negative", "borrow statistical strength", "Akaike information criterion", "F1 score", "false positive rate", "pooled", "linregEbModelSelVsN", "non-informative", "postDensityIntervals", "integrate out", "Fisher information matrix", "missed detection", "Gittins Indices", "area under the curve", "posterior expected loss", "bimodalDemo", "squared loss", "HPD", "quadratic loss", "evidence procedure", "decision procedure", "equal error rate", "robustPriorDemo", "evidence", "score function", "one-shot decision problem", "recall", "harmonic mean", "Fisher information", "sequential", "AUC", "loss matrix", "Bayesian Occam\u2019s razor", "type I error rate", "parameter", "bayesChangeOfVar", "policy", "penalized log likelihood", "Bayes decision rule", "observed information", "false discovery rate", "Bayesian model selection", "multi-armed bandit", "Bayesian statistics", "multi-level model", "improper prior", "reject action", "label", "hierarchical Bayesian model", "contextual bandit", "prevalence", "type-II maximum likelihood", "actions", "information retrieval", "slot machine", "empirical Bayes", "betaCredibleInt", "outliers", "confusion matrix", "optimal action", "moment matching", "Haldane prior", "action", "minimum mean squared error", "high throughput", "suspicious coincidence", "MMSE", "chi-squared statistic", "game against nature", "mixture of conjugate priors", "multiple hypothesis testing", "Jeffreys-Lindley paradox", "(cid:7)2 loss", "false alarm rate", "direct posterior probability approach", "inverse reinforcement learning", "Thompson sampling", "HDI", "EB", "receiver operating characteristic", "integrated likelihood", "test statistic", "exploration-exploitation", "cross over rate", "tabula rasa", "game theory", "macro-averaged F1", "UCB", "Jeffreys prior", "variance stabilizing transform", "highest density interval", "null hypothesis", "Bayes estimator", "cost-bene\ufb01t analysis", "micro-averaged F1", "robust", "mixing weights", "squared error", "con\ufb01dence intervals", "lossFunctionFig", "one-armed bandit", "decision", "scale invariant prior", "QALY", "ROC", "uninformative", "posterior median", "average precision at K", "mean precision", "maximum expected utility principle", "rare event", "Bayesian information criterion", "point estimate", "sensitivity analysis", "Jacobian", "MDL", "translation invariant prior", "misclassi\ufb01cation loss", "amazonSellerDemo", "multi-stage", "AIC", "James Stein estimator", "cancerRatesEb", "(cid:7)1 loss", "coinsModelSelDemo", "BIC", "utility function", "mcQuantileDemo", "multi-task learning", "true positive rate", "state", "James-Stein estimator", "minimum description length", "scale of evidence", "action space", "decision problem", "loss", "classical", "EER", "F score", "type II maximum likelihood", "marginal likelihood", "hit rate", "mixture model", "alternative hypothesis", "mixBetaDemo", "posterior mean", "posterior mode"], "level": 1, "startpage": 179, "endpage": 220, "topicname": "5 Bayesian Statistics"}, {"keywordlist": ["Bayesian statistics", "point estimate", "classical"], "level": 2, "startpage": 179, "endpage": 179, "topicname": "5.1 Introduction"}, {"keywordlist": ["central interval", "highest posterior density", "betaHPD", "postDensityIntervals", "Fisher information matrix", "bimodalDemo", "HPD", "bayesChangeOfVar", "Bayesian statistics", "betaCredibleInt", "HDI", "highest density interval", "con\ufb01dence intervals", "point estimate", "Jacobian", "mcQuantileDemo", "classical"], "level": 2, "startpage": 179, "endpage": 184, "topicname": "5.2 Summarizing posterior distributions"}, {"keywordlist": ["bimodalDemo", "bayesChangeOfVar", "Bayesian statistics", "point estimate", "Jacobian", "classical"], "level": 3, "startpage": 179, "endpage": 181, "topicname": "5.2.1 MAP estimation"}, {"keywordlist": ["central interval", "highest posterior density", "betaHPD", "Fisher information matrix", "HPD", "betaCredibleInt", "con\ufb01dence intervals", "mcQuantileDemo"], "level": 3, "startpage": 182, "endpage": 183, "topicname": "5.2.2 Credible intervals"}, {"keywordlist": ["postDensityIntervals", "HDI", "highest density interval"], "level": 3, "startpage": 184, "endpage": 184, "topicname": "5.2.3 Inference for a difference in proportions"}, {"keywordlist": ["conservation of probability mass", "Akaike information criterion", "linregEbModelSelVsN", "integrate out", "evidence", "Bayesian Occam\u2019s razor", "penalized log likelihood", "Bayesian model selection", "empirical Bayes", "suspicious coincidence", "chi-squared statistic", "integrated likelihood", "test statistic", "null hypothesis", "Bayesian information criterion", "MDL", "amazonSellerDemo", "AIC", "coinsModelSelDemo", "BIC", "minimum description length", "scale of evidence", "type II maximum likelihood", "marginal likelihood", "mixture model", "alternative hypothesis"], "level": 2, "startpage": 185, "endpage": 194, "topicname": "5.3 Bayesian model selection"}, {"keywordlist": ["conservation of probability mass", "integrate out", "evidence", "Bayesian Occam\u2019s razor", "Bayesian model selection", "empirical Bayes", "integrated likelihood", "type II maximum likelihood", "marginal likelihood"], "level": 3, "startpage": 186, "endpage": 187, "topicname": "5.3.1 Bayesian Occam\u2019s razor"}, {"keywordlist": ["Akaike information criterion", "linregEbModelSelVsN", "penalized log likelihood", "Bayesian information criterion", "MDL", "AIC", "BIC", "minimum description length"], "level": 3, "startpage": 188, "endpage": 192, "topicname": "5.3.2 Computing the marginal likelihood (evidence)"}, {"keywordlist": ["chi-squared statistic", "test statistic", "null hypothesis", "scale of evidence", "alternative hypothesis"], "level": 3, "startpage": 193, "endpage": 193, "topicname": "5.3.3 Bayes factors"}, {"keywordlist": ["suspicious coincidence", "coinsModelSelDemo", "mixture model"], "level": 3, "startpage": 194, "endpage": 194, "topicname": "5.3.4 Jeffreys-Lindley paradox *"}, {"keywordlist": ["blank slate", "robust priors", "non-informative", "robustPriorDemo", "score function", "Fisher information", "observed information", "improper prior", "Haldane prior", "mixture of conjugate priors", "Jeffreys-Lindley paradox", "tabula rasa", "Jeffreys prior", "mixing weights", "scale invariant prior", "uninformative", "sensitivity analysis", "translation invariant prior", "mixBetaDemo"], "level": 2, "startpage": 195, "endpage": 200, "topicname": "5.4 Priors"}, {"keywordlist": ["blank slate", "non-informative", "Jeffreys-Lindley paradox", "tabula rasa", "uninformative"], "level": 3, "startpage": 195, "endpage": 195, "topicname": "5.4.1 Uninformative priors"}, {"keywordlist": ["score function", "Fisher information", "observed information", "improper prior", "Haldane prior", "Jeffreys prior", "sensitivity analysis", "translation invariant prior"], "level": 3, "startpage": 196, "endpage": 197, "topicname": "5.4.2 Jeffreys priors *"}, {"keywordlist": ["robust priors", "robustPriorDemo", "scale invariant prior"], "level": 3, "startpage": 198, "endpage": 198, "topicname": "5.4.3 Robust priors"}, {"keywordlist": ["robust priors", "robustPriorDemo", "mixture of conjugate priors", "mixing weights", "scale invariant prior", "mixBetaDemo"], "level": 3, "startpage": 198, "endpage": 200, "topicname": "5.4.4 Mixtures of conjugate priors"}, {"keywordlist": ["borrow statistical strength", "pooled", "multi-level model", "hierarchical Bayesian model"], "level": 2, "startpage": 201, "endpage": 201, "topicname": "5.5 Hierarchical Bayes"}, {"keywordlist": ["borrow statistical strength", "pooled", "multi-level model", "hierarchical Bayesian model"], "level": 3, "startpage": 201, "endpage": 201, "topicname": "5.5.1 Example: modeling related cancer rates"}, {"keywordlist": ["shrinkageDemoBaseball", "evidence procedure", "type-II maximum likelihood", "EB", "variance stabilizing transform", "James Stein estimator", "cancerRatesEb", "multi-task learning", "James-Stein estimator"], "level": 2, "startpage": 202, "endpage": 205, "topicname": "5.6 Empirical Bayes"}, {"keywordlist": ["evidence procedure", "type-II maximum likelihood", "EB", "James-Stein estimator"], "level": 3, "startpage": 203, "endpage": 203, "topicname": "5.6.1 Example: beta-binomial model"}, {"keywordlist": ["shrinkageDemoBaseball", "evidence procedure", "type-II maximum likelihood", "EB", "variance stabilizing transform", "James Stein estimator", "James-Stein estimator"], "level": 3, "startpage": 203, "endpage": 205, "topicname": "5.6.2 Example: Gaussian-Gaussian model"}, {"keywordlist": ["preferences", "PRhand", "precision recall curve", "rational behavior", "false negative", "F1 score", "false positive rate", "missed detection", "Gittins Indices", "area under the curve", "posterior expected loss", "squared loss", "quadratic loss", "decision procedure", "equal error rate", "one-shot decision problem", "recall", "harmonic mean", "sequential", "AUC", "loss matrix", "type I error rate", "parameter", "policy", "Bayes decision rule", "false discovery rate", "multi-armed bandit", "reject action", "label", "contextual bandit", "prevalence", "actions", "information retrieval", "slot machine", "outliers", "confusion matrix", "optimal action", "moment matching", "action", "minimum mean squared error", "high throughput", "MMSE", "game against nature", "multiple hypothesis testing", "(cid:7)2 loss", "false alarm rate", "direct posterior probability approach", "inverse reinforcement learning", "Thompson sampling", "receiver operating characteristic", "exploration-exploitation", "cross over rate", "game theory", "macro-averaged F1", "UCB", "Bayes estimator", "cost-bene\ufb01t analysis", "micro-averaged F1", "robust", "squared error", "lossFunctionFig", "one-armed bandit", "decision", "QALY", "ROC", "posterior median", "average precision at K", "mean precision", "maximum expected utility principle", "rare event", "misclassi\ufb01cation loss", "multi-stage", "(cid:7)1 loss", "utility function", "true positive rate", "state", "action space", "decision problem", "loss", "EER", "F score", "hit rate", "posterior mean", "posterior mode"], "level": 2, "startpage": 206, "endpage": 220, "topicname": "5.7 Bayesian decision theory"}, {"keywordlist": ["rational behavior", "posterior expected loss", "quadratic loss", "decision procedure", "policy", "Bayes decision rule", "reject action", "outliers", "optimal action", "minimum mean squared error", "MMSE", "(cid:7)2 loss", "Bayes estimator", "robust", "squared error", "lossFunctionFig", "posterior median", "maximum expected utility principle", "(cid:7)1 loss", "utility function", "posterior mean", "posterior mode"], "level": 3, "startpage": 207, "endpage": 209, "topicname": "5.7.1 Bayes estimators for common loss functions"}, {"keywordlist": ["PRhand", "precision recall curve", "false negative", "F1 score", "false positive rate", "missed detection", "area under the curve", "equal error rate", "recall", "harmonic mean", "AUC", "type I error rate", "prevalence", "information retrieval", "confusion matrix", "false alarm rate", "receiver operating characteristic", "cross over rate", "macro-averaged F1", "micro-averaged F1", "ROC", "average precision at K", "mean precision", "rare event", "true positive rate", "EER", "F score", "hit rate"], "level": 3, "startpage": 210, "endpage": 213, "topicname": "5.7.2 The false positive vs false negative tradeoff"}, {"keywordlist": ["preferences", "Gittins Indices", "one-shot decision problem", "sequential", "loss matrix", "false discovery rate", "multi-armed bandit", "contextual bandit", "slot machine", "high throughput", "multiple hypothesis testing", "direct posterior probability approach", "inverse reinforcement learning", "Thompson sampling", "exploration-exploitation", "UCB", "cost-bene\ufb01t analysis", "one-armed bandit", "QALY", "multi-stage"], "level": 3, "startpage": 214, "endpage": 220, "topicname": "5.7.3 Other topics *"}, {"keywordlist": ["risk", "admissible", "consistent", "ridge regression", "Hoeffding\u2019s inequality", "asymptotically optimal", "bootstrapDemoBer", "support vector machines", "bootstrap", "bottleneck", "VC", "leave one out cross validation", "log-loss", "NHST", "PAC", "one-standard error rule", "Hessian", "samplingDistGaussShrinkage", "empirical risk minimization", "frequentist statistics", "maximum risk", "Vapnik-Chervonenkis", "asymptotically normal", "classical statistics", "biasVarModelComplexity3", "COLT", "statistically signi\ufb01cant", "\ufb01t-predict cycle", "strati\ufb01ed CV", "optimism of the training error", "weak conditionality", "Bayes risk", "regularized risk minimization", "non-parametric bootstrap", "SVM", "con\ufb01dence interval", "estimator", "probably approximately correct", "parametric bootstrap", "strict", "linregPolyVsRegDemo", "negative binomial distribution", "bias-variance tradeoff", "likelihood equivalent", "integrated risk", "computational learning theory", "hinge loss", "sufficiency principle", "unbiased", "dominates", "Cramer-Rao inequality", "generalized cross validation", "sampling distribution", "unidenti\ufb01able", "surrogate loss function", "statistical learning theory", "pathologies", "preposterior risk", "hingeLossPlot", "type I", "Stein\u2019s paradox", "null hypothesis signi\ufb01cance testing", "empirical risk", "VC dimension", "efficiently PAC-learnable", "least favorable prior", "ERM", "likelihood principle", "stopping rule", "mean squared error", "structural risk minimization", "orthodox statistics", "union bound", "minimax rule", "standard errors", "Cramer-Rao lower bound", "tail area probability", "Wald interval", "observed information matrix", "riskFnGauss"], "level": 1, "startpage": 221, "endpage": 246, "topicname": "6 Frequentist Statistics"}, {"keywordlist": ["frequentist statistics", "classical statistics", "estimator", "sampling distribution", "orthodox statistics"], "level": 2, "startpage": 221, "endpage": 221, "topicname": "6.1 Introduction"}, {"keywordlist": ["bootstrapDemoBer", "bootstrap", "Hessian", "frequentist statistics", "classical statistics", "non-parametric bootstrap", "estimator", "parametric bootstrap", "sampling distribution", "orthodox statistics", "observed information matrix"], "level": 2, "startpage": 221, "endpage": 223, "topicname": "6.2 Sampling distribution of an estimator"}, {"keywordlist": ["bootstrapDemoBer", "bootstrap", "non-parametric bootstrap", "parametric bootstrap"], "level": 3, "startpage": 222, "endpage": 222, "topicname": "6.2.1 Bootstrap"}, {"keywordlist": ["Hessian", "observed information matrix"], "level": 3, "startpage": 223, "endpage": 223, "topicname": "6.2.2 Large sample theory for the MLE *"}, {"keywordlist": ["risk", "admissible", "maximum risk", "asymptotically normal", "Bayes risk", "strict", "integrated risk", "dominates", "preposterior risk", "Stein\u2019s paradox", "least favorable prior", "minimax rule", "standard errors", "riskFnGauss"], "level": 2, "startpage": 224, "endpage": 229, "topicname": "6.3 Frequentist decision theory"}, {"keywordlist": ["risk", "Bayes risk", "integrated risk", "preposterior risk"], "level": 3, "startpage": 225, "endpage": 225, "topicname": "6.3.1 Bayes risk"}, {"keywordlist": ["maximum risk", "minimax rule"], "level": 3, "startpage": 226, "endpage": 226, "topicname": "6.3.2 Minimax risk"}, {"keywordlist": ["admissible", "strict", "dominates", "Stein\u2019s paradox", "least favorable prior", "riskFnGauss"], "level": 3, "startpage": 227, "endpage": 229, "topicname": "6.3.3 Admissible estimators"}, {"keywordlist": ["consistent", "ridge regression", "asymptotically optimal", "samplingDistGaussShrinkage", "bias-variance tradeoff", "likelihood equivalent", "unbiased", "Cramer-Rao inequality", "unidenti\ufb01able", "Cramer-Rao lower bound"], "level": 2, "startpage": 230, "endpage": 233, "topicname": "6.4 Desirable properties of estimators"}, {"keywordlist": ["consistent", "likelihood equivalent", "unbiased", "unidenti\ufb01able"], "level": 3, "startpage": 230, "endpage": 230, "topicname": "6.4.1 Consistent estimators"}, {"keywordlist": ["consistent", "likelihood equivalent", "unbiased", "unidenti\ufb01able"], "level": 3, "startpage": 230, "endpage": 230, "topicname": "6.4.2 Unbiased estimators"}, {"keywordlist": ["asymptotically optimal", "Cramer-Rao inequality", "Cramer-Rao lower bound"], "level": 3, "startpage": 231, "endpage": 231, "topicname": "6.4.3 Minimum variance estimators"}, {"keywordlist": ["ridge regression", "samplingDistGaussShrinkage", "bias-variance tradeoff"], "level": 3, "startpage": 232, "endpage": 233, "topicname": "6.4.4 The bias-variance tradeoff"}, {"keywordlist": ["Hoeffding\u2019s inequality", "bottleneck", "VC", "leave one out cross validation", "log-loss", "PAC", "one-standard error rule", "empirical risk minimization", "Vapnik-Chervonenkis", "biasVarModelComplexity3", "COLT", "\ufb01t-predict cycle", "strati\ufb01ed CV", "optimism of the training error", "regularized risk minimization", "probably approximately correct", "linregPolyVsRegDemo", "computational learning theory", "generalized cross validation", "statistical learning theory", "empirical risk", "VC dimension", "efficiently PAC-learnable", "ERM", "mean squared error", "structural risk minimization", "union bound"], "level": 2, "startpage": 234, "endpage": 240, "topicname": "6.5 Empirical risk minimization"}, {"keywordlist": ["bottleneck", "empirical risk minimization", "empirical risk", "ERM", "mean squared error"], "level": 3, "startpage": 235, "endpage": 235, "topicname": "6.5.1 Regularized risk minimization"}, {"keywordlist": ["\ufb01t-predict cycle", "strati\ufb01ed CV", "optimism of the training error", "regularized risk minimization", "VC dimension", "structural risk minimization"], "level": 3, "startpage": 236, "endpage": 236, "topicname": "6.5.2 Structural risk minimization"}, {"keywordlist": ["leave one out cross validation", "one-standard error rule", "\ufb01t-predict cycle", "strati\ufb01ed CV", "optimism of the training error", "regularized risk minimization", "linregPolyVsRegDemo", "generalized cross validation", "VC dimension", "structural risk minimization"], "level": 3, "startpage": 236, "endpage": 238, "topicname": "6.5.3 Estimating the risk using cross validation"}, {"keywordlist": ["Hoeffding\u2019s inequality", "statistical learning theory", "union bound"], "level": 3, "startpage": 239, "endpage": 239, "topicname": "6.5.4 Upper bounding the risk using statistical learning theory *"}, {"keywordlist": ["VC", "log-loss", "PAC", "Vapnik-Chervonenkis", "COLT", "probably approximately correct", "computational learning theory", "efficiently PAC-learnable"], "level": 3, "startpage": 240, "endpage": 240, "topicname": "6.5.5 Surrogate loss functions"}, {"keywordlist": ["support vector machines", "NHST", "statistically signi\ufb01cant", "weak conditionality", "SVM", "con\ufb01dence interval", "negative binomial distribution", "hinge loss", "sufficiency principle", "surrogate loss function", "pathologies", "hingeLossPlot", "type I", "null hypothesis signi\ufb01cance testing", "likelihood principle", "stopping rule", "tail area probability", "Wald interval"], "level": 2, "startpage": 241, "endpage": 246, "topicname": "6.6 Pathologies of frequentist statistics *"}, {"keywordlist": ["con\ufb01dence interval", "Wald interval"], "level": 3, "startpage": 242, "endpage": 242, "topicname": "6.6.1 Counter-intuitive behavior of confidence intervals"}, {"keywordlist": ["NHST", "statistically signi\ufb01cant", "type I", "null hypothesis signi\ufb01cance testing", "tail area probability"], "level": 3, "startpage": 243, "endpage": 243, "topicname": "6.6.2 p-values considered harmful"}, {"keywordlist": ["negative binomial distribution", "sufficiency principle", "likelihood principle", "stopping rule"], "level": 3, "startpage": 244, "endpage": 244, "topicname": "6.6.3 The likelihood principle"}, {"keywordlist": ["weak conditionality"], "level": 3, "startpage": 245, "endpage": 246, "topicname": "6.6.4 Why isn\u2019t everyone a Bayesian?"}, {"keywordlist": ["epigraph", "bayesLinRegDemo2d", "orthogonal projection", "least squares", "huberLossDemo", "NLL", "principal components regression", "sum of squares", "sum of squared errors", "split variable", "linregDemo1", "leastSquaresProjection", "global minimum", "residualsDemo", "noise \ufb02oor", "consistent estimator", "regularization", "strictly convex", "QR decomposition", "convexFnHand", "linear program", "learning curve", "Cholesky decomposition", "robustness", "motes", "negative log likelihood", "penalized least squares", "linregRobustDemoCombined", "Laplace", "linregPostPredDemo", "geomRidge", "residual sum of squares", "(cid:7)2 regularization", "linregBayesCaterpillar", "Huber loss", "ARD", "contoursSSEdemo", "hat matrix", "ordinary least squares", "(cid:7)2orm", "optimization", "linregPolyVsN", "g-prior", "backslash operator", "Simple linear regression", "unit information prior", "concave", "approximation error", "normal equation", "OLS", "weight decay", "active learning", "surfaceFitDemo", "MSE", "structural error"], "level": 1, "startpage": 247, "endpage": 274, "topicname": "7 Linear Regression"}, {"keywordlist": [], "level": 2, "startpage": 247, "endpage": 247, "topicname": "7.1 Introduction"}, {"keywordlist": [], "level": 2, "startpage": 247, "endpage": 247, "topicname": "7.2 Model specification"}, {"keywordlist": ["epigraph", "orthogonal projection", "least squares", "NLL", "sum of squares", "sum of squared errors", "leastSquaresProjection", "global minimum", "residualsDemo", "strictly convex", "convexFnHand", "motes", "negative log likelihood", "residual sum of squares", "contoursSSEdemo", "hat matrix", "ordinary least squares", "(cid:7)2orm", "optimization", "concave", "normal equation", "OLS", "surfaceFitDemo", "MSE"], "level": 2, "startpage": 247, "endpage": 252, "topicname": "7.3 Maximum likelihood estimation (least squares)"}, {"keywordlist": ["least squares", "residualsDemo", "contoursSSEdemo"], "level": 3, "startpage": 249, "endpage": 249, "topicname": "7.3.1 Derivation of the MLE"}, {"keywordlist": ["sum of squares", "ordinary least squares", "normal equation", "OLS"], "level": 3, "startpage": 250, "endpage": 250, "topicname": "7.3.2 Geometric interpretation"}, {"keywordlist": ["epigraph", "orthogonal projection", "leastSquaresProjection", "global minimum", "strictly convex", "convexFnHand", "hat matrix", "concave"], "level": 3, "startpage": 251, "endpage": 252, "topicname": "7.3.3 Convexity"}, {"keywordlist": ["huberLossDemo", "split variable", "linear program", "robustness", "linregRobustDemoCombined", "Laplace", "Huber loss"], "level": 2, "startpage": 253, "endpage": 254, "topicname": "7.4 Robust linear regression *"}, {"keywordlist": ["principal components regression", "noise \ufb02oor", "regularization", "QR decomposition", "learning curve", "Cholesky decomposition", "penalized least squares", "geomRidge", "(cid:7)2 regularization", "backslash operator", "approximation error", "weight decay", "active learning", "structural error"], "level": 2, "startpage": 255, "endpage": 260, "topicname": "7.5 Ridge regression"}, {"keywordlist": ["penalized least squares", "(cid:7)2 regularization", "weight decay"], "level": 3, "startpage": 255, "endpage": 256, "topicname": "7.5.1 Basic idea"}, {"keywordlist": ["regularization", "Cholesky decomposition"], "level": 3, "startpage": 257, "endpage": 257, "topicname": "7.5.2 Numerically stable computation *"}, {"keywordlist": ["QR decomposition", "geomRidge", "backslash operator"], "level": 3, "startpage": 258, "endpage": 259, "topicname": "7.5.3 Connection with PCA *"}, {"keywordlist": ["principal components regression", "noise \ufb02oor", "learning curve", "approximation error", "active learning", "structural error"], "level": 3, "startpage": 260, "endpage": 260, "topicname": "7.5.4 Regularization effects of big data"}, {"keywordlist": ["bayesLinRegDemo2d", "linregDemo1", "consistent estimator", "linregPostPredDemo", "linregBayesCaterpillar", "ARD", "linregPolyVsN", "g-prior", "Simple linear regression", "unit information prior"], "level": 2, "startpage": 261, "endpage": 274, "topicname": "7.6 Bayesian linear regression"}, {"keywordlist": [], "level": 3, "startpage": 262, "endpage": 262, "topicname": "7.6.1 Computing the posterior"}, {"keywordlist": ["bayesLinRegDemo2d", "consistent estimator"], "level": 3, "startpage": 263, "endpage": 263, "topicname": "7.6.2 Computing the posterior predictive"}, {"keywordlist": [], "level": 3, "startpage": 264, "endpage": 264, "topicname": "7.6.3 Bayesian inference when \u03c32 is unknown *"}, {"keywordlist": ["linregDemo1", "linregPostPredDemo", "linregBayesCaterpillar", "ARD", "g-prior", "Simple linear regression", "unit information prior"], "level": 3, "startpage": 264, "endpage": 274, "topicname": "7.6.4 EB for linear regression (evidence procedure)"}, {"keywordlist": ["rocking", "missing completely at random", "MAR", "iteratively reweighted least squares", "logregSATdemoBayes", "momentum", "complete data", "semi-supervised learning", "projection", "moderated output", "LMS", "steepest descent", "error signal", "global convergence", "\ufb01sherLDAdemo", "Quasi-Newton", "stochastic optimization", "steepestDescentDemo", "case analysis", "newtonsMethodNonConvex", "gradient descent", "LMSdemo", "probitRegDemo", "kronecker product", "line search", "Polyak-Ruppert averaging", "residual analysis", "structured-output classi\ufb01cation problems", "truncated Newton", "missing at random", "regret", "qq-plot", "working response", "conjugate gradients", "MCAR", "INDEX TO KEYWORDS Fisher\u2019s linear discriminant analysis", "heteroscedastic LDA", "Robbins-Monro", "Octave, xxviii offline", "energy function", "zig-zag", "linear threshold unit", "Levenberg Marquardt", "early stopping", "Newton\u2019s algorithm", "IRLS", "Occam factor", "Widrow-Hoff rule", "Laplace approximation", "epoch", "perceptron algorithm", "BFGS", "generativeVsDiscrim", "FLDA", "logregFit", "SGD", "newtonsMethodMinQuad", "L-BFGS", "probit", "conditional logit model", "second order", "discriminative", "large margin principle", "step size", "one-of-C encoding", "Taylor\u2019s theorem", "EM", "heavy ball method", "\ufb01sherDiscrimVowelDemo", "simulated annealing", "NMAR", "particle \ufb01ltering", "batch", "Rosenblatt", "saddle point approximation", "Gaussian approximation", "streaming data", "Bayes point", "not missing at random", "sigmoidplot2D", "least mean squares", "logregLaplaceGirolamiDemo", "delta rule", "multiple LDA", "limited memory BFGS", "adagrad", "online gradient descent", "recursive least squares", "generative approach", "mini-batch", "maximum entropy classi\ufb01er", "logregMultinomKernelDemo", "probitPlot", "weighted least squares problem", "generalized eigenvalue", "missing data problem", "cross-entropy", "assumed density \ufb01lter", "schedule", "line minimization", "learning rate", "Taylor series", "loss function"], "level": 1, "startpage": 275, "endpage": 310, "topicname": "8 Logistic Regression"}, {"keywordlist": ["discriminative", "generative approach"], "level": 2, "startpage": 275, "endpage": 275, "topicname": "8.1 Introduction"}, {"keywordlist": ["discriminative", "generative approach"], "level": 2, "startpage": 275, "endpage": 275, "topicname": "8.2 Model specification"}, {"keywordlist": ["iteratively reweighted least squares", "momentum", "steepest descent", "global convergence", "Quasi-Newton", "steepestDescentDemo", "newtonsMethodNonConvex", "gradient descent", "kronecker product", "line search", "truncated Newton", "working response", "conjugate gradients", "zig-zag", "linear threshold unit", "Levenberg Marquardt", "Newton\u2019s algorithm", "IRLS", "BFGS", "newtonsMethodMinQuad", "L-BFGS", "conditional logit model", "second order", "discriminative", "step size", "one-of-C encoding", "Taylor\u2019s theorem", "heavy ball method", "sigmoidplot2D", "limited memory BFGS", "generative approach", "maximum entropy classi\ufb01er", "weighted least squares problem", "cross-entropy", "line minimization", "learning rate"], "level": 2, "startpage": 275, "endpage": 283, "topicname": "8.3 Model fitting"}, {"keywordlist": ["sigmoidplot2D", "cross-entropy"], "level": 3, "startpage": 276, "endpage": 276, "topicname": "8.3.1 MLE"}, {"keywordlist": ["momentum", "steepest descent", "global convergence", "steepestDescentDemo", "gradient descent", "line search", "zig-zag", "step size", "Taylor\u2019s theorem", "line minimization", "learning rate"], "level": 3, "startpage": 277, "endpage": 278, "topicname": "8.3.2 Steepest descent"}, {"keywordlist": ["conjugate gradients", "Newton\u2019s algorithm", "second order", "heavy ball method"], "level": 3, "startpage": 279, "endpage": 279, "topicname": "8.3.3 Newton\u2019s method"}, {"keywordlist": ["newtonsMethodNonConvex", "truncated Newton", "working response", "Levenberg Marquardt", "newtonsMethodMinQuad"], "level": 3, "startpage": 280, "endpage": 280, "topicname": "8.3.4 Iteratively reweighted least squares (IRLS)"}, {"keywordlist": ["iteratively reweighted least squares", "Quasi-Newton", "IRLS", "BFGS", "weighted least squares problem"], "level": 3, "startpage": 281, "endpage": 281, "topicname": "8.3.5 Quasi-Newton (variable metric) methods"}, {"keywordlist": ["linear threshold unit", "L-BFGS", "conditional logit model", "one-of-C encoding", "limited memory BFGS", "maximum entropy classi\ufb01er"], "level": 3, "startpage": 282, "endpage": 282, "topicname": "8.3.6 2e regularization"}, {"keywordlist": ["kronecker product", "linear threshold unit", "L-BFGS", "conditional logit model", "one-of-C encoding", "limited memory BFGS", "maximum entropy classi\ufb01er"], "level": 3, "startpage": 282, "endpage": 283, "topicname": "8.3.7 Multi-class logistic regression"}, {"keywordlist": ["logregSATdemoBayes", "moderated output", "case analysis", "probitRegDemo", "residual analysis", "qq-plot", "energy function", "Occam factor", "Laplace approximation", "logregFit", "probit", "large margin principle", "saddle point approximation", "Gaussian approximation", "Bayes point", "logregLaplaceGirolamiDemo", "probitPlot", "Taylor series"], "level": 2, "startpage": 284, "endpage": 290, "topicname": "8.4 Bayesian logistic regression"}, {"keywordlist": ["energy function", "Occam factor", "Laplace approximation", "saddle point approximation", "Gaussian approximation", "Taylor series"], "level": 3, "startpage": 285, "endpage": 285, "topicname": "8.4.1 Laplace approximation"}, {"keywordlist": ["energy function", "Occam factor", "Laplace approximation", "saddle point approximation", "Gaussian approximation", "Taylor series"], "level": 3, "startpage": 285, "endpage": 285, "topicname": "8.4.2 Derivation of the BIC"}, {"keywordlist": [], "level": 3, "startpage": 286, "endpage": 286, "topicname": "8.4.3 Gaussian approximation for logistic regression"}, {"keywordlist": ["logregSATdemoBayes", "probitRegDemo", "large margin principle", "Bayes point", "logregLaplaceGirolamiDemo", "probitPlot"], "level": 3, "startpage": 286, "endpage": 289, "topicname": "8.4.4 Approximating the posterior predictive"}, {"keywordlist": ["moderated output", "case analysis", "residual analysis", "qq-plot", "probit"], "level": 3, "startpage": 290, "endpage": 290, "topicname": "8.4.5 Residual analysis (outlier detection) *"}, {"keywordlist": ["rocking", "projection", "LMS", "error signal", "stochastic optimization", "LMSdemo", "Polyak-Ruppert averaging", "structured-output classi\ufb01cation problems", "regret", "Robbins-Monro", "Octave, xxviii offline", "early stopping", "Widrow-Hoff rule", "epoch", "perceptron algorithm", "SGD", "simulated annealing", "batch", "Rosenblatt", "streaming data", "least mean squares", "delta rule", "adagrad", "online gradient descent", "recursive least squares", "mini-batch", "schedule", "loss function"], "level": 2, "startpage": 291, "endpage": 296, "topicname": "8.5 Online learning and stochastic optimization"}, {"keywordlist": ["projection", "stochastic optimization", "regret", "SGD", "simulated annealing", "online gradient descent"], "level": 3, "startpage": 292, "endpage": 292, "topicname": "8.5.1 Online learning and regret minimization"}, {"keywordlist": ["projection", "stochastic optimization", "Polyak-Ruppert averaging", "regret", "Robbins-Monro", "early stopping", "SGD", "simulated annealing", "adagrad", "online gradient descent", "schedule"], "level": 3, "startpage": 292, "endpage": 293, "topicname": "8.5.2 Stochastic optimization and risk minimization"}, {"keywordlist": ["epoch", "mini-batch"], "level": 3, "startpage": 294, "endpage": 294, "topicname": "8.5.3 The LMS algorithm"}, {"keywordlist": ["LMS", "error signal", "LMSdemo", "Widrow-Hoff rule", "least mean squares", "delta rule", "recursive least squares"], "level": 3, "startpage": 295, "endpage": 295, "topicname": "8.5.4 The perceptron algorithm"}, {"keywordlist": ["structured-output classi\ufb01cation problems", "perceptron algorithm", "Rosenblatt"], "level": 3, "startpage": 296, "endpage": 296, "topicname": "8.5.5 A Bayesian view"}, {"keywordlist": ["missing completely at random", "MAR", "complete data", "semi-supervised learning", "\ufb01sherLDAdemo", "missing at random", "MCAR", "INDEX TO KEYWORDS Fisher\u2019s linear discriminant analysis", "heteroscedastic LDA", "generativeVsDiscrim", "FLDA", "EM", "\ufb01sherDiscrimVowelDemo", "NMAR", "particle \ufb01ltering", "not missing at random", "multiple LDA", "logregMultinomKernelDemo", "generalized eigenvalue", "missing data problem", "assumed density \ufb01lter"], "level": 2, "startpage": 297, "endpage": 310, "topicname": "8.6 Generative vs discriminative classifiers"}, {"keywordlist": ["semi-supervised learning"], "level": 3, "startpage": 298, "endpage": 298, "topicname": "8.6.1 Pros and cons of each approach"}, {"keywordlist": ["missing completely at random", "MAR", "complete data", "missing at random", "MCAR", "generativeVsDiscrim", "NMAR", "not missing at random", "logregMultinomKernelDemo", "missing data problem"], "level": 3, "startpage": 299, "endpage": 300, "topicname": "8.6.2 Dealing with missing data"}, {"keywordlist": ["\ufb01sherLDAdemo", "INDEX TO KEYWORDS Fisher\u2019s linear discriminant analysis", "heteroscedastic LDA", "FLDA", "EM", "\ufb01sherDiscrimVowelDemo", "multiple LDA", "generalized eigenvalue"], "level": 3, "startpage": 301, "endpage": 310, "topicname": "8.6.3 Fisher\u2019s linear discriminant analysis (FLDA) *"}, {"keywordlist": ["domain adaptation", "personalized spam \ufb01ltering", "natural exponential family", "generalized estimating equations", "calculus of variations", "multi-task feature selection", "log partition function", "dRUM", "weighted approximate-rank pairwise", "NDCG", "language model", "mean reciprocal rank", "Gumbel", "partition function", "ListNet", "semi-parametric model", "curved exponential family", "learning to learn", "utilities", "mean average precision", "GLMM", "GLM", "cumulant function", "poisson regression", "multivariate probit", "PageRank", "\ufb01xed effect", "mean function", "Lagrange multipliers", "RUM", "discounted cumulative gain", "generalized linear models", "Kendall\u2019s", "random effects", "link function", "spline", "Fisher scoring method", "sparsity-promoting prior", "canonical form", "canonical link function", "cumulants", "RankNet", "learning to rank", "query logs", "conjugate priors", "random utility model", "negative transfer", "Pitman-Koopman-Darmois theorem", "generalized linear model", "precision at k", "maxent", "normalized discounted cumulative gain", "mixed model", "generalized linear mixed effects model", "multinomial probit", "minimal", "probit regression", "variational inference", "conjoint analysis", "Plackett-Luce", "neural network", "over-complete", "dispersion parameter", "Bing", "pointwise approach", "surrogate loss", "WARP", "GEE", "log-odds ratio", "Domain adaptation", "binomial regression", "ordinal", "Gibbs distribution", "Rank correlation", "LETOR", "transfer learning", "discrete choice modeling", "average precision"], "level": 1, "startpage": 311, "endpage": 336, "topicname": "9 Generalized Linear Models and the Exponential Family"}, {"keywordlist": ["generalized linear models", "conjugate priors", "generalized linear model", "variational inference"], "level": 2, "startpage": 311, "endpage": 311, "topicname": "9.1 Introduction"}, {"keywordlist": ["natural exponential family", "calculus of variations", "log partition function", "partition function", "curved exponential family", "cumulant function", "Lagrange multipliers", "generalized linear models", "canonical form", "cumulants", "conjugate priors", "Pitman-Koopman-Darmois theorem", "generalized linear model", "maxent", "minimal", "variational inference", "over-complete", "log-odds ratio"], "level": 2, "startpage": 311, "endpage": 319, "topicname": "9.2 The exponential family"}, {"keywordlist": ["natural exponential family", "log partition function", "partition function", "curved exponential family", "cumulant function", "canonical form", "minimal", "over-complete"], "level": 3, "startpage": 312, "endpage": 312, "topicname": "9.2.1 Definition"}, {"keywordlist": ["natural exponential family", "log partition function", "partition function", "curved exponential family", "cumulant function", "canonical form", "minimal", "over-complete", "log-odds ratio"], "level": 3, "startpage": 312, "endpage": 313, "topicname": "9.2.2 Examples"}, {"keywordlist": ["cumulants"], "level": 3, "startpage": 314, "endpage": 315, "topicname": "9.2.3 Log partition function"}, {"keywordlist": ["Pitman-Koopman-Darmois theorem"], "level": 3, "startpage": 316, "endpage": 316, "topicname": "9.2.4 MLE for the exponential family"}, {"keywordlist": [], "level": 3, "startpage": 317, "endpage": 318, "topicname": "9.2.5 Bayes for the exponential family *"}, {"keywordlist": ["calculus of variations", "Lagrange multipliers", "maxent"], "level": 3, "startpage": 319, "endpage": 319, "topicname": "9.2.6 Maximum entropy derivation of the exponential family *"}, {"keywordlist": ["GLM", "poisson regression", "mean function", "link function", "canonical link function", "dispersion parameter", "binomial regression", "Gibbs distribution"], "level": 2, "startpage": 320, "endpage": 322, "topicname": "9.3 Generalized linear models (GLMs)"}, {"keywordlist": ["GLM", "mean function", "link function", "canonical link function", "dispersion parameter", "Gibbs distribution"], "level": 3, "startpage": 320, "endpage": 321, "topicname": "9.3.1 Basics"}, {"keywordlist": ["poisson regression", "binomial regression"], "level": 3, "startpage": 322, "endpage": 322, "topicname": "9.3.2 ML and MAP estimation"}, {"keywordlist": ["Fisher scoring method", "probit regression"], "level": 3, "startpage": 323, "endpage": 323, "topicname": "9.3.3 Bayesian inference"}, {"keywordlist": ["dRUM", "Gumbel", "utilities", "multivariate probit", "RUM", "Fisher scoring method", "random utility model", "multinomial probit", "probit regression", "ordinal"], "level": 2, "startpage": 323, "endpage": 325, "topicname": "9.4 Probit regression"}, {"keywordlist": ["dRUM", "utilities", "RUM", "random utility model"], "level": 3, "startpage": 324, "endpage": 324, "topicname": "9.4.1 ML/MAP estimation using gradient-based optimization"}, {"keywordlist": ["dRUM", "utilities", "RUM", "random utility model"], "level": 3, "startpage": 324, "endpage": 324, "topicname": "9.4.2 Latent variable interpretation"}, {"keywordlist": ["Gumbel", "multivariate probit", "multinomial probit", "ordinal"], "level": 3, "startpage": 325, "endpage": 325, "topicname": "9.4.3 Ordinal probit regression *"}, {"keywordlist": ["Gumbel", "multivariate probit", "multinomial probit", "ordinal"], "level": 3, "startpage": 325, "endpage": 325, "topicname": "9.4.4 Multinomial probit models *"}, {"keywordlist": ["domain adaptation", "personalized spam \ufb01ltering", "multi-task feature selection", "learning to learn", "sparsity-promoting prior", "negative transfer", "conjoint analysis", "Domain adaptation", "transfer learning", "discrete choice modeling"], "level": 2, "startpage": 326, "endpage": 327, "topicname": "9.5 Multi-task learning"}, {"keywordlist": ["personalized spam \ufb01ltering", "learning to learn", "transfer learning", "discrete choice modeling"], "level": 3, "startpage": 326, "endpage": 326, "topicname": "9.5.1 Hierarchical Bayes for multi-task learning"}, {"keywordlist": ["personalized spam \ufb01ltering", "learning to learn", "transfer learning", "discrete choice modeling"], "level": 3, "startpage": 326, "endpage": 326, "topicname": "9.5.2 Application to personalized email spam filtering"}, {"keywordlist": ["domain adaptation", "multi-task feature selection", "sparsity-promoting prior", "negative transfer", "conjoint analysis", "Domain adaptation"], "level": 3, "startpage": 327, "endpage": 327, "topicname": "9.5.3 Application to domain adaptation"}, {"keywordlist": ["domain adaptation", "multi-task feature selection", "sparsity-promoting prior", "negative transfer", "conjoint analysis", "Domain adaptation"], "level": 3, "startpage": 327, "endpage": 327, "topicname": "9.5.4 Other kinds of prior"}, {"keywordlist": ["semi-parametric model", "GLMM", "\ufb01xed effect", "random effects", "spline", "mixed model", "generalized linear mixed effects model"], "level": 2, "startpage": 328, "endpage": 329, "topicname": "9.6 Generalized linear mixed models *"}, {"keywordlist": ["semi-parametric model", "GLMM", "\ufb01xed effect", "random effects", "spline", "mixed model", "generalized linear mixed effects model"], "level": 3, "startpage": 328, "endpage": 329, "topicname": "9.6.1 Example: semi-parametric GLMMs for medical data"}, {"keywordlist": ["generalized estimating equations", "language model", "learning to rank", "GEE", "LETOR"], "level": 3, "startpage": 330, "endpage": 330, "topicname": "9.6.2 Computational issues"}, {"keywordlist": ["generalized estimating equations", "weighted approximate-rank pairwise", "NDCG", "language model", "mean reciprocal rank", "ListNet", "mean average precision", "PageRank", "discounted cumulative gain", "Kendall\u2019s", "RankNet", "learning to rank", "query logs", "precision at k", "normalized discounted cumulative gain", "Plackett-Luce", "neural network", "Bing", "pointwise approach", "surrogate loss", "WARP", "GEE", "Rank correlation", "LETOR", "average precision"], "level": 2, "startpage": 330, "endpage": 336, "topicname": "9.7 Learning to rank *"}, {"keywordlist": ["PageRank", "query logs", "pointwise approach"], "level": 3, "startpage": 331, "endpage": 331, "topicname": "9.7.1 The pointwise approach"}, {"keywordlist": ["PageRank", "query logs", "pointwise approach"], "level": 3, "startpage": 331, "endpage": 331, "topicname": "9.7.2 The pairwise approach"}, {"keywordlist": ["ListNet", "RankNet", "Plackett-Luce", "neural network", "Bing"], "level": 3, "startpage": 332, "endpage": 332, "topicname": "9.7.3 The listwise approach"}, {"keywordlist": ["weighted approximate-rank pairwise", "NDCG", "mean reciprocal rank", "mean average precision", "discounted cumulative gain", "Kendall\u2019s", "precision at k", "normalized discounted cumulative gain", "surrogate loss", "WARP", "Rank correlation", "average precision"], "level": 3, "startpage": 333, "endpage": 336, "topicname": "9.7.4 Loss functions for ranking"}, {"keywordlist": ["alleles", "conditioning case", "alarm network", "GM", "co-parents", "Markov assumption", "path", "sigmoid belief net", "chance nodes", "nodes", "root", "nested plate", "action nodes", "POMDP", "HMM", "BN2O", "value of perfect information", "total ordering", "belief networks", "exchangeable", "non-descendants", "phase", "vertices", "Markov chain", "minimal I-map", "Berkson\u2019s paradox", "parents", "CI", "tree-augmented naive Bayes classi\ufb01er", "plates", "no forgetting", "full conditional", "visible nodes", "second order Markov chain", "haplotype", "utility nodes", "conditional independence", "neighbors", "graph", "v-structure", "marker", "scope", "hidden nodes", "quick medical reference", "probabilistic inference", "expected pro\ufb01t", "decision diagram", "QMR", "belief state MDP", "transition model", "inter-causal reasoning", "genotype", "Markov", "bipartite graph", "Gaussian Bayes net", "subjective probability", "polytree", "Mendelian inheritance", "learning", "collider", "perception-action", "decomposes", "CPTs", "self loops", "local evidence", "hidden variable", "complete", "cycle", "founder model", "conditional probability distribution", "Markov decision process", "phylogenetic HMM", "intensive care unit", "recombination model", "children", "Bayes ball algorithm", "TAN", "inverse problem", "fan-in", "conditional probability tables", "hidden variables", "family", "causal networks", "in-degree", "explaining away", "Markov blanket", "genetic linkage analysis", "maximal clique", "unrolled", "graphical model", "conditioning", "clique", "noisy-OR", "edges", "adjacency matrix", "query variables", "information arc", "in\ufb02uence diagram", "directed local Markov property", "linear Gaussian", "tree", "inheritance model", "leak node", "ordered Markov property", "barren node removal", "loop", "observation model", "pedigree graph", "inference", "clamping", "treewidth", "visualizeAlarmNetwork", "oil wild-catter", "probability of the evidence", "subgraph", "directed", "dynamic programming", "directed graphical model", "ancestors", "genome", "CPD", "undirected", "phenotypes", "degree", "stochastic matrix", "bloodtype", "directed acyclic graph", "MDP", "trail", "I-map", "forest", "out-degree", "Bayesian networks", "descendants", "state transition matrix", "hidden Markov model", "Gibbs sampling", "d-separated", "DGM", "context speci\ufb01c independence", "value nodes", "decision nodes", "nuisance variables", "likelihood", "probabilistic expert system", "marginalizing out", "penetrance model", "syntactic sugar", "state estimation", "Chow-Liu algorithm", "leaf", "topological ordering", "knowledge engineering", "partially observed Markov decision process", "DAG", "visible variables", "variable elimination"], "level": 1, "startpage": 337, "endpage": 366, "topicname": "10 Directed Graphical Models (Bayes Nets)"}, {"keywordlist": ["GM", "Markov assumption", "path", "nodes", "root", "total ordering", "belief networks", "vertices", "Markov chain", "parents", "CI", "conditional independence", "neighbors", "graph", "subjective probability", "polytree", "CPTs", "self loops", "cycle", "conditional probability distribution", "children", "conditional probability tables", "family", "causal networks", "in-degree", "maximal clique", "graphical model", "clique", "edges", "adjacency matrix", "tree", "ordered Markov property", "loop", "subgraph", "directed", "directed graphical model", "ancestors", "CPD", "undirected", "degree", "stochastic matrix", "directed acyclic graph", "trail", "forest", "out-degree", "Bayesian networks", "descendants", "state transition matrix", "DGM", "leaf", "topological ordering", "DAG"], "level": 2, "startpage": 337, "endpage": 340, "topicname": "10.1 Introduction"}, {"keywordlist": ["stochastic matrix"], "level": 3, "startpage": 337, "endpage": 337, "topicname": "10.1.1 Chain rule"}, {"keywordlist": ["GM", "Markov assumption", "Markov chain", "CI", "conditional independence", "CPTs", "conditional probability distribution", "conditional probability tables", "graphical model", "CPD", "state transition matrix"], "level": 3, "startpage": 338, "endpage": 338, "topicname": "10.1.2 Conditional independence"}, {"keywordlist": ["GM", "Markov assumption", "Markov chain", "CI", "conditional independence", "CPTs", "conditional probability distribution", "conditional probability tables", "graphical model", "CPD", "state transition matrix"], "level": 3, "startpage": 338, "endpage": 338, "topicname": "10.1.3 Graphical models"}, {"keywordlist": ["nodes", "root", "vertices", "parents", "neighbors", "graph", "self loops", "children", "family", "edges", "adjacency matrix", "directed", "ancestors", "undirected", "descendants", "leaf"], "level": 3, "startpage": 339, "endpage": 339, "topicname": "10.1.4 Graph terminology"}, {"keywordlist": ["path", "total ordering", "belief networks", "subjective probability", "polytree", "cycle", "causal networks", "in-degree", "maximal clique", "clique", "tree", "ordered Markov property", "loop", "subgraph", "directed graphical model", "degree", "directed acyclic graph", "trail", "forest", "out-degree", "Bayesian networks", "DGM", "topological ordering", "DAG"], "level": 3, "startpage": 340, "endpage": 340, "topicname": "10.1.5 Directed graphical models"}, {"keywordlist": ["alleles", "alarm network", "sigmoid belief net", "HMM", "BN2O", "phase", "tree-augmented naive Bayes classi\ufb01er", "visible nodes", "second order Markov chain", "haplotype", "marker", "hidden nodes", "quick medical reference", "QMR", "transition model", "genotype", "bipartite graph", "Gaussian Bayes net", "Mendelian inheritance", "local evidence", "hidden variable", "founder model", "phylogenetic HMM", "intensive care unit", "recombination model", "TAN", "inverse problem", "fan-in", "genetic linkage analysis", "noisy-OR", "linear Gaussian", "inheritance model", "leak node", "observation model", "pedigree graph", "visualizeAlarmNetwork", "genome", "phenotypes", "bloodtype", "hidden Markov model", "probabilistic expert system", "penetrance model", "state estimation", "Chow-Liu algorithm", "knowledge engineering", "variable elimination"], "level": 2, "startpage": 341, "endpage": 348, "topicname": "10.2 Examples"}, {"keywordlist": [], "level": 3, "startpage": 341, "endpage": 341, "topicname": "10.2.1 Naive Bayes classifiers"}, {"keywordlist": ["HMM", "tree-augmented naive Bayes classi\ufb01er", "second order Markov chain", "transition model", "hidden variable", "TAN", "observation model", "hidden Markov model", "Chow-Liu algorithm"], "level": 3, "startpage": 342, "endpage": 342, "topicname": "10.2.2 Markov and hidden Markov models"}, {"keywordlist": ["alarm network", "sigmoid belief net", "visible nodes", "hidden nodes", "quick medical reference", "QMR", "bipartite graph", "intensive care unit", "fan-in", "noisy-OR", "visualizeAlarmNetwork", "probabilistic expert system", "state estimation", "knowledge engineering"], "level": 3, "startpage": 343, "endpage": 344, "topicname": "10.2.3 Medical diagnosis"}, {"keywordlist": ["alleles", "BN2O", "phase", "haplotype", "marker", "genotype", "Mendelian inheritance", "local evidence", "founder model", "phylogenetic HMM", "recombination model", "inverse problem", "genetic linkage analysis", "inheritance model", "leak node", "pedigree graph", "phenotypes", "bloodtype", "penetrance model"], "level": 3, "startpage": 345, "endpage": 347, "topicname": "10.2.4 Genetic linkage analysis *"}, {"keywordlist": ["Gaussian Bayes net", "linear Gaussian", "genome", "variable elimination"], "level": 3, "startpage": 348, "endpage": 348, "topicname": "10.2.5 Directed Gaussian graphical models *"}, {"keywordlist": ["probabilistic inference", "hidden variables", "conditioning", "clamping", "probability of the evidence", "likelihood", "visible variables"], "level": 2, "startpage": 349, "endpage": 349, "topicname": "10.3 Inference"}, {"keywordlist": ["conditioning case", "nested plate", "exchangeable", "plates", "learning", "decomposes", "complete", "unrolled", "query variables", "inference", "treewidth", "context speci\ufb01c independence", "nuisance variables", "marginalizing out", "syntactic sugar"], "level": 2, "startpage": 350, "endpage": 353, "topicname": "10.4 Learning"}, {"keywordlist": ["nested plate", "exchangeable", "plates", "learning", "unrolled", "query variables", "inference", "treewidth", "context speci\ufb01c independence", "nuisance variables", "marginalizing out", "syntactic sugar"], "level": 3, "startpage": 350, "endpage": 351, "topicname": "10.4.1 Plate notation"}, {"keywordlist": ["conditioning case", "decomposes", "complete"], "level": 3, "startpage": 352, "endpage": 352, "topicname": "10.4.2 Learning from complete data"}, {"keywordlist": [], "level": 3, "startpage": 353, "endpage": 353, "topicname": "10.4.3 Learning with missing and/or latent variables"}, {"keywordlist": ["co-parents", "non-descendants", "minimal I-map", "Berkson\u2019s paradox", "v-structure", "inter-causal reasoning", "Markov", "collider", "Bayes ball algorithm", "explaining away", "Markov blanket", "directed local Markov property", "I-map", "d-separated"], "level": 2, "startpage": 354, "endpage": 357, "topicname": "10.5 Conditional independence properties of DGMs"}, {"keywordlist": ["minimal I-map", "Berkson\u2019s paradox", "v-structure", "inter-causal reasoning", "Markov", "collider", "Bayes ball algorithm", "explaining away", "I-map", "d-separated"], "level": 3, "startpage": 354, "endpage": 356, "topicname": "10.5.1 d-separation and the Bayes Ball algorithm (global Markov properties)"}, {"keywordlist": ["co-parents", "non-descendants", "Markov blanket", "directed local Markov property"], "level": 3, "startpage": 357, "endpage": 357, "topicname": "10.5.2 Other Markov properties of DGMs"}, {"keywordlist": ["co-parents", "non-descendants", "Markov blanket", "directed local Markov property"], "level": 3, "startpage": 357, "endpage": 357, "topicname": "10.5.3 Markov blanket and full conditionals"}, {"keywordlist": ["chance nodes", "action nodes", "POMDP", "value of perfect information", "no forgetting", "full conditional", "utility nodes", "scope", "expected pro\ufb01t", "decision diagram", "belief state MDP", "perception-action", "Markov decision process", "information arc", "in\ufb02uence diagram", "barren node removal", "oil wild-catter", "dynamic programming", "MDP", "Gibbs sampling", "value nodes", "decision nodes", "partially observed Markov decision process"], "level": 2, "startpage": 358, "endpage": 366, "topicname": "10.6 Influence (decision) diagrams *"}, {"keywordlist": ["birth moves", "forwards model", "visible", "expected sufficient statistics", "standardized", "mixGaussPlotDemo", "data augmentation", "vector quantization", "Gaussian scale mixture", "k-means++", "incremental EM", "image compression", "generalized EM", "Gaussian mixture model", "Censored regression", "expected complete data log likelihood", "VQ", "ECM", "Student t", "death moves", "gap statistic", "emLogLikelihoodMax", "ECME", "E step", "triangle inequality", "mixexpDemo", "end effector", "GMM", "label switching", "kmeansModelSel1d", "stochastic approximation", "overrelaxed EM algorithm", "mixture density network", "stochastic EM", "genetic algorithms", "interval censored", "mixGaussMLvsMAP", "MM", "hard EM", "mixture of Gaussians", "weighted least squares", "multiple random restarts", "mixBerMnistEM", "right censored", "deterministic annealing", "inverse problems", "M step", "knee", "kmeansYeastDemo", "linregCensoredSchmeeHahnDemo", "Monte Carlo EM", "varEMbound", "K-means algorithm", "prototype", "vqDemo", "mixexpDemoOneToMany", "auxiliary function", "black-box", "kinematic tracking", "lossy compression", "truncated Gaussian", "reconstruction error", "rate", "Tobit model", "modularity, xxviii MoE", "stepwise EM", "responsibility", "LVM", "distortion", "hard clustering", "hierarchical mixture of experts", "identi\ufb01able", "reversible jump MCMC", "gaussMissingFitEm", "kink", "soft clustering", "GEM", "censored regression", "online EM", "expectation maximization", "complete data log likelihood", "digamma", "bound optimization", "mixStudentBankruptcyDemo", "observed data log likelihood", "centroid", "neural networks", "stochastic approximation EM", "minorize-maximize", "base distribution", "family marginal", "mixGaussDemoFaithful", "mixture of experts", "codebook", "left censored", "gating function", "farthest point clustering", "probabilistic matrix factorization", "mixGaussLikSurfaceDemo", "mixGaussSingularity", "latent variable models", "mixGaussOverRelaxedEmDemo", "hierarchical Bayesian models", "variational EM", "MCEM"], "level": 1, "startpage": 367, "endpage": 410, "topicname": "11 Mixture Models and the EM Algorithm"}, {"keywordlist": ["LVM", "probabilistic matrix factorization", "latent variable models"], "level": 2, "startpage": 367, "endpage": 367, "topicname": "11.1 Latent variable models"}, {"keywordlist": ["mixGaussPlotDemo", "Gaussian mixture model", "mixexpDemo", "end effector", "GMM", "label switching", "mixture density network", "mixture of Gaussians", "mixBerMnistEM", "inverse problems", "kmeansYeastDemo", "prototype", "mixexpDemoOneToMany", "black-box", "kinematic tracking", "modularity, xxviii MoE", "responsibility", "LVM", "hard clustering", "hierarchical mixture of experts", "soft clustering", "centroid", "neural networks", "base distribution", "mixture of experts", "gating function", "probabilistic matrix factorization", "latent variable models"], "level": 2, "startpage": 367, "endpage": 374, "topicname": "11.2 Mixture models"}, {"keywordlist": ["mixGaussPlotDemo", "Gaussian mixture model", "GMM", "mixture of Gaussians"], "level": 3, "startpage": 369, "endpage": 369, "topicname": "11.2.1 Mixtures of Gaussians"}, {"keywordlist": ["black-box", "responsibility", "hard clustering", "soft clustering"], "level": 3, "startpage": 370, "endpage": 370, "topicname": "11.2.2 Mixture of multinoullis"}, {"keywordlist": ["label switching", "mixBerMnistEM", "kmeansYeastDemo", "prototype", "black-box", "responsibility", "hard clustering", "soft clustering", "centroid"], "level": 3, "startpage": 370, "endpage": 371, "topicname": "11.2.3 Using mixture models for clustering"}, {"keywordlist": ["mixexpDemo", "end effector", "mixture density network", "inverse problems", "mixexpDemoOneToMany", "kinematic tracking", "modularity, xxviii MoE", "hierarchical mixture of experts", "neural networks", "mixture of experts", "gating function"], "level": 3, "startpage": 372, "endpage": 374, "topicname": "11.2.4 Mixtures of experts"}, {"keywordlist": ["forwards model", "identi\ufb01able", "mixGaussLikSurfaceDemo", "hierarchical Bayesian models"], "level": 2, "startpage": 375, "endpage": 377, "topicname": "11.3 Parameter estimation for mixture models"}, {"keywordlist": ["identi\ufb01able", "mixGaussLikSurfaceDemo"], "level": 3, "startpage": 376, "endpage": 376, "topicname": "11.3.1 Unidentifiability"}, {"keywordlist": ["hierarchical Bayesian models"], "level": 3, "startpage": 377, "endpage": 377, "topicname": "11.3.2 Computing a MAP estimate is non-convex"}, {"keywordlist": ["visible", "expected sufficient statistics", "standardized", "data augmentation", "vector quantization", "Gaussian scale mixture", "k-means++", "incremental EM", "image compression", "generalized EM", "expected complete data log likelihood", "VQ", "ECM", "Student t", "emLogLikelihoodMax", "ECME", "E step", "triangle inequality", "stochastic approximation", "overrelaxed EM algorithm", "stochastic EM", "genetic algorithms", "mixGaussMLvsMAP", "MM", "hard EM", "weighted least squares", "multiple random restarts", "deterministic annealing", "M step", "Monte Carlo EM", "varEMbound", "K-means algorithm", "vqDemo", "auxiliary function", "lossy compression", "truncated Gaussian", "reconstruction error", "rate", "stepwise EM", "distortion", "GEM", "online EM", "expectation maximization", "complete data log likelihood", "digamma", "bound optimization", "mixStudentBankruptcyDemo", "observed data log likelihood", "stochastic approximation EM", "minorize-maximize", "family marginal", "mixGaussDemoFaithful", "codebook", "farthest point clustering", "mixGaussSingularity", "mixGaussOverRelaxedEmDemo", "variational EM", "MCEM"], "level": 2, "startpage": 378, "endpage": 399, "topicname": "11.4 The EM algorithm"}, {"keywordlist": ["visible", "expectation maximization"], "level": 3, "startpage": 379, "endpage": 379, "topicname": "11.4.1 Basic idea"}, {"keywordlist": ["expected sufficient statistics", "standardized", "vector quantization", "k-means++", "image compression", "expected complete data log likelihood", "VQ", "E step", "triangle inequality", "mixGaussMLvsMAP", "hard EM", "M step", "K-means algorithm", "vqDemo", "auxiliary function", "lossy compression", "reconstruction error", "rate", "distortion", "mixGaussDemoFaithful", "codebook", "farthest point clustering", "mixGaussSingularity"], "level": 3, "startpage": 380, "endpage": 386, "topicname": "11.4.2 EM for GMMs"}, {"keywordlist": [], "level": 3, "startpage": 387, "endpage": 387, "topicname": "11.4.3 EM for mixture of experts"}, {"keywordlist": ["weighted least squares"], "level": 3, "startpage": 388, "endpage": 388, "topicname": "11.4.4 EM for DGMs with hidden variables"}, {"keywordlist": ["Gaussian scale mixture", "generalized EM", "Student t", "digamma", "mixStudentBankruptcyDemo", "family marginal"], "level": 3, "startpage": 389, "endpage": 391, "topicname": "11.4.5 EM for the Student distribution *"}, {"keywordlist": ["data augmentation", "truncated Gaussian"], "level": 3, "startpage": 392, "endpage": 392, "topicname": "11.4.6 EM for probit regression *"}, {"keywordlist": [], "level": 3, "startpage": 393, "endpage": 394, "topicname": "11.4.7 Theoretical basis for EM *"}, {"keywordlist": ["incremental EM", "emLogLikelihoodMax", "stepwise EM", "online EM"], "level": 3, "startpage": 395, "endpage": 396, "topicname": "11.4.8 Online EM"}, {"keywordlist": ["ECM", "ECME", "stochastic approximation", "overrelaxed EM algorithm", "stochastic EM", "MM", "deterministic annealing", "Monte Carlo EM", "varEMbound", "GEM", "bound optimization", "stochastic approximation EM", "minorize-maximize", "mixGaussOverRelaxedEmDemo", "variational EM", "MCEM"], "level": 3, "startpage": 397, "endpage": 399, "topicname": "11.4.9 Other EM variants *"}, {"keywordlist": ["birth moves", "death moves", "kmeansModelSel1d", "reversible jump MCMC"], "level": 2, "startpage": 400, "endpage": 401, "topicname": "11.5 Model selection for latent variable models"}, {"keywordlist": ["birth moves", "death moves", "reversible jump MCMC"], "level": 3, "startpage": 400, "endpage": 400, "topicname": "11.5.1 Model selection for probabilistic models"}, {"keywordlist": ["birth moves", "death moves", "kmeansModelSel1d", "reversible jump MCMC"], "level": 3, "startpage": 400, "endpage": 401, "topicname": "11.5.2 Model selection for non-probabilistic methods"}, {"keywordlist": ["Censored regression", "gap statistic", "interval censored", "right censored", "knee", "linregCensoredSchmeeHahnDemo", "Tobit model", "gaussMissingFitEm", "kink", "censored regression", "left censored"], "level": 2, "startpage": 402, "endpage": 410, "topicname": "11.6 Fitting models with missing data"}, {"keywordlist": ["Censored regression", "interval censored", "right censored", "linregCensoredSchmeeHahnDemo", "Tobit model", "gaussMissingFitEm", "censored regression", "left censored"], "level": 3, "startpage": 403, "endpage": 410, "topicname": "11.6.1 EM for the MLE of an MVN with missing data"}, {"keywordlist": ["icaDemo", "singular values", "skewness", "ppcaDemo2d", "infomax", "negentropy", "blind signal separation", "pcaDemo2d", "subSuperGaussPlot", "platykurtic", "supervised PCA", "factor loading matrix", "mixture of factor analysers", "varimax", "biplot", "scree plot", "Canonical correlation analysis", "scores", "PPCA", "Lanczos algorithm", "kurtosis", "cocktail party problem", "principal component", "leptokurtic", "factors", "Frobenius norm", "multi-information", "de\ufb02ated matrix", "probabilistic principal components analysis", "thin SVD", "icaDemoUniform", "sensible PCA", "Zellner\u2019s g-prior", "Karhunen Loeve", "pcaDemoHeightWeight", "Hinton diagrams", "super-Gaussian", "fraction of variance explained", "generative weights", "Bayesian factor regression", "recognition weights", "ICA", "data fusion", "founder variables", "semi-supervised", "mixPpcaDemoNetlab", "economy sized SVD", "logistic distribution", "latent semantic indexing", "whitening", "truncated SVD", "faBiplotDemo", "information bottleneck", "CCA", "sub-Gaussian", "categorical PCA", "pcaOver\ufb01tDemo", "pcaPmtk", "central moment", "projection pursuit", "partial least squares", "mixing matrix", "independent component analysis", "singular value decomposition", "FA", "blind source separation", "pro\ufb01le log likelihood", "simple cells", "factor analysis", "analysis view", "logistic normal", "probabilistic PCA", "natural gradient", "svdImageDemo", "fast ICA", "PLS", "lsiCode", "binaryFaDemoTipping", "synthesis view", "pcaEmStepByStep", "wavelet transforms"], "level": 1, "startpage": 411, "endpage": 450, "topicname": "12 Latent Linear Models"}, {"keywordlist": ["factor loading matrix", "mixture of factor analysers", "varimax", "biplot", "scores", "PPCA", "factors", "probabilistic principal components analysis", "ICA", "founder variables", "mixPpcaDemoNetlab", "faBiplotDemo", "FA", "factor analysis"], "level": 2, "startpage": 411, "endpage": 416, "topicname": "12.1 Factor analysis"}, {"keywordlist": ["factor loading matrix", "PPCA", "probabilistic principal components analysis", "FA", "factor analysis"], "level": 3, "startpage": 411, "endpage": 411, "topicname": "12.1.1 FA is a low rank parameterization of an MVN"}, {"keywordlist": ["scores", "factors"], "level": 3, "startpage": 412, "endpage": 412, "topicname": "12.1.2 Inference of the latent factors"}, {"keywordlist": ["biplot", "faBiplotDemo"], "level": 3, "startpage": 413, "endpage": 414, "topicname": "12.1.3 Unidentifiability"}, {"keywordlist": ["varimax", "ICA", "founder variables"], "level": 3, "startpage": 415, "endpage": 415, "topicname": "12.1.4 Mixtures of factor analysers"}, {"keywordlist": ["mixture of factor analysers", "mixPpcaDemoNetlab"], "level": 3, "startpage": 416, "endpage": 416, "topicname": "12.1.5 EM for factor analysis models"}, {"keywordlist": ["sensible PCA", "Karhunen Loeve", "probabilistic PCA", "synthesis view"], "level": 3, "startpage": 417, "endpage": 417, "topicname": "12.1.6 Fitting FA models with missing data"}, {"keywordlist": ["singular values", "ppcaDemo2d", "pcaDemo2d", "principal component", "Frobenius norm", "thin SVD", "sensible PCA", "Karhunen Loeve", "pcaDemoHeightWeight", "economy sized SVD", "truncated SVD", "pcaPmtk", "singular value decomposition", "analysis view", "probabilistic PCA", "svdImageDemo", "synthesis view", "pcaEmStepByStep"], "level": 2, "startpage": 417, "endpage": 427, "topicname": "12.2 Principal components analysis (PCA)"}, {"keywordlist": ["ppcaDemo2d", "pcaDemo2d", "principal component", "Frobenius norm", "sensible PCA", "Karhunen Loeve", "probabilistic PCA", "synthesis view"], "level": 3, "startpage": 417, "endpage": 418, "topicname": "12.2.1 Classical PCA: statement of the theorem"}, {"keywordlist": ["pcaDemoHeightWeight", "analysis view"], "level": 3, "startpage": 419, "endpage": 421, "topicname": "12.2.2 Proof *"}, {"keywordlist": ["singular values", "thin SVD", "economy sized SVD", "truncated SVD", "pcaPmtk", "singular value decomposition", "svdImageDemo"], "level": 3, "startpage": 422, "endpage": 424, "topicname": "12.2.3 Singular value decomposition (SVD)"}, {"keywordlist": [], "level": 3, "startpage": 425, "endpage": 425, "topicname": "12.2.4 Probabilistic PCA"}, {"keywordlist": ["pcaEmStepByStep"], "level": 3, "startpage": 426, "endpage": 427, "topicname": "12.2.5 EM algorithm for PCA"}, {"keywordlist": ["scree plot", "Lanczos algorithm", "Hinton diagrams", "fraction of variance explained", "pcaOver\ufb01tDemo", "pro\ufb01le log likelihood"], "level": 2, "startpage": 428, "endpage": 431, "topicname": "12.3 Choosing the number of latent dimensions"}, {"keywordlist": ["Lanczos algorithm"], "level": 3, "startpage": 428, "endpage": 428, "topicname": "12.3.1 Model selection for FA/PPCA"}, {"keywordlist": ["scree plot", "Hinton diagrams", "fraction of variance explained", "pcaOver\ufb01tDemo", "pro\ufb01le log likelihood"], "level": 3, "startpage": 429, "endpage": 431, "topicname": "12.3.2 Model selection for PCA"}, {"keywordlist": ["categorical PCA", "logistic normal", "binaryFaDemoTipping"], "level": 2, "startpage": 432, "endpage": 433, "topicname": "12.4 PCA for categorical data"}, {"keywordlist": ["supervised PCA", "Zellner\u2019s g-prior", "Bayesian factor regression", "data fusion", "semi-supervised", "information bottleneck", "partial least squares", "PLS"], "level": 2, "startpage": 434, "endpage": 436, "topicname": "12.5 PCA for paired and multi-view data"}, {"keywordlist": ["supervised PCA", "Zellner\u2019s g-prior", "Bayesian factor regression", "semi-supervised", "information bottleneck"], "level": 3, "startpage": 435, "endpage": 435, "topicname": "12.5.1 Supervised PCA (latent factor regression)"}, {"keywordlist": ["partial least squares", "PLS"], "level": 3, "startpage": 436, "endpage": 436, "topicname": "12.5.2 Partial least squares"}, {"keywordlist": ["blind signal separation", "Canonical correlation analysis", "cocktail party problem", "CCA", "blind source separation"], "level": 3, "startpage": 437, "endpage": 437, "topicname": "12.5.3 Canonical correlation analysis"}, {"keywordlist": ["icaDemo", "skewness", "infomax", "negentropy", "blind signal separation", "subSuperGaussPlot", "platykurtic", "Canonical correlation analysis", "kurtosis", "cocktail party problem", "leptokurtic", "multi-information", "de\ufb02ated matrix", "icaDemoUniform", "super-Gaussian", "generative weights", "recognition weights", "logistic distribution", "latent semantic indexing", "whitening", "CCA", "sub-Gaussian", "central moment", "projection pursuit", "mixing matrix", "independent component analysis", "blind source separation", "simple cells", "natural gradient", "fast ICA", "lsiCode", "wavelet transforms"], "level": 2, "startpage": 437, "endpage": 450, "topicname": "12.6 Independent Component Analysis (ICA)"}, {"keywordlist": ["generative weights", "recognition weights", "whitening"], "level": 3, "startpage": 440, "endpage": 440, "topicname": "12.6.1 Maximum likelihood estimation"}, {"keywordlist": ["skewness", "subSuperGaussPlot", "platykurtic", "kurtosis", "leptokurtic", "super-Gaussian", "logistic distribution", "sub-Gaussian", "central moment", "simple cells", "natural gradient", "fast ICA", "wavelet transforms"], "level": 3, "startpage": 441, "endpage": 443, "topicname": "12.6.2 The FastICA algorithm"}, {"keywordlist": [], "level": 3, "startpage": 444, "endpage": 444, "topicname": "12.6.3 Using EM"}, {"keywordlist": ["infomax", "negentropy", "multi-information", "de\ufb02ated matrix", "latent semantic indexing", "projection pursuit", "lsiCode"], "level": 3, "startpage": 445, "endpage": 450, "topicname": "12.6.4 Other estimation principles *"}, {"keywordlist": ["forwards selection", "gene microarrays", "array CGH", "stability selection", "least squares boosting", "projected gradient descent", "\ufb01elds of experts", "iterative soft thresholding", "subgradient", "elastic net", "beam search", "Gray code", "inclusion probabilities", "graph-guided fused lasso", "LARS", "factorial prior", "forwards-backwards algorithm", "Active set", "subderivative", "non-negative sparse coding", "sparseSensingDemo", "NMF", "prostateComparison", "non-negative matrix factorization", "lasso", "Bayesian lasso", "small N large D", "quadratic program", "sparsePostPlot", "linregAllsubsetsGraycodeDemo", "translation invariant", "support", "bolassoDemo", "box constraints", "inverse Gaussian", "warm starting", "overcomplete", "bridge regression", "Fourier basis", "lassoPathProstate", "LassoShooting", "SBL", "regularization path", "fused lasso", "exponential power distribution", "bootstrap resampling", "binary mask", "hard thresholding", "bootstrap lasso", "linregFitL1Test", "beta process", "Backwards selection", "basis functions", "linregPolyLassoDemo", "icaBasisDemo", "sparse Bayesian learning", "proximal operator", "soft thresholding", "sparse coding", "(cid:7)0 pseudo-norm", "homotopy", "median model", "FISTA", "(cid:7)0 regularization", "evolutionary MCMC", "BPDN", "subdifferential", "wrapper method", "normalGammaThresholdPlotDemo", "relevance vector machine", "analysis-synthesis", "non-smooth", "sparse PCA", "continuation method", "sparse kernel machine", "basic feasible solution", "ridgePathProstate", "sparseDictDemo", "model selection consistent", "Bernoulli-Gaussian", "spectral", "active set", "Barzilai-Borwein", "sparse matrix factorization", "compressive sensing", "generalized t distribution", "adaptive lasso", "debiasing", "signal processing", "automatic relevance determination", "non-factorial", "SpaRSA", "group lasso", "QP", "atom", "subgradientPlot", "glmnet", "Nesterov\u2019s method", "orthogonal matching pursuits", "LAR", "besselk", "basis pursuit denoising", "interaction effects", "stochastic search", "DCT", "groupLassoDemo", "hierarchical adaptive lasso", "compressed sensing", "grouping effect", "orthogonal least squares", "dictionary", "spike and slab", "image denoising", "normalGammaPenaltyPlotDemo", "OMP", "sparse representation", "prostateSubsets", "matching pursuits", "wavelet", "shrinkage factor", "normal Gamma", "single best replacement", "double Pareto distribution", "bolasso", "(cid:7)1 regularization", "Wald", "shooting", "saturated model"], "level": 1, "startpage": 451, "endpage": 508, "topicname": "13 Sparse Linear Models"}, {"keywordlist": ["gene microarrays", "small N large D", "basis functions", "sparse kernel machine", "signal processing", "interaction effects", "sparse representation"], "level": 2, "startpage": 451, "endpage": 451, "topicname": "13.1 Introduction"}, {"keywordlist": ["forwards selection", "least squares boosting", "beam search", "Gray code", "inclusion probabilities", "forwards-backwards algorithm", "linregAllsubsetsGraycodeDemo", "support", "binary mask", "Backwards selection", "(cid:7)0 pseudo-norm", "median model", "(cid:7)0 regularization", "wrapper method", "Bernoulli-Gaussian", "orthogonal matching pursuits", "orthogonal least squares", "spike and slab", "OMP", "prostateSubsets", "matching pursuits", "single best replacement", "saturated model"], "level": 2, "startpage": 452, "endpage": 458, "topicname": "13.2 Bayesian variable selection"}, {"keywordlist": ["(cid:7)0 pseudo-norm", "spike and slab"], "level": 3, "startpage": 454, "endpage": 454, "topicname": "13.2.1 The spike and slab model"}, {"keywordlist": [], "level": 3, "startpage": 455, "endpage": 455, "topicname": "13.2.2 From the Bernoulli-Gaussian model to \u00040 regularization"}, {"keywordlist": ["forwards selection", "least squares boosting", "beam search", "forwards-backwards algorithm", "support", "binary mask", "Backwards selection", "(cid:7)0 regularization", "wrapper method", "Bernoulli-Gaussian", "orthogonal matching pursuits", "orthogonal least squares", "OMP", "prostateSubsets", "matching pursuits", "single best replacement", "saturated model"], "level": 3, "startpage": 456, "endpage": 458, "topicname": "13.2.3 Algorithms"}, {"keywordlist": ["stability selection", "subgradient", "elastic net", "LARS", "subderivative", "sparseSensingDemo", "prostateComparison", "lasso", "quadratic program", "bolassoDemo", "lassoPathProstate", "regularization path", "bootstrap resampling", "hard thresholding", "bootstrap lasso", "linregPolyLassoDemo", "soft thresholding", "evolutionary MCMC", "BPDN", "subdifferential", "non-smooth", "ridgePathProstate", "model selection consistent", "debiasing", "QP", "subgradientPlot", "basis pursuit denoising", "stochastic search", "shrinkage factor", "bolasso", "(cid:7)1 regularization"], "level": 2, "startpage": 459, "endpage": 470, "topicname": "13.3 e1 regularization: basics"}, {"keywordlist": ["BPDN", "basis pursuit denoising", "(cid:7)1 regularization"], "level": 3, "startpage": 460, "endpage": 460, "topicname": "13.3.1 Why does e1 regularization yield sparse solutions?"}, {"keywordlist": ["subgradient", "subderivative", "lasso", "quadratic program", "hard thresholding", "soft thresholding", "subdifferential", "non-smooth", "QP", "subgradientPlot"], "level": 3, "startpage": 461, "endpage": 464, "topicname": "13.3.2 Optimality conditions for lasso"}, {"keywordlist": [], "level": 3, "startpage": 465, "endpage": 465, "topicname": "13.3.3 Comparison of least squares, lasso, ridge and subset selection"}, {"keywordlist": ["elastic net", "LARS", "sparseSensingDemo", "prostateComparison", "lassoPathProstate", "regularization path", "linregPolyLassoDemo", "ridgePathProstate", "shrinkage factor"], "level": 3, "startpage": 466, "endpage": 468, "topicname": "13.3.4 Regularization path"}, {"keywordlist": ["stability selection", "bootstrap resampling", "bootstrap lasso", "model selection consistent", "debiasing", "bolasso"], "level": 3, "startpage": 469, "endpage": 469, "topicname": "13.3.5 Model selection"}, {"keywordlist": ["bolassoDemo"], "level": 3, "startpage": 470, "endpage": 470, "topicname": "13.3.6 Bayesian inference for linear models with Laplace priors"}, {"keywordlist": ["projected gradient descent", "iterative soft thresholding", "Active set", "Bayesian lasso", "box constraints", "inverse Gaussian", "warm starting", "LassoShooting", "linregFitL1Test", "proximal operator", "homotopy", "FISTA", "continuation method", "spectral", "active set", "Barzilai-Borwein", "SpaRSA", "glmnet", "Nesterov\u2019s method", "LAR", "Wald", "shooting"], "level": 2, "startpage": 471, "endpage": 478, "topicname": "13.4 e1 regularization: algorithms"}, {"keywordlist": ["Active set", "LassoShooting", "shooting"], "level": 3, "startpage": 471, "endpage": 471, "topicname": "13.4.1 Coordinate descent"}, {"keywordlist": ["Active set", "LassoShooting", "shooting"], "level": 3, "startpage": 471, "endpage": 471, "topicname": "13.4.2 LARS and other homotopy methods"}, {"keywordlist": ["projected gradient descent", "iterative soft thresholding", "box constraints", "warm starting", "proximal operator", "homotopy", "FISTA", "continuation method", "spectral", "active set", "Barzilai-Borwein", "SpaRSA", "glmnet", "Nesterov\u2019s method", "LAR"], "level": 3, "startpage": 472, "endpage": 476, "topicname": "13.4.3 Proximal and gradient projection methods"}, {"keywordlist": ["Bayesian lasso", "inverse Gaussian", "linregFitL1Test", "Wald"], "level": 3, "startpage": 477, "endpage": 478, "topicname": "13.4.4 EM for lasso"}, {"keywordlist": ["array CGH", "graph-guided fused lasso", "fused lasso", "group lasso", "groupLassoDemo", "grouping effect"], "level": 2, "startpage": 479, "endpage": 486, "topicname": "13.5 e1 regularization: extensions"}, {"keywordlist": ["group lasso", "groupLassoDemo"], "level": 3, "startpage": 479, "endpage": 483, "topicname": "13.5.1 Group Lasso"}, {"keywordlist": ["array CGH", "graph-guided fused lasso", "fused lasso"], "level": 3, "startpage": 484, "endpage": 484, "topicname": "13.5.2 Fused lasso"}, {"keywordlist": ["grouping effect"], "level": 3, "startpage": 485, "endpage": 486, "topicname": "13.5.3 Elastic net (ridge and lasso combined)"}, {"keywordlist": ["sparsePostPlot", "bridge regression", "exponential power distribution", "normalGammaThresholdPlotDemo", "generalized t distribution", "adaptive lasso", "hierarchical adaptive lasso", "normalGammaPenaltyPlotDemo", "double Pareto distribution"], "level": 2, "startpage": 487, "endpage": 492, "topicname": "13.6 Non-convex regularizers"}, {"keywordlist": ["bridge regression", "exponential power distribution", "hierarchical adaptive lasso"], "level": 3, "startpage": 488, "endpage": 488, "topicname": "13.6.1 Bridge regression"}, {"keywordlist": ["sparsePostPlot", "bridge regression", "exponential power distribution", "normalGammaThresholdPlotDemo", "generalized t distribution", "adaptive lasso", "hierarchical adaptive lasso", "normalGammaPenaltyPlotDemo", "double Pareto distribution"], "level": 3, "startpage": 488, "endpage": 491, "topicname": "13.6.2 Hierarchical adaptive lasso"}, {"keywordlist": [], "level": 3, "startpage": 492, "endpage": 492, "topicname": "13.6.3 Other hierarchical priors"}, {"keywordlist": ["factorial prior", "SBL", "sparse Bayesian learning", "relevance vector machine", "automatic relevance determination", "non-factorial"], "level": 2, "startpage": 493, "endpage": 497, "topicname": "13.7 Automatic relevance determination (ARD)/sparse Bayesian learning (SBL)"}, {"keywordlist": ["factorial prior", "SBL", "sparse Bayesian learning", "relevance vector machine", "automatic relevance determination"], "level": 3, "startpage": 493, "endpage": 494, "topicname": "13.7.1 ARD for linear regression"}, {"keywordlist": [], "level": 3, "startpage": 495, "endpage": 495, "topicname": "13.7.2 Whence sparsity?"}, {"keywordlist": [], "level": 3, "startpage": 495, "endpage": 495, "topicname": "13.7.3 Connection to MAP estimation"}, {"keywordlist": ["non-factorial"], "level": 3, "startpage": 496, "endpage": 497, "topicname": "13.7.4 Algorithms for ARD *"}, {"keywordlist": ["basic feasible solution"], "level": 3, "startpage": 498, "endpage": 498, "topicname": "13.7.5 ARD for logistic regression"}, {"keywordlist": ["\ufb01elds of experts", "non-negative sparse coding", "NMF", "non-negative matrix factorization", "translation invariant", "overcomplete", "Fourier basis", "beta process", "icaBasisDemo", "sparse coding", "analysis-synthesis", "sparse PCA", "basic feasible solution", "sparseDictDemo", "sparse matrix factorization", "compressive sensing", "atom", "besselk", "DCT", "compressed sensing", "dictionary", "image denoising", "wavelet", "normal Gamma"], "level": 2, "startpage": 498, "endpage": 508, "topicname": "13.8 Sparse coding *"}, {"keywordlist": ["overcomplete", "sparse coding", "sparse PCA", "sparse matrix factorization", "atom", "DCT", "dictionary", "wavelet"], "level": 3, "startpage": 499, "endpage": 499, "topicname": "13.8.1 Learning a sparse coding dictionary"}, {"keywordlist": ["non-negative sparse coding", "NMF", "non-negative matrix factorization", "beta process", "icaBasisDemo", "analysis-synthesis", "sparseDictDemo"], "level": 3, "startpage": 500, "endpage": 501, "topicname": "13.8.2 Results of dictionary learning from image patches"}, {"keywordlist": ["translation invariant", "Fourier basis", "compressive sensing", "compressed sensing"], "level": 3, "startpage": 502, "endpage": 502, "topicname": "13.8.3 Compressed sensing"}, {"keywordlist": ["\ufb01elds of experts", "translation invariant", "Fourier basis", "compressive sensing", "besselk", "compressed sensing", "image denoising", "normal Gamma"], "level": 3, "startpage": 502, "endpage": 508, "topicname": "13.8.4 Image inpainting and denoising"}, {"keywordlist": ["Mercer kernel", "one-versus-one", "kernel density estimator", "SIFT", "kernelRegressionDemo", "jittered", "RBF network", "epsilon insensitive loss function", "one-vs-all", "LOESS", "soft margin constraints", "ARD kernel", "kernel smoothing", "large margin classi\ufb01er", "Dirichlet process mixture models", "Mercer\u2019s theorem", "bandwidth", "RVM", "equivalent kernel", "pyramid match kernel", "interest point detector", "tri-cube kernel", "nearest medoid classi\ufb01cation", "score vector", "centering matrix", "Ornstein-Uhlenbeck process", "discriminant function", "polynomial kernel", "Kleene star", "bursty", "characteristic length scale", "primal variables", "Brownian motion", "centroids", "support vectors", "smoothingKernelPlot", "cosine similarity", "linregRbfDemo", "boxcar kernel", "exclusive or", "Matern kernel", "sequential minimal optimization", "kpcaDemo2", "class imbalance", "tube", "Gram matrix", "multidimensional scaling", "\u03bd-SVM classi\ufb01er", "one-versus-the-rest", "positive de\ufb01nite kernel", "k-spectrum kernel", "slack variables", "kernelBinaryClassifDemo", "xor", "Fisher kernel", "Epanechnikov kernel", "Gaussian process", "locally weighted regression", "svmCgammaDemo", "probability product kernel", "squared exponential kernel", "smoothing kernel", "L2VM", "linear kernel", "kernel machine", "kernel trick", "RBF", "suffix trees", "TF-IDF", "kernel PCA", "KDE", "Nadaraya-Watson", "LOWESS", "parzenWindowDemo2", "support vector machine", "Bessel function", "edit distance", "logregXorDemo", "kernel function", "kernelRegrDemo", "Parzen window density estimator", "all pairs", "dual variables", "bag-of-characters", "mean absolute deviation", "SMO", "MDS", "bag-of-words", "sigmoid kernel", "clusters", "Gaussian kernel", "L1VM", "error-correcting output codes", "kernel regression", "kernelised feature vector", "K-medoids algorothm", "sparse vector machine", "kpcaScholkopf", "deep learning", "string kernel", "histogram", "radial basis function"], "level": 1, "startpage": 509, "endpage": 544, "topicname": "14 Kernels"}, {"keywordlist": ["edit distance", "kernel function", "deep learning"], "level": 2, "startpage": 509, "endpage": 509, "topicname": "14.1 Introduction"}, {"keywordlist": ["Mercer kernel", "SIFT", "ARD kernel", "Mercer\u2019s theorem", "bandwidth", "pyramid match kernel", "interest point detector", "score vector", "Ornstein-Uhlenbeck process", "polynomial kernel", "Kleene star", "bursty", "characteristic length scale", "Brownian motion", "cosine similarity", "Matern kernel", "Gram matrix", "positive de\ufb01nite kernel", "k-spectrum kernel", "Fisher kernel", "Gaussian process", "probability product kernel", "squared exponential kernel", "linear kernel", "RBF", "suffix trees", "TF-IDF", "Bessel function", "edit distance", "kernel function", "bag-of-characters", "bag-of-words", "sigmoid kernel", "Gaussian kernel", "deep learning", "string kernel", "radial basis function"], "level": 2, "startpage": 509, "endpage": 515, "topicname": "14.2 Kernel functions"}, {"keywordlist": ["ARD kernel", "bandwidth", "bursty", "characteristic length scale", "cosine similarity", "squared exponential kernel", "RBF", "TF-IDF", "Gaussian kernel", "radial basis function"], "level": 3, "startpage": 510, "endpage": 510, "topicname": "14.2.1 RBF kernels"}, {"keywordlist": ["ARD kernel", "bandwidth", "bursty", "characteristic length scale", "cosine similarity", "squared exponential kernel", "RBF", "TF-IDF", "Gaussian kernel", "radial basis function"], "level": 3, "startpage": 510, "endpage": 510, "topicname": "14.2.2 Kernels for comparing documents"}, {"keywordlist": ["Mercer kernel", "Mercer\u2019s theorem", "polynomial kernel", "Gram matrix", "positive de\ufb01nite kernel"], "level": 3, "startpage": 511, "endpage": 511, "topicname": "14.2.3 Mercer (positive definite) kernels"}, {"keywordlist": ["Matern kernel", "linear kernel", "sigmoid kernel"], "level": 3, "startpage": 512, "endpage": 512, "topicname": "14.2.4 Linear kernels"}, {"keywordlist": ["Matern kernel", "linear kernel", "sigmoid kernel"], "level": 3, "startpage": 512, "endpage": 512, "topicname": "14.2.5 Matern kernels"}, {"keywordlist": ["Ornstein-Uhlenbeck process", "Kleene star", "Brownian motion", "Gaussian process", "suffix trees", "Bessel function", "bag-of-characters", "bag-of-words", "string kernel"], "level": 3, "startpage": 513, "endpage": 513, "topicname": "14.2.6 String kernels"}, {"keywordlist": ["SIFT", "pyramid match kernel", "interest point detector", "k-spectrum kernel"], "level": 3, "startpage": 514, "endpage": 514, "topicname": "14.2.7 Pyramid match kernels"}, {"keywordlist": ["score vector", "Fisher kernel", "probability product kernel"], "level": 3, "startpage": 515, "endpage": 515, "topicname": "14.2.8 Kernels derived from probabilistic generative models"}, {"keywordlist": ["jittered", "RBF network", "centroids", "linregRbfDemo", "exclusive or", "xor", "kernel machine", "logregXorDemo", "clusters", "kernelised feature vector"], "level": 2, "startpage": 516, "endpage": 517, "topicname": "14.3 Using kernels inside GLMs"}, {"keywordlist": ["jittered", "RBF network", "centroids", "exclusive or", "xor", "kernel machine", "logregXorDemo", "kernelised feature vector"], "level": 3, "startpage": 516, "endpage": 516, "topicname": "14.3.1 Kernel machines"}, {"keywordlist": ["linregRbfDemo", "clusters"], "level": 3, "startpage": 517, "endpage": 517, "topicname": "14.3.2 L1VMs, RVMs, and other sparse vector machines"}, {"keywordlist": ["RVM", "nearest medoid classi\ufb01cation", "centering matrix", "primal variables", "kpcaDemo2", "kernelBinaryClassifDemo", "L2VM", "kernel trick", "kernel PCA", "support vector machine", "kernelRegrDemo", "dual variables", "L1VM", "K-medoids algorothm", "sparse vector machine", "kpcaScholkopf"], "level": 2, "startpage": 518, "endpage": 525, "topicname": "14.4 The kernel trick"}, {"keywordlist": ["kernelBinaryClassifDemo"], "level": 3, "startpage": 519, "endpage": 519, "topicname": "14.4.1 Kernelized nearest neighbor classification"}, {"keywordlist": ["nearest medoid classi\ufb01cation", "kernelBinaryClassifDemo", "kernelRegrDemo", "K-medoids algorothm"], "level": 3, "startpage": 519, "endpage": 521, "topicname": "14.4.2 Kernelized K-medoids clustering"}, {"keywordlist": ["primal variables", "dual variables"], "level": 3, "startpage": 522, "endpage": 522, "topicname": "14.4.3 Kernelized ridge regression"}, {"keywordlist": ["centering matrix", "kpcaDemo2", "kernel PCA", "kpcaScholkopf"], "level": 3, "startpage": 523, "endpage": 525, "topicname": "14.4.4 Kernel PCA"}, {"keywordlist": ["one-versus-one", "epsilon insensitive loss function", "one-vs-all", "soft margin constraints", "large margin classi\ufb01er", "discriminant function", "support vectors", "sequential minimal optimization", "class imbalance", "tube", "multidimensional scaling", "\u03bd-SVM classi\ufb01er", "one-versus-the-rest", "slack variables", "svmCgammaDemo", "all pairs", "SMO", "MDS", "error-correcting output codes"], "level": 2, "startpage": 526, "endpage": 534, "topicname": "14.5 Support vector machines (SVMs)"}, {"keywordlist": ["epsilon insensitive loss function", "tube"], "level": 3, "startpage": 527, "endpage": 527, "topicname": "14.5.1 SVMs for regression"}, {"keywordlist": ["one-versus-one", "one-vs-all", "soft margin constraints", "large margin classi\ufb01er", "discriminant function", "sequential minimal optimization", "class imbalance", "\u03bd-SVM classi\ufb01er", "one-versus-the-rest", "slack variables", "all pairs", "SMO", "error-correcting output codes"], "level": 3, "startpage": 528, "endpage": 533, "topicname": "14.5.2 SVMs for classification"}, {"keywordlist": ["svmCgammaDemo"], "level": 3, "startpage": 534, "endpage": 534, "topicname": "14.5.3 Choosing C"}, {"keywordlist": ["svmCgammaDemo"], "level": 3, "startpage": 534, "endpage": 534, "topicname": "14.5.4 Summary of key points"}, {"keywordlist": [], "level": 3, "startpage": 535, "endpage": 535, "topicname": "14.5.5 A probabilistic interpretation of SVMs"}, {"keywordlist": [], "level": 2, "startpage": 535, "endpage": 536, "topicname": "14.6 Comparison of discriminative kernel methods"}, {"keywordlist": ["kernel density estimator", "kernelRegressionDemo", "LOESS", "kernel smoothing", "Dirichlet process mixture models", "equivalent kernel", "tri-cube kernel", "smoothingKernelPlot", "boxcar kernel", "Epanechnikov kernel", "locally weighted regression", "smoothing kernel", "KDE", "Nadaraya-Watson", "LOWESS", "parzenWindowDemo2", "Parzen window density estimator", "mean absolute deviation", "kernel regression", "histogram"], "level": 2, "startpage": 537, "endpage": 544, "topicname": "14.7 Kernels for building generative models"}, {"keywordlist": ["smoothingKernelPlot", "smoothing kernel"], "level": 3, "startpage": 537, "endpage": 537, "topicname": "14.7.1 Smoothing kernels"}, {"keywordlist": ["kernel density estimator", "Dirichlet process mixture models", "tri-cube kernel", "boxcar kernel", "Epanechnikov kernel", "KDE", "Parzen window density estimator", "histogram"], "level": 3, "startpage": 538, "endpage": 538, "topicname": "14.7.2 Kernel density estimation (KDE)"}, {"keywordlist": ["parzenWindowDemo2"], "level": 3, "startpage": 539, "endpage": 539, "topicname": "14.7.3 From KDE to KNN"}, {"keywordlist": ["kernelRegressionDemo", "kernel smoothing", "Nadaraya-Watson", "mean absolute deviation", "kernel regression"], "level": 3, "startpage": 540, "endpage": 541, "topicname": "14.7.4 Kernel regression"}, {"keywordlist": ["LOESS", "equivalent kernel", "locally weighted regression", "LOWESS"], "level": 3, "startpage": 542, "endpage": 544, "topicname": "14.7.5 Locally weighted regression"}, {"keywordlist": ["relative risk", "degenerate", "disease mapping", "fast Gauss transform", "Gaussian processes", "RKHS", "gpSpatialDemoLaplace", "gpnnDemo", "expectation propagation", "reproducing kernel Hilbert space", "reproducing property", "kriging", "representer theorem", "regression spline", "gprDemoMarglik", "unscented Kalman \ufb01lter", "DACE", "linear smoother", "RBF kernel", "gprDemoNoiseFree", "weight function", "interpolator", "knots", "cubic spline", "MARS", "gprDemoChangeHparams", "central composite design", "multiple kernel learning", "factor analysis distance", "gprDemoArd", "gpcDemo2d", "GPs", "Smoothing splines", "thin plate spline", "norm of a function", "tensor product basis", "piecewise polynomial", "GP-LVM", "penalized splines"], "level": 1, "startpage": 545, "endpage": 572, "topicname": "15 Gaussian Processes"}, {"keywordlist": ["Gaussian processes", "GPs"], "level": 2, "startpage": 545, "endpage": 545, "topicname": "15.1 Introduction"}, {"keywordlist": ["fast Gauss transform", "kriging", "gprDemoMarglik", "unscented Kalman \ufb01lter", "DACE", "RBF kernel", "gprDemoNoiseFree", "interpolator", "gprDemoChangeHparams", "central composite design", "multiple kernel learning", "factor analysis distance", "gprDemoArd"], "level": 2, "startpage": 546, "endpage": 554, "topicname": "15.2 GPs for regression"}, {"keywordlist": ["RBF kernel", "gprDemoNoiseFree", "interpolator"], "level": 3, "startpage": 547, "endpage": 547, "topicname": "15.2.1 Predictions using noise-free observations"}, {"keywordlist": ["DACE"], "level": 3, "startpage": 548, "endpage": 548, "topicname": "15.2.2 Predictions using noisy observations"}, {"keywordlist": ["gprDemoChangeHparams", "factor analysis distance", "gprDemoArd"], "level": 3, "startpage": 549, "endpage": 550, "topicname": "15.2.3 Effect of the kernel parameters"}, {"keywordlist": ["gprDemoMarglik", "unscented Kalman \ufb01lter", "central composite design"], "level": 3, "startpage": 551, "endpage": 553, "topicname": "15.2.4 Estimating the kernel parameters"}, {"keywordlist": ["fast Gauss transform", "multiple kernel learning"], "level": 3, "startpage": 554, "endpage": 554, "topicname": "15.2.5 Computational and numerical issues *"}, {"keywordlist": ["fast Gauss transform", "multiple kernel learning"], "level": 3, "startpage": 554, "endpage": 554, "topicname": "15.2.6 Semi-parametric GPs *"}, {"keywordlist": ["relative risk", "disease mapping", "expectation propagation", "gpcDemo2d"], "level": 2, "startpage": 555, "endpage": 561, "topicname": "15.3 GPs meet GLMs"}, {"keywordlist": ["expectation propagation"], "level": 3, "startpage": 555, "endpage": 557, "topicname": "15.3.1 Binary classification"}, {"keywordlist": ["gpcDemo2d"], "level": 3, "startpage": 558, "endpage": 560, "topicname": "15.3.2 Multi-class classification"}, {"keywordlist": ["relative risk", "disease mapping"], "level": 3, "startpage": 561, "endpage": 561, "topicname": "15.3.3 GPs for Poisson regression"}, {"keywordlist": ["degenerate", "RKHS", "gpSpatialDemoLaplace", "gpnnDemo", "reproducing kernel Hilbert space", "reproducing property", "representer theorem", "regression spline", "linear smoother", "weight function", "knots", "cubic spline", "MARS", "Smoothing splines", "thin plate spline", "norm of a function", "tensor product basis", "piecewise polynomial", "penalized splines"], "level": 2, "startpage": 562, "endpage": 569, "topicname": "15.4 Connection with other methods"}, {"keywordlist": ["degenerate", "gpSpatialDemoLaplace"], "level": 3, "startpage": 562, "endpage": 562, "topicname": "15.4.1 Linear models compared to GPs"}, {"keywordlist": ["linear smoother", "weight function"], "level": 3, "startpage": 563, "endpage": 563, "topicname": "15.4.2 Linear smoothers compared to GPs"}, {"keywordlist": [], "level": 3, "startpage": 564, "endpage": 564, "topicname": "15.4.3 SVMs compared to GPs"}, {"keywordlist": [], "level": 3, "startpage": 564, "endpage": 564, "topicname": "15.4.4 L1VM and RVMs compared to GPs"}, {"keywordlist": [], "level": 3, "startpage": 565, "endpage": 565, "topicname": "15.4.5 Neural networks compared to GPs"}, {"keywordlist": ["gpnnDemo", "regression spline", "knots", "cubic spline", "Smoothing splines", "piecewise polynomial", "penalized splines"], "level": 3, "startpage": 566, "endpage": 567, "topicname": "15.4.6 Smoothing splines compared to GPs *"}, {"keywordlist": ["RKHS", "reproducing kernel Hilbert space", "reproducing property", "representer theorem", "MARS", "thin plate spline", "norm of a function", "tensor product basis"], "level": 3, "startpage": 568, "endpage": 569, "topicname": "15.4.7 RKHS methods compared to GPs *"}, {"keywordlist": ["GP-LVM"], "level": 2, "startpage": 570, "endpage": 571, "topicname": "15.5 GP latent variable model"}, {"keywordlist": [], "level": 2, "startpage": 572, "endpage": 572, "topicname": "15.6 Approximation methods for large datasets"}, {"keywordlist": ["dt\ufb01t", "activation", "random forests", "regtreeSurfaceDemo", "demard", "Bayesian adaptive regression trees", "boosting", "mlpRegHmcDemo", "connectionism", "n-gram", "CART", "probe", "matching pursuit", "probabilistic decision tree", "template matching", "Gini index", "Hop\ufb01eld network", "feature maps", "semi-supervised embedding", "deviance", "MLP", "axis parallel splits", "boostingDemo", "bagging", "functional gradient descent", "pure", "forward stagewise linear regression", "BinomialBoost", "distorted", "mutual inhibition", "BART", "mlpPriorsDemo", "sparseNnetDemo", "distributed representation", "kernel", "embedding", "dtreeDemoIris", "universal approximator", "margin", "skip arcs", "pruning", "re\ufb02ecting pair", "rules", "logitBoost", "stochastic gradient boosting", "Adaboost.M1", "computationalism", "semantic role labeling", "backpropagation algorithm", "multi-layer perceptron", "soft weight sharing", "transfer function", "perceptron", "Boosting", "face detector", "L1-Adaboost", "feature construction", "hidden layer", "stacking", "partial dependence plot", "contrastive divergence", "ANOVA", "hidden units", "mlpRegEvidenceDemo", "NETtalk", "gradient boosting", "C4.5", "neocognitron", "SpAM", "adaline", "associative memory", "Classi\ufb01cation and regression trees", "information gain", "sparse boosting", "marsDemo", "decision trees", "recurrent neural network", "L2boosting", "Entropy", "kinect", "feedforward neural network", "unstable", "back\ufb01tting", "high variance estimators", "LeNet5", "giniDemo", "data fragmentation", "generalized additive model", "subsampling", "elasticDistortionsDemo", "translation invariance", "adaptive basis-function model", "MART", "forward stagewise additive modeling", "discrete AdaBoost", "convolutional neural network", "tensor product", "hybrid Monte Carlo", "relative importance of predictor variables", "ECOC", "committee method", "deep networks", "base learner", "Ensemble learning", "Boltzmann machine", "tanhPlot", "backpropagation", "weak learner", "multivariate adaptive regression splines", "real AdaBoost", "Misclassi\ufb01cation rate", "surrogate splits", "receptive \ufb01elds", "ID3", "population minimizer", "exponential loss"], "level": 1, "startpage": 573, "endpage": 618, "topicname": "16 Adaptive Basis Function Models"}, {"keywordlist": ["template matching", "adaptive basis-function model"], "level": 2, "startpage": 573, "endpage": 573, "topicname": "16.1 Introduction"}, {"keywordlist": ["dt\ufb01t", "random forests", "regtreeSurfaceDemo", "Bayesian adaptive regression trees", "CART", "probabilistic decision tree", "Gini index", "deviance", "axis parallel splits", "bagging", "pure", "BART", "dtreeDemoIris", "pruning", "rules", "C4.5", "Classi\ufb01cation and regression trees", "information gain", "decision trees", "Entropy", "kinect", "unstable", "high variance estimators", "giniDemo", "data fragmentation", "Misclassi\ufb01cation rate", "surrogate splits", "ID3"], "level": 2, "startpage": 574, "endpage": 581, "topicname": "16.2 Classification and regression trees (CART)"}, {"keywordlist": ["CART", "axis parallel splits", "Classi\ufb01cation and regression trees", "decision trees"], "level": 3, "startpage": 574, "endpage": 574, "topicname": "16.2.1 Basics"}, {"keywordlist": ["dt\ufb01t", "regtreeSurfaceDemo", "Gini index", "deviance", "pure", "C4.5", "information gain", "Entropy", "giniDemo", "data fragmentation", "Misclassi\ufb01cation rate", "ID3"], "level": 3, "startpage": 575, "endpage": 578, "topicname": "16.2.2 Growing a tree"}, {"keywordlist": ["dtreeDemoIris", "pruning"], "level": 3, "startpage": 579, "endpage": 579, "topicname": "16.2.3 Pruning a tree"}, {"keywordlist": ["rules", "unstable", "high variance estimators", "surrogate splits"], "level": 3, "startpage": 580, "endpage": 580, "topicname": "16.2.4 Pros and cons of trees"}, {"keywordlist": ["rules", "unstable", "high variance estimators", "surrogate splits"], "level": 3, "startpage": 580, "endpage": 580, "topicname": "16.2.5 Random forests"}, {"keywordlist": ["random forests", "Bayesian adaptive regression trees", "probabilistic decision tree", "bagging", "BART", "kinect"], "level": 3, "startpage": 581, "endpage": 581, "topicname": "16.2.6 CART compared to hierarchical mixture of experts *"}, {"keywordlist": ["boosting", "re\ufb02ecting pair", "ANOVA", "SpAM", "back\ufb01tting", "generalized additive model", "tensor product", "multivariate adaptive regression splines"], "level": 2, "startpage": 582, "endpage": 583, "topicname": "16.3 Generalized additive models"}, {"keywordlist": ["back\ufb01tting", "generalized additive model"], "level": 3, "startpage": 582, "endpage": 582, "topicname": "16.3.1 Backfitting"}, {"keywordlist": ["boosting", "re\ufb02ecting pair", "ANOVA", "SpAM", "tensor product", "multivariate adaptive regression splines"], "level": 3, "startpage": 583, "endpage": 583, "topicname": "16.3.2 Computational efficiency"}, {"keywordlist": ["boosting", "re\ufb02ecting pair", "ANOVA", "SpAM", "tensor product", "multivariate adaptive regression splines"], "level": 3, "startpage": 583, "endpage": 583, "topicname": "16.3.3 Multivariate adaptive regression splines (MARS)"}, {"keywordlist": ["matching pursuit", "boostingDemo", "functional gradient descent", "forward stagewise linear regression", "BinomialBoost", "logitBoost", "Adaboost.M1", "Boosting", "face detector", "gradient boosting", "sparse boosting", "marsDemo", "L2boosting", "MART", "forward stagewise additive modeling", "discrete AdaBoost", "base learner", "weak learner", "real AdaBoost", "population minimizer", "exponential loss"], "level": 2, "startpage": 584, "endpage": 592, "topicname": "16.4 Boosting"}, {"keywordlist": ["boostingDemo", "face detector", "population minimizer", "exponential loss"], "level": 3, "startpage": 585, "endpage": 586, "topicname": "16.4.1 Forward stagewise additive modeling"}, {"keywordlist": ["forward stagewise additive modeling"], "level": 3, "startpage": 587, "endpage": 587, "topicname": "16.4.2 L2boosting"}, {"keywordlist": ["L2boosting"], "level": 3, "startpage": 588, "endpage": 588, "topicname": "16.4.3 AdaBoost"}, {"keywordlist": ["Adaboost.M1", "discrete AdaBoost", "real AdaBoost"], "level": 3, "startpage": 589, "endpage": 589, "topicname": "16.4.4 LogitBoost"}, {"keywordlist": ["logitBoost", "gradient boosting"], "level": 3, "startpage": 590, "endpage": 590, "topicname": "16.4.5 Boosting as functional gradient descent"}, {"keywordlist": ["functional gradient descent", "BinomialBoost"], "level": 3, "startpage": 591, "endpage": 591, "topicname": "16.4.6 Sparse boosting"}, {"keywordlist": ["matching pursuit", "forward stagewise linear regression", "sparse boosting", "MART"], "level": 3, "startpage": 592, "endpage": 592, "topicname": "16.4.7 Multivariate adaptive regression trees (MART)"}, {"keywordlist": ["matching pursuit", "forward stagewise linear regression", "sparse boosting", "MART"], "level": 3, "startpage": 592, "endpage": 592, "topicname": "16.4.8 Why does boosting work so well?"}, {"keywordlist": ["activation", "MLP", "margin", "multi-layer perceptron", "transfer function", "L1-Adaboost", "hidden layer", "feedforward neural network"], "level": 3, "startpage": 593, "endpage": 593, "topicname": "16.4.9 A Bayesian view"}, {"keywordlist": ["activation", "mlpRegHmcDemo", "connectionism", "n-gram", "Hop\ufb01eld network", "feature maps", "semi-supervised embedding", "MLP", "distorted", "mutual inhibition", "mlpPriorsDemo", "sparseNnetDemo", "distributed representation", "kernel", "embedding", "universal approximator", "margin", "skip arcs", "computationalism", "semantic role labeling", "backpropagation algorithm", "multi-layer perceptron", "soft weight sharing", "transfer function", "perceptron", "L1-Adaboost", "feature construction", "hidden layer", "contrastive divergence", "hidden units", "mlpRegEvidenceDemo", "NETtalk", "neocognitron", "adaline", "associative memory", "recurrent neural network", "feedforward neural network", "LeNet5", "subsampling", "elasticDistortionsDemo", "translation invariance", "convolutional neural network", "deep networks", "Boltzmann machine", "tanhPlot", "backpropagation", "receptive \ufb01elds"], "level": 2, "startpage": 593, "endpage": 609, "topicname": "16.5 Feedforward neural networks (multilayer perceptrons)"}, {"keywordlist": ["feature maps", "distorted", "mutual inhibition", "kernel", "universal approximator", "feature construction", "hidden units", "neocognitron", "LeNet5", "subsampling", "elasticDistortionsDemo", "translation invariance", "convolutional neural network", "receptive \ufb01elds"], "level": 3, "startpage": 594, "endpage": 597, "topicname": "16.5.1 Convolutional neural networks"}, {"keywordlist": ["n-gram", "Hop\ufb01eld network", "skip arcs", "associative memory", "recurrent neural network", "Boltzmann machine"], "level": 3, "startpage": 598, "endpage": 598, "topicname": "16.5.2 Other kinds of neural networks"}, {"keywordlist": ["n-gram", "Hop\ufb01eld network", "skip arcs", "associative memory", "recurrent neural network", "Boltzmann machine"], "level": 3, "startpage": 598, "endpage": 598, "topicname": "16.5.3 A brief history of the field"}, {"keywordlist": ["connectionism", "distributed representation", "computationalism", "backpropagation algorithm", "perceptron", "contrastive divergence", "NETtalk", "adaline", "deep networks", "tanhPlot", "backpropagation"], "level": 3, "startpage": 599, "endpage": 601, "topicname": "16.5.4 The backpropagation algorithm"}, {"keywordlist": [], "level": 3, "startpage": 602, "endpage": 602, "topicname": "16.5.5 Identifiability"}, {"keywordlist": ["mlpPriorsDemo", "sparseNnetDemo", "embedding", "soft weight sharing"], "level": 3, "startpage": 602, "endpage": 605, "topicname": "16.5.6 Regularization"}, {"keywordlist": ["mlpRegHmcDemo", "semi-supervised embedding", "semantic role labeling", "mlpRegEvidenceDemo"], "level": 3, "startpage": 606, "endpage": 609, "topicname": "16.5.7 Bayesian inference"}, {"keywordlist": ["demard", "stacking", "ECOC", "committee method", "Ensemble learning"], "level": 2, "startpage": 610, "endpage": 611, "topicname": "16.6 Ensemble learning"}, {"keywordlist": ["demard", "stacking", "committee method", "Ensemble learning"], "level": 3, "startpage": 610, "endpage": 610, "topicname": "16.6.1 Stacking"}, {"keywordlist": ["ECOC"], "level": 3, "startpage": 611, "endpage": 611, "topicname": "16.6.2 Error-correcting output codes"}, {"keywordlist": ["ECOC"], "level": 3, "startpage": 611, "endpage": 611, "topicname": "16.6.3 Ensemble learning is not equivalent to Bayes model averaging"}, {"keywordlist": ["probe", "stochastic gradient boosting", "hybrid Monte Carlo"], "level": 2, "startpage": 612, "endpage": 614, "topicname": "16.7 Experimental comparison"}, {"keywordlist": [], "level": 3, "startpage": 612, "endpage": 612, "topicname": "16.7.1 Low-dimensional features"}, {"keywordlist": ["probe", "stochastic gradient boosting", "hybrid Monte Carlo"], "level": 3, "startpage": 613, "endpage": 614, "topicname": "16.7.2 High-dimensional features"}, {"keywordlist": ["partial dependence plot", "relative importance of predictor variables"], "level": 2, "startpage": 615, "endpage": 618, "topicname": "16.8 Interpreting black-box models"}, {"keywordlist": ["Buried Markov models", "hmmFilter", "absorbing state", "stochastic context free grammars", "hindsight", "phone", "gene \ufb01nding", "lag", "variational Bayes EM", "Baum-Welch", "DBN", "homogeneous", "left-to-right transition matrix", "factorial HMM", "left-to-right", "regular", "observation", "link farms", "semi-Markov model", "hmmSelfLoopDist", "time reversible", "Part of speech tagging", "regime switching Markov model", "Toeplitz", "recurrent", "power method", "Chapman-Kolmogorov", "control signal", "part of speech", "MPE", "MPM", "horizon", "Smoothing", "SCFGs", "Protein sequence alignment", "ngramPlot", "irreducible", "mcStatDist", "in\ufb01nite HMM", "pagerankDemo", "second-order Markov model", "language models", "N-best list", "pagerankDemoPmtk", "auto-regressive HMM", "occasionally dishonest casino", "invariant distribution", "max-product", "recurrent neural networks", "trellis", "minimum entropy prior", "Dasher", "rerank", "casinoDemo", "hierarchical Dirichlet process", "hidden semi-Markov model", "inside outside", "negative binomial", "unigram statistics", "Levinson-Durbin", "dynamic Bayesian network", "web crawling", "bigram model", "backoff smoothing", "Hinton diagram", "entanglement", "Gamma", "deleted interpolation", "period", "geometric distribution", "Gene \ufb01nding", "HSMM", "structure learning", "conditional random \ufb01elds", "DyBN", "web spam", "search engine optimization", "equilibrium distribution", "inverted index", "traceback", "Markov switching models", "tied-mixture HMM", "stochastic automaton", "detailed balance equations", "DeeBN", "coupled HMM", "maximizer of the posterior marginals", "time-invariant", "Viterbi decoding", "greatest common divisor", "trellis diagram", "state transition diagram", "Markov model", "audio-visual speech recognition", "stochastic processes", "pro\ufb01le HMM", "Filtering", "open class", "chip-Seq", "split merge", "sum-product", "predict-update cycle", "Hadamard product", "Fixed lag smoothing", "n-gram models", "stationary distribution", "posterior predictive density", "Viterbi", "stationary", "Automatic speech recognition", "hmmFwdBack", "hierarchical HMM", "two-slice marginal", "transition matrix", "in\ufb02uence model", "transient", "belief propagation", "random walk on the integers", "aperiodic", "automatic speech recognition", "speech recognition", "limiting distribution", "multi net", "interpolated Kneser-Ney", "semi-continuous HMM", "trigram model", "Viterbi training", "Activity recognition", "conditional likelihood", "global balance equations", "Dirichlet process", "multiple restarts", "non-null recurrent", "one-step-ahead predictive density", "JC Penney", "INDEX TO KEYWORDS variable duration HMM", "Open Directory Project", "explicit duration HMM", "ergodic", "hmmLillypadDemo"], "level": 1, "startpage": 619, "endpage": 660, "topicname": "17 Markov and Hidden Markov Models"}, {"keywordlist": ["homogeneous", "time-invariant", "Markov model", "stochastic processes", "stationary", "transition matrix"], "level": 2, "startpage": 619, "endpage": 619, "topicname": "17.1 Introduction"}, {"keywordlist": ["absorbing state", "homogeneous", "left-to-right transition matrix", "regular", "link farms", "time reversible", "recurrent", "Chapman-Kolmogorov", "ngramPlot", "irreducible", "mcStatDist", "pagerankDemo", "second-order Markov model", "language models", "pagerankDemoPmtk", "invariant distribution", "recurrent neural networks", "Dasher", "unigram statistics", "web crawling", "bigram model", "backoff smoothing", "Hinton diagram", "deleted interpolation", "period", "equilibrium distribution", "inverted index", "stochastic automaton", "detailed balance equations", "time-invariant", "greatest common divisor", "state transition diagram", "Markov model", "stochastic processes", "open class", "n-gram models", "stationary distribution", "stationary", "transition matrix", "transient", "random walk on the integers", "aperiodic", "speech recognition", "limiting distribution", "interpolated Kneser-Ney", "trigram model", "global balance equations", "Dirichlet process", "non-null recurrent", "Open Directory Project", "ergodic"], "level": 2, "startpage": 619, "endpage": 632, "topicname": "17.2 Markov models"}, {"keywordlist": ["homogeneous", "left-to-right transition matrix", "Chapman-Kolmogorov", "stochastic automaton", "time-invariant", "state transition diagram", "Markov model", "stochastic processes", "stationary", "transition matrix", "speech recognition"], "level": 3, "startpage": 619, "endpage": 620, "topicname": "17.2.1 Transition matrix"}, {"keywordlist": ["ngramPlot", "second-order Markov model", "language models", "recurrent neural networks", "Dasher", "unigram statistics", "bigram model", "backoff smoothing", "Hinton diagram", "deleted interpolation", "n-gram models", "interpolated Kneser-Ney", "trigram model"], "level": 3, "startpage": 621, "endpage": 625, "topicname": "17.2.2 Application: Language modeling"}, {"keywordlist": ["absorbing state", "regular", "time reversible", "recurrent", "irreducible", "mcStatDist", "invariant distribution", "period", "equilibrium distribution", "detailed balance equations", "greatest common divisor", "open class", "stationary distribution", "transient", "random walk on the integers", "aperiodic", "limiting distribution", "global balance equations", "Dirichlet process", "non-null recurrent", "ergodic"], "level": 3, "startpage": 626, "endpage": 629, "topicname": "17.2.3 Stationary distribution of a Markov chain *"}, {"keywordlist": ["link farms", "pagerankDemo", "pagerankDemoPmtk", "web crawling", "inverted index", "Open Directory Project"], "level": 3, "startpage": 630, "endpage": 632, "topicname": "17.2.4 Application: Google\u2019s PageRank algorithm for web page ranking"}, {"keywordlist": ["observation", "Part of speech tagging", "power method", "part of speech", "web spam", "search engine optimization", "Markov switching models", "Automatic speech recognition", "Activity recognition", "JC Penney", "hmmLillypadDemo"], "level": 2, "startpage": 633, "endpage": 635, "topicname": "17.3 Hidden Markov models"}, {"keywordlist": ["Part of speech tagging", "part of speech", "Markov switching models", "Automatic speech recognition", "Activity recognition", "hmmLillypadDemo"], "level": 3, "startpage": 634, "endpage": 635, "topicname": "17.3.1 Applications of HMMs"}, {"keywordlist": ["hmmFilter", "hindsight", "lag", "left-to-right", "MPE", "MPM", "horizon", "Smoothing", "Protein sequence alignment", "N-best list", "occasionally dishonest casino", "max-product", "trellis", "rerank", "casinoDemo", "Gene \ufb01nding", "conditional random \ufb01elds", "traceback", "maximizer of the posterior marginals", "Viterbi decoding", "trellis diagram", "pro\ufb01le HMM", "Filtering", "sum-product", "predict-update cycle", "Hadamard product", "Fixed lag smoothing", "posterior predictive density", "Viterbi", "hmmFwdBack", "two-slice marginal", "belief propagation", "one-step-ahead predictive density"], "level": 2, "startpage": 636, "endpage": 646, "topicname": "17.4 Inference in HMMs"}, {"keywordlist": ["hindsight", "lag", "horizon", "Smoothing", "Protein sequence alignment", "occasionally dishonest casino", "casinoDemo", "Gene \ufb01nding", "conditional random \ufb01elds", "Viterbi decoding", "pro\ufb01le HMM", "Filtering", "Fixed lag smoothing", "posterior predictive density"], "level": 3, "startpage": 636, "endpage": 638, "topicname": "17.4.1 Types of inference problems for temporal models"}, {"keywordlist": ["hmmFilter", "predict-update cycle", "Hadamard product", "one-step-ahead predictive density"], "level": 3, "startpage": 639, "endpage": 639, "topicname": "17.4.2 The forwards algorithm"}, {"keywordlist": ["hmmFwdBack", "two-slice marginal", "belief propagation"], "level": 3, "startpage": 640, "endpage": 641, "topicname": "17.4.3 The forwards-backwards algorithm"}, {"keywordlist": ["left-to-right", "MPE", "MPM", "max-product", "trellis", "traceback", "maximizer of the posterior marginals", "trellis diagram", "sum-product", "Viterbi"], "level": 3, "startpage": 642, "endpage": 645, "topicname": "17.4.4 The Viterbi algorithm"}, {"keywordlist": ["N-best list", "rerank"], "level": 3, "startpage": 646, "endpage": 646, "topicname": "17.4.5 Forwards filtering, backwards sampling"}, {"keywordlist": ["variational Bayes EM", "Baum-Welch", "Viterbi training", "conditional likelihood", "multiple restarts"], "level": 2, "startpage": 647, "endpage": 650, "topicname": "17.5 Learning for HMMs"}, {"keywordlist": [], "level": 3, "startpage": 647, "endpage": 647, "topicname": "17.5.1 Training with fully observed data"}, {"keywordlist": ["Baum-Welch"], "level": 3, "startpage": 648, "endpage": 649, "topicname": "17.5.2 EM for HMMs (the Baum-Welch algorithm)"}, {"keywordlist": ["variational Bayes EM", "Viterbi training", "conditional likelihood", "multiple restarts"], "level": 3, "startpage": 650, "endpage": 650, "topicname": "17.5.3 Bayesian methods for \u201cfitting\u201d HMMs *"}, {"keywordlist": ["variational Bayes EM", "Viterbi training", "conditional likelihood", "multiple restarts"], "level": 3, "startpage": 650, "endpage": 650, "topicname": "17.5.4 Discriminative training"}, {"keywordlist": ["in\ufb01nite HMM", "minimum entropy prior", "hierarchical Dirichlet process", "structure learning", "split merge"], "level": 3, "startpage": 651, "endpage": 651, "topicname": "17.5.5 Model selection"}, {"keywordlist": ["Buried Markov models", "stochastic context free grammars", "phone", "gene \ufb01nding", "DBN", "factorial HMM", "semi-Markov model", "hmmSelfLoopDist", "regime switching Markov model", "Toeplitz", "control signal", "SCFGs", "in\ufb01nite HMM", "auto-regressive HMM", "minimum entropy prior", "hierarchical Dirichlet process", "hidden semi-Markov model", "inside outside", "negative binomial", "Levinson-Durbin", "dynamic Bayesian network", "entanglement", "Gamma", "geometric distribution", "HSMM", "structure learning", "DyBN", "tied-mixture HMM", "DeeBN", "coupled HMM", "audio-visual speech recognition", "chip-Seq", "split merge", "hierarchical HMM", "in\ufb02uence model", "automatic speech recognition", "multi net", "semi-continuous HMM", "INDEX TO KEYWORDS variable duration HMM", "explicit duration HMM"], "level": 2, "startpage": 651, "endpage": 660, "topicname": "17.6 Generalizations of HMMs"}, {"keywordlist": ["gene \ufb01nding", "semi-Markov model", "hmmSelfLoopDist", "hidden semi-Markov model", "Gamma", "geometric distribution", "HSMM", "chip-Seq", "INDEX TO KEYWORDS variable duration HMM", "explicit duration HMM"], "level": 3, "startpage": 652, "endpage": 653, "topicname": "17.6.1 Variable duration (semi-Markov) HMMs"}, {"keywordlist": ["stochastic context free grammars", "phone", "SCFGs", "inside outside", "negative binomial", "hierarchical HMM", "automatic speech recognition"], "level": 3, "startpage": 654, "endpage": 654, "topicname": "17.6.2 Hierarchical HMMs"}, {"keywordlist": ["control signal"], "level": 3, "startpage": 655, "endpage": 655, "topicname": "17.6.3 Input-output HMMs"}, {"keywordlist": ["regime switching Markov model", "auto-regressive HMM"], "level": 3, "startpage": 656, "endpage": 656, "topicname": "17.6.4 Auto-regressive and buried HMMs"}, {"keywordlist": ["Buried Markov models", "Toeplitz", "Levinson-Durbin", "multi net"], "level": 3, "startpage": 657, "endpage": 657, "topicname": "17.6.5 Factorial HMM"}, {"keywordlist": ["DBN", "factorial HMM", "dynamic Bayesian network", "DyBN", "DeeBN", "coupled HMM", "audio-visual speech recognition", "in\ufb02uence model"], "level": 3, "startpage": 658, "endpage": 658, "topicname": "17.6.6 Coupled HMM and the influence model"}, {"keywordlist": ["DBN", "factorial HMM", "dynamic Bayesian network", "entanglement", "DyBN", "tied-mixture HMM", "DeeBN", "coupled HMM", "audio-visual speech recognition", "in\ufb02uence model", "semi-continuous HMM"], "level": 3, "startpage": 658, "endpage": 660, "topicname": "17.6.7 Dynamic Bayesian networks (DBNs)"}, {"keywordlist": ["Taylor series expansion", "Kalman smoothing", "UKF", "sampling period", "assumed density \ufb01ltering", "LG-SSM", "SSM", "structural time series", "information \ufb01lter", "Kalman smoother", "extended Kalman \ufb01lter", "iterated EKF", "FastSLAM", "residual", "closing the loop", "ssmTimeSeriesSimple", "entanglement problem", "linregOnlineDemoKalman", "ADF", "SLAM", "interactive multiple models", "switching state space model", "unscented transform", "kalmanFilter", "RLS", "linear trend", "generalized pseudo Bayes \ufb01lter", "multiple hypothesis tracking", "slippage", "fault diagnosis", "IMM", "predict-update-project", "switching linear dynamical system", "linear dynamical system", "state space model", "LDS", "nearest neighbor data association", "local level model", "Ricatti equations", "Gaussian sum \ufb01lter", "Xbox", "derivative free \ufb01lter", "EKF", "random accelerations model", "dynamic Bayes net", "radar", "sigma points", "regime switching", "two-\ufb01lter smoothing", "kalmanTrackingDemo", "expectation correction", "hybrid systems", "systems identi\ufb01cation", "forwards-backwards", "ARMA", "HMM \ufb01lter", "maximal weight bipartite matching", "innovation", "dynamic linear model", "Rao-Blackwellized particle \ufb01ltering", "TrueSkill", "Kalman gain matrix", "time-series forecasting", "multi-target tracking", "econometric forecasting", "jump Markov linear system", "RTS smoother", "data association", "linear-Gaussian SSM", "subspace method", "message passing", "junction trees", "correspondence", "weak marginalization", "simultaneous localization and mapping", "thin junction tree \ufb01lter", "Boyen-Koller", "Hungarian algorithm", "square root \ufb01lter"], "level": 1, "startpage": 661, "endpage": 690, "topicname": "18 State Space Models"}, {"keywordlist": ["LG-SSM", "SSM", "linear dynamical system", "state space model", "LDS", "linear-Gaussian SSM"], "level": 2, "startpage": 661, "endpage": 661, "topicname": "18.1 Introduction"}, {"keywordlist": ["sampling period", "structural time series", "Kalman smoother", "FastSLAM", "closing the loop", "ssmTimeSeriesSimple", "entanglement problem", "linregOnlineDemoKalman", "SLAM", "RLS", "slippage", "local level model", "random accelerations model", "kalmanTrackingDemo", "ARMA", "dynamic linear model", "Kalman gain matrix", "time-series forecasting", "junction trees", "simultaneous localization and mapping", "thin junction tree \ufb01lter"], "level": 2, "startpage": 662, "endpage": 669, "topicname": "18.2 Applications of SSMs"}, {"keywordlist": ["kalmanTrackingDemo"], "level": 3, "startpage": 662, "endpage": 662, "topicname": "18.2.1 SSMs for object tracking"}, {"keywordlist": ["sampling period", "Kalman smoother", "FastSLAM", "closing the loop", "entanglement problem", "SLAM", "slippage", "random accelerations model", "junction trees", "simultaneous localization and mapping", "thin junction tree \ufb01lter"], "level": 3, "startpage": 663, "endpage": 665, "topicname": "18.2.2 Robotic SLAM"}, {"keywordlist": ["linregOnlineDemoKalman", "RLS", "dynamic linear model"], "level": 3, "startpage": 666, "endpage": 666, "topicname": "18.2.3 Online parameter learning using recursive least squares"}, {"keywordlist": ["structural time series", "ssmTimeSeriesSimple", "local level model", "ARMA", "Kalman gain matrix", "time-series forecasting"], "level": 3, "startpage": 667, "endpage": 669, "topicname": "18.2.4 SSM for time series forecasting *"}, {"keywordlist": ["Kalman smoothing", "information \ufb01lter", "residual", "kalmanFilter", "Ricatti equations", "forwards-backwards", "HMM \ufb01lter", "innovation", "RTS smoother", "message passing", "square root \ufb01lter"], "level": 2, "startpage": 670, "endpage": 675, "topicname": "18.3 Inference in LG-SSM"}, {"keywordlist": ["information \ufb01lter", "residual", "kalmanFilter", "Ricatti equations", "HMM \ufb01lter", "innovation", "square root \ufb01lter"], "level": 3, "startpage": 670, "endpage": 672, "topicname": "18.3.1 The Kalman filtering algorithm"}, {"keywordlist": ["Kalman smoothing", "forwards-backwards", "RTS smoother", "message passing"], "level": 3, "startpage": 673, "endpage": 675, "topicname": "18.3.2 The Kalman smoothing algorithm"}, {"keywordlist": ["two-\ufb01lter smoothing", "systems identi\ufb01cation"], "level": 2, "startpage": 676, "endpage": 676, "topicname": "18.4 Learning for LG-SSM"}, {"keywordlist": ["two-\ufb01lter smoothing", "systems identi\ufb01cation"], "level": 3, "startpage": 676, "endpage": 676, "topicname": "18.4.1 Identifiability and numerical stability"}, {"keywordlist": ["subspace method"], "level": 3, "startpage": 677, "endpage": 677, "topicname": "18.4.2 Training with fully observed data"}, {"keywordlist": ["subspace method"], "level": 3, "startpage": 677, "endpage": 677, "topicname": "18.4.3 EM for LG-SSM"}, {"keywordlist": ["subspace method"], "level": 3, "startpage": 677, "endpage": 677, "topicname": "18.4.4 Subspace methods"}, {"keywordlist": ["subspace method"], "level": 3, "startpage": 677, "endpage": 677, "topicname": "18.4.5 Bayesian methods for \u201cfitting\u201d LG-SSMs"}, {"keywordlist": ["Taylor series expansion", "UKF", "assumed density \ufb01ltering", "extended Kalman \ufb01lter", "iterated EKF", "ADF", "unscented transform", "predict-update-project", "Xbox", "derivative free \ufb01lter", "EKF", "dynamic Bayes net", "sigma points", "TrueSkill", "subspace method", "Boyen-Koller"], "level": 2, "startpage": 677, "endpage": 684, "topicname": "18.5 Approximate online inference for non-linear, non-Gaussian SSMs"}, {"keywordlist": ["Taylor series expansion", "extended Kalman \ufb01lter", "EKF"], "level": 3, "startpage": 678, "endpage": 679, "topicname": "18.5.1 Extended Kalman filter (EKF)"}, {"keywordlist": ["UKF", "iterated EKF", "unscented transform", "derivative free \ufb01lter", "sigma points"], "level": 3, "startpage": 680, "endpage": 681, "topicname": "18.5.2 Unscented Kalman filter (UKF)"}, {"keywordlist": ["assumed density \ufb01ltering", "ADF", "predict-update-project", "Xbox", "dynamic Bayes net", "TrueSkill", "Boyen-Koller"], "level": 3, "startpage": 682, "endpage": 684, "topicname": "18.5.3 Assumed density filtering (ADF)"}, {"keywordlist": ["interactive multiple models", "switching state space model", "linear trend", "generalized pseudo Bayes \ufb01lter", "multiple hypothesis tracking", "fault diagnosis", "IMM", "switching linear dynamical system", "nearest neighbor data association", "Gaussian sum \ufb01lter", "radar", "regime switching", "expectation correction", "hybrid systems", "maximal weight bipartite matching", "Rao-Blackwellized particle \ufb01ltering", "multi-target tracking", "econometric forecasting", "jump Markov linear system", "data association", "correspondence", "weak marginalization", "Hungarian algorithm"], "level": 2, "startpage": 685, "endpage": 690, "topicname": "18.6 Hybrid discrete/continuous SSMs"}, {"keywordlist": ["generalized pseudo Bayes \ufb01lter", "multiple hypothesis tracking", "Gaussian sum \ufb01lter"], "level": 3, "startpage": 686, "endpage": 687, "topicname": "18.6.1 Inference"}, {"keywordlist": ["interactive multiple models", "IMM", "nearest neighbor data association", "radar", "expectation correction", "data association", "correspondence", "weak marginalization"], "level": 3, "startpage": 688, "endpage": 688, "topicname": "18.6.2 Application: data association and multi-target tracking"}, {"keywordlist": ["fault diagnosis", "maximal weight bipartite matching", "Rao-Blackwellized particle \ufb01ltering", "multi-target tracking", "Hungarian algorithm"], "level": 3, "startpage": 689, "endpage": 689, "topicname": "18.6.3 Application: fault diagnosis"}, {"keywordlist": ["linear trend", "regime switching", "econometric forecasting"], "level": 3, "startpage": 690, "endpage": 690, "topicname": "18.6.4 Application: econometric forecasting"}, {"keywordlist": ["Markov mesh", "Prolog", "chain graph", "latent CRF", "log-linear", "Gaussian MRF", "pipeline", "decomposable", "grammars", "pairwise MRF", "\ufb01rst-order logic", "discontinuity preserving", "structured perceptron algorithm", "MRF", "Pegasos", "gibbsDemoIsing", "iterative scaling", "loopy belief propagation", "statistical relational AI", "SSVMs", "M3ets", "slack re-scaling", "CCCP", "Horn clauses", "bi-directed graph", "decoding", "ancestral graph", "covariance graph", "structural equation models", "spin", "INDEX TO KEYWORDS production rules", "context free grammar", "bias term", "Ising model", "vector auto-regressive", "disparity", "external \ufb01eld", "metric CRF", "feature induction", "conjunctive normal form", "label bias", "undirected graphical model", "perfect map", "open universe", "semi-metric", "VAR", "discriminative random \ufb01eld", "shallow parsing", "template", "associative Markov network", "noun phrase chunking", "confounder", "Markov network", "composite likelihood", "contingency table", "stochastic maximum likelihood", "UGM", "Hammersley-Clifford", "rotamers", "max margin Markov networks", "persistent contrastive divergence", "knowledge base", "conditional random \ufb01eld", "frustrated system", "global Markov property", "closure", "constant symbols", "iterative conditional modes", "metric", "matrix permanent", "pattern completion", "Bayesian IPF", "efficient IPF", "locally normalized", "phase transition", "non-terminals", "named entity extraction", "linear-Gaussian CPD", "SVMstruct", "directed mixed graphical model", "inside-outside algorithm", "decomposable graphs", "critical value", "IPF", "concave-convex procedure", "moralization", "Markov random \ufb01eld", "terminals", "chordal", "Markov logic network", "partially observed MRF", "loss-calibrated inference", "ferro-magnets", "undirected local Markov property", "factor", "globally normalized", "pseudo likelihood", "content addressable memory", "HMMs", "energy based models", "clamped term", "alignment", "IPFdemo2x2", "contrastive term", "skip-chain CRF", "clausal form", "MEMM", "causal MRF", "structured output", "side chains", "potential function", "SML", "anti-ferromagnets", "unfaithful", "Chomsky normal form", "hop\ufb01eldDemo", "information extraction", "latent SVMs", "maximum entropy Markov model", "label taxonomy", "separation oracle", "BIO", "Potts model", "relational probabilistic models", "dense stereo reconstruction", "feature function", "dependency networks", "ground states", "CRF", "margin re-rescaling)", "image segmentation", "pairwise Markov property", "truncated Gaussian potential", "structural zeros", "loss-augmented decoding", "iterative proportional \ufb01tting", "lattice", "Gibbs sampler", "cutting plane", "certainty factors", "Low-level vision", "structural support vector machines", "probabilistic relational modeling", "ground network", "unclamped term", "PCFG"], "level": 1, "startpage": 691, "endpage": 736, "topicname": "19 Undirected Graphical Models (Markov Random Fields)"}, {"keywordlist": ["Markov mesh", "MRF", "undirected graphical model", "Markov network", "UGM", "global Markov property", "Markov random \ufb01eld", "causal MRF", "CRF"], "level": 2, "startpage": 691, "endpage": 691, "topicname": "19.1 Introduction"}, {"keywordlist": ["Markov mesh", "MRF", "ancestral graph", "undirected graphical model", "perfect map", "Markov network", "UGM", "global Markov property", "closure", "moralization", "Markov random \ufb01eld", "undirected local Markov property", "causal MRF", "unfaithful", "CRF", "pairwise Markov property"], "level": 2, "startpage": 691, "endpage": 694, "topicname": "19.2 Conditional independence properties of UGMs"}, {"keywordlist": ["Markov mesh", "MRF", "undirected graphical model", "Markov network", "UGM", "global Markov property", "closure", "Markov random \ufb01eld", "undirected local Markov property", "causal MRF", "CRF", "pairwise Markov property"], "level": 3, "startpage": 691, "endpage": 692, "topicname": "19.2.1 Key properties"}, {"keywordlist": ["moralization", "unfaithful"], "level": 3, "startpage": 693, "endpage": 693, "topicname": "19.2.2 An undirected alternative to d-separation"}, {"keywordlist": ["ancestral graph", "perfect map"], "level": 3, "startpage": 694, "endpage": 694, "topicname": "19.2.3 Comparing directed and undirected graphical models"}, {"keywordlist": ["log-linear", "decomposable", "pairwise MRF", "Hammersley-Clifford", "chordal", "factor", "energy based models", "potential function", "feature function"], "level": 2, "startpage": 695, "endpage": 697, "topicname": "19.3 Parameterization of MRFs"}, {"keywordlist": ["decomposable", "pairwise MRF", "Hammersley-Clifford", "chordal", "factor", "energy based models", "potential function"], "level": 3, "startpage": 695, "endpage": 696, "topicname": "19.3.1 The Hammersley-Clifford theorem"}, {"keywordlist": ["log-linear", "feature function"], "level": 3, "startpage": 697, "endpage": 697, "topicname": "19.3.2 Representing potential functions"}, {"keywordlist": ["chain graph", "Gaussian MRF", "\ufb01rst-order logic", "gibbsDemoIsing", "statistical relational AI", "bi-directed graph", "covariance graph", "structural equation models", "spin", "bias term", "Ising model", "vector auto-regressive", "external \ufb01eld", "conjunctive normal form", "VAR", "associative Markov network", "confounder", "frustrated system", "iterative conditional modes", "matrix permanent", "pattern completion", "phase transition", "linear-Gaussian CPD", "directed mixed graphical model", "critical value", "Markov logic network", "partially observed MRF", "ferro-magnets", "content addressable memory", "clausal form", "anti-ferromagnets", "hop\ufb01eldDemo", "Potts model", "ground states", "image segmentation", "structural zeros", "lattice", "Gibbs sampler", "certainty factors", "probabilistic relational modeling"], "level": 2, "startpage": 698, "endpage": 705, "topicname": "19.4 Examples of MRFs"}, {"keywordlist": ["spin", "Ising model", "external \ufb01eld", "associative Markov network", "frustrated system", "ferro-magnets", "anti-ferromagnets", "ground states", "lattice"], "level": 3, "startpage": 698, "endpage": 698, "topicname": "19.4.1 Ising model"}, {"keywordlist": ["gibbsDemoIsing", "bias term", "iterative conditional modes", "matrix permanent", "pattern completion", "content addressable memory", "hop\ufb01eldDemo"], "level": 3, "startpage": 699, "endpage": 700, "topicname": "19.4.2 Hopfield networks"}, {"keywordlist": ["chain graph", "phase transition", "critical value", "Potts model", "image segmentation"], "level": 3, "startpage": 701, "endpage": 701, "topicname": "19.4.3 Potts model"}, {"keywordlist": ["Gaussian MRF", "vector auto-regressive", "VAR", "linear-Gaussian CPD", "partially observed MRF", "structural zeros", "Gibbs sampler"], "level": 3, "startpage": 702, "endpage": 703, "topicname": "19.4.4 Gaussian MRFs"}, {"keywordlist": ["\ufb01rst-order logic", "statistical relational AI", "bi-directed graph", "covariance graph", "structural equation models", "conjunctive normal form", "confounder", "directed mixed graphical model", "Markov logic network", "clausal form", "certainty factors", "probabilistic relational modeling"], "level": 3, "startpage": 704, "endpage": 705, "topicname": "19.4.5 Markov logic networks *"}, {"keywordlist": ["Prolog", "iterative scaling", "Horn clauses", "feature induction", "open universe", "template", "composite likelihood", "contingency table", "stochastic maximum likelihood", "persistent contrastive divergence", "knowledge base", "constant symbols", "Bayesian IPF", "efficient IPF", "decomposable graphs", "IPF", "pseudo likelihood", "clamped term", "IPFdemo2x2", "contrastive term", "SML", "relational probabilistic models", "dependency networks", "iterative proportional \ufb01tting", "ground network", "unclamped term"], "level": 2, "startpage": 706, "endpage": 713, "topicname": "19.5 Learning"}, {"keywordlist": ["Prolog", "Horn clauses", "open universe", "template", "knowledge base", "constant symbols", "relational probabilistic models", "ground network"], "level": 3, "startpage": 706, "endpage": 706, "topicname": "19.5.1 Training maxent models using gradient methods"}, {"keywordlist": ["clamped term", "contrastive term", "unclamped term"], "level": 3, "startpage": 707, "endpage": 707, "topicname": "19.5.2 Training partially observed maxent models"}, {"keywordlist": ["composite likelihood", "pseudo likelihood"], "level": 3, "startpage": 708, "endpage": 708, "topicname": "19.5.3 Approximate methods for computing the MLEs of MRFs"}, {"keywordlist": ["composite likelihood", "pseudo likelihood"], "level": 3, "startpage": 708, "endpage": 708, "topicname": "19.5.4 Pseudo likelihood"}, {"keywordlist": ["dependency networks"], "level": 3, "startpage": 709, "endpage": 709, "topicname": "19.5.5 Stochastic maximum likelihood"}, {"keywordlist": ["feature induction", "stochastic maximum likelihood", "persistent contrastive divergence", "SML"], "level": 3, "startpage": 710, "endpage": 710, "topicname": "19.5.6 Feature induction for maxent models *"}, {"keywordlist": ["iterative scaling", "contingency table", "Bayesian IPF", "efficient IPF", "decomposable graphs", "IPF", "IPFdemo2x2", "iterative proportional \ufb01tting"], "level": 3, "startpage": 711, "endpage": 713, "topicname": "19.5.7 Iterative proportional fitting (IPF) *"}, {"keywordlist": ["pipeline", "grammars", "discontinuity preserving", "loopy belief propagation", "INDEX TO KEYWORDS production rules", "context free grammar", "disparity", "metric CRF", "label bias", "semi-metric", "discriminative random \ufb01eld", "shallow parsing", "noun phrase chunking", "rotamers", "conditional random \ufb01eld", "metric", "locally normalized", "non-terminals", "named entity extraction", "inside-outside algorithm", "terminals", "globally normalized", "HMMs", "skip-chain CRF", "MEMM", "structured output", "side chains", "Chomsky normal form", "information extraction", "maximum entropy Markov model", "label taxonomy", "BIO", "dense stereo reconstruction", "truncated Gaussian potential", "Low-level vision", "PCFG"], "level": 2, "startpage": 714, "endpage": 722, "topicname": "19.6 Conditional random fields (CRFs)"}, {"keywordlist": ["label bias", "discriminative random \ufb01eld", "conditional random \ufb01eld", "HMMs", "MEMM", "structured output", "maximum entropy Markov model"], "level": 3, "startpage": 714, "endpage": 715, "topicname": "19.6.1 Chain-structured CRFs, MEMMs and the label-bias problem"}, {"keywordlist": ["pipeline", "grammars", "discontinuity preserving", "loopy belief propagation", "INDEX TO KEYWORDS production rules", "context free grammar", "disparity", "metric CRF", "semi-metric", "shallow parsing", "noun phrase chunking", "rotamers", "metric", "locally normalized", "non-terminals", "named entity extraction", "inside-outside algorithm", "terminals", "globally normalized", "skip-chain CRF", "side chains", "Chomsky normal form", "information extraction", "label taxonomy", "BIO", "dense stereo reconstruction", "truncated Gaussian potential", "Low-level vision", "PCFG"], "level": 3, "startpage": 716, "endpage": 721, "topicname": "19.6.2 Applications of CRFs"}, {"keywordlist": [], "level": 3, "startpage": 722, "endpage": 722, "topicname": "19.6.3 CRF training"}, {"keywordlist": ["latent CRF", "structured perceptron algorithm", "Pegasos", "SSVMs", "M3ets", "slack re-scaling", "CCCP", "decoding", "max margin Markov networks", "SVMstruct", "concave-convex procedure", "loss-calibrated inference", "alignment", "latent SVMs", "separation oracle", "margin re-rescaling)", "loss-augmented decoding", "cutting plane", "structural support vector machines"], "level": 2, "startpage": 723, "endpage": 736, "topicname": "19.7 Structural SVMs"}, {"keywordlist": ["SSVMs", "M3ets", "decoding", "max margin Markov networks", "loss-calibrated inference", "structural support vector machines"], "level": 3, "startpage": 723, "endpage": 724, "topicname": "19.7.1 SSVMs: a probabilistic view"}, {"keywordlist": ["slack re-scaling", "margin re-rescaling)"], "level": 3, "startpage": 725, "endpage": 727, "topicname": "19.7.2 SSVMs: a non-probabilistic view"}, {"keywordlist": ["SVMstruct", "separation oracle", "loss-augmented decoding", "cutting plane"], "level": 3, "startpage": 728, "endpage": 729, "topicname": "19.7.3 Cutting plane methods for fitting SSVMs"}, {"keywordlist": ["structured perceptron algorithm"], "level": 3, "startpage": 730, "endpage": 730, "topicname": "19.7.4 Online algorithms for fitting SSVMs"}, {"keywordlist": ["latent CRF", "Pegasos", "CCCP", "concave-convex procedure", "alignment", "latent SVMs"], "level": 3, "startpage": 731, "endpage": 736, "topicname": "19.7.5 Latent structural SVMs"}, {"keywordlist": ["out-of-clique query", "diameter", "pushing sums inside products", "approximate inference", "constraint satisfaction problems", "clause", "heuristics", "running intersection property", "junction tree algorithm", "collect-to-root", "commutative semi-ring", "commutative semiring", "distributive law", "induced width", "non-parametric BP", "junction tree", "separating set", "polynomial time approximation schemes", "bucket elimination", "Hugin", "#P-hard", "satisfying assignment", "cliques", "non-serial dynamic programming", "chordal graph", "distribute evidence", "systolic array", "passing a \ufb02ow", "JTA", "NP-hard", "3-SAT", "sum-product algorithm", "Shafer-Shenoy", "triangulated", "logical reasoning problems", "Gauss-Seidel", "\ufb01ll-in edges", "collect evidence", "fast Fourier transform", "Lauritzen-Spiegelhalter", "elimination order", "variableElimination", "Gaussian graphical models", "peeling algorithm", "distribute-from-root", "Jacobi", "BP", "belief updating", "calibration"], "level": 1, "startpage": 737, "endpage": 760, "topicname": "20 Exact Inference for Graphical Models"}, {"keywordlist": ["distribute evidence", "sum-product algorithm", "collect evidence", "BP"], "level": 2, "startpage": 737, "endpage": 737, "topicname": "20.1 Introduction"}, {"keywordlist": ["diameter", "non-parametric BP", "distribute evidence", "systolic array", "sum-product algorithm", "Gauss-Seidel", "collect evidence", "Jacobi", "BP", "belief updating"], "level": 2, "startpage": 737, "endpage": 743, "topicname": "20.2 Belief propagation for trees"}, {"keywordlist": ["distribute evidence", "sum-product algorithm", "collect evidence", "BP"], "level": 3, "startpage": 737, "endpage": 738, "topicname": "20.2.1 Serial protocol"}, {"keywordlist": ["belief updating"], "level": 3, "startpage": 739, "endpage": 739, "topicname": "20.2.2 Parallel protocol"}, {"keywordlist": ["diameter", "systolic array", "Gauss-Seidel", "Jacobi"], "level": 3, "startpage": 740, "endpage": 741, "topicname": "20.2.3 Gaussian BP *"}, {"keywordlist": ["non-parametric BP"], "level": 3, "startpage": 742, "endpage": 743, "topicname": "20.2.4 Other BP variants *"}, {"keywordlist": ["pushing sums inside products", "constraint satisfaction problems", "commutative semi-ring", "distributive law", "induced width", "bucket elimination", "cliques", "non-serial dynamic programming", "\ufb01ll-in edges", "fast Fourier transform", "elimination order", "variableElimination", "peeling algorithm"], "level": 2, "startpage": 744, "endpage": 749, "topicname": "20.3 The variable elimination algorithm"}, {"keywordlist": ["constraint satisfaction problems", "commutative semi-ring", "distributive law", "non-serial dynamic programming", "fast Fourier transform", "variableElimination"], "level": 3, "startpage": 747, "endpage": 747, "topicname": "20.3.1 The generalized distributive law *"}, {"keywordlist": ["constraint satisfaction problems", "commutative semi-ring", "distributive law", "induced width", "cliques", "non-serial dynamic programming", "\ufb01ll-in edges", "fast Fourier transform", "elimination order", "variableElimination"], "level": 3, "startpage": 747, "endpage": 749, "topicname": "20.3.2 Computational complexity of VE"}, {"keywordlist": ["junction tree algorithm", "chordal graph", "JTA"], "level": 3, "startpage": 750, "endpage": 750, "topicname": "20.3.3 A weakness of VE"}, {"keywordlist": ["out-of-clique query", "running intersection property", "junction tree algorithm", "collect-to-root", "junction tree", "separating set", "Hugin", "chordal graph", "passing a \ufb02ow", "JTA", "Shafer-Shenoy", "triangulated", "Lauritzen-Spiegelhalter", "Gaussian graphical models", "distribute-from-root", "calibration"], "level": 2, "startpage": 750, "endpage": 755, "topicname": "20.4 The junction tree algorithm *"}, {"keywordlist": ["junction tree algorithm", "chordal graph", "JTA"], "level": 3, "startpage": 750, "endpage": 751, "topicname": "20.4.1 Creating a junction tree"}, {"keywordlist": ["out-of-clique query", "running intersection property", "collect-to-root", "junction tree", "separating set", "Hugin", "passing a \ufb02ow", "Shafer-Shenoy", "triangulated", "Lauritzen-Spiegelhalter", "distribute-from-root", "calibration"], "level": 3, "startpage": 752, "endpage": 754, "topicname": "20.4.2 Message passing on a junction tree"}, {"keywordlist": ["Gaussian graphical models"], "level": 3, "startpage": 755, "endpage": 755, "topicname": "20.4.3 Computational complexity of JTA"}, {"keywordlist": ["commutative semiring", "NP-hard", "logical reasoning problems"], "level": 3, "startpage": 756, "endpage": 756, "topicname": "20.4.4 JTA generalizations *"}, {"keywordlist": ["approximate inference", "clause", "heuristics", "commutative semiring", "polynomial time approximation schemes", "#P-hard", "satisfying assignment", "NP-hard", "3-SAT", "logical reasoning problems"], "level": 2, "startpage": 756, "endpage": 760, "topicname": "20.5 Computational intractability of exact inference in the worst case"}, {"keywordlist": ["approximate inference", "clause", "heuristics", "polynomial time approximation schemes", "#P-hard", "satisfying assignment", "3-SAT"], "level": 3, "startpage": 757, "endpage": 760, "topicname": "20.5.1 Approximate inference"}, {"keywordlist": ["multivariate delta method", "free-form optimization", "variational Bayes", "forwards KL", "moment projection", "parameter expansion", "sigmoidLowerBounds", "reverse KL", "zero forcing", "VB", "M-projection", "information projection", "rich get richer", "correlated topic model", "mean \ufb01eld", "I-projection", "energy functional", "VIBES", "damped updates", "zero avoiding", "variational message passing", "local variational approximation", "pattern search", "Helmholtz free energy", "mixGaussVbDemoFaithful", "alpha divergence", "structured mean \ufb01eld", "tractable substructure", "VBEM", "Hellinger distance", "topic model", "VMP", "unigaussVbDemo", "JJ bound", "bits-back", "BUGS", "isingImageDenoiseDemo", "expectation proagation", "variational free energy", "lse", "sigmoid belief nets", "KLfwdReverseMixGauss", "ensemble learning", "KLpqGauss"], "level": 1, "startpage": 761, "endpage": 796, "topicname": "21 Variational Inference"}, {"keywordlist": [], "level": 2, "startpage": 761, "endpage": 761, "topicname": "21.1 Introduction"}, {"keywordlist": ["forwards KL", "moment projection", "reverse KL", "zero forcing", "M-projection", "information projection", "I-projection", "energy functional", "zero avoiding", "Helmholtz free energy", "bits-back", "variational free energy", "KLfwdReverseMixGauss", "KLpqGauss"], "level": 2, "startpage": 762, "endpage": 764, "topicname": "21.2 Variational inference"}, {"keywordlist": ["forwards KL", "moment projection", "reverse KL", "zero forcing", "M-projection", "information projection", "I-projection", "zero avoiding", "Helmholtz free energy", "bits-back", "variational free energy"], "level": 3, "startpage": 763, "endpage": 763, "topicname": "21.2.1 Alternative interpretations of the variational objective"}, {"keywordlist": ["forwards KL", "moment projection", "reverse KL", "zero forcing", "M-projection", "information projection", "I-projection", "zero avoiding", "Helmholtz free energy", "bits-back", "variational free energy", "KLfwdReverseMixGauss", "KLpqGauss"], "level": 3, "startpage": 763, "endpage": 764, "topicname": "21.2.2 Forward or reverse KL? *"}, {"keywordlist": ["free-form optimization", "parameter expansion", "mean \ufb01eld", "pattern search", "alpha divergence", "Hellinger distance", "expectation proagation"], "level": 2, "startpage": 765, "endpage": 768, "topicname": "21.3 The mean field method"}, {"keywordlist": ["parameter expansion", "pattern search"], "level": 3, "startpage": 766, "endpage": 766, "topicname": "21.3.1 Derivation of the mean field update equations"}, {"keywordlist": ["free-form optimization"], "level": 3, "startpage": 767, "endpage": 768, "topicname": "21.3.2 Example: mean field for the Ising model"}, {"keywordlist": ["damped updates", "structured mean \ufb01eld", "tractable substructure", "isingImageDenoiseDemo"], "level": 2, "startpage": 769, "endpage": 771, "topicname": "21.4 Structured mean field *"}, {"keywordlist": ["structured mean \ufb01eld"], "level": 3, "startpage": 770, "endpage": 771, "topicname": "21.4.1 Example: factorial HMM"}, {"keywordlist": ["variational Bayes", "VB", "unigaussVbDemo", "ensemble learning"], "level": 2, "startpage": 772, "endpage": 778, "topicname": "21.5 Variational Bayes"}, {"keywordlist": ["variational Bayes", "VB", "unigaussVbDemo", "ensemble learning"], "level": 3, "startpage": 772, "endpage": 775, "topicname": "21.5.1 Example: VB for a univariate Gaussian"}, {"keywordlist": [], "level": 3, "startpage": 776, "endpage": 778, "topicname": "21.5.2 Example: VB for linear regression"}, {"keywordlist": ["rich get richer", "mixGaussVbDemoFaithful", "VBEM"], "level": 2, "startpage": 779, "endpage": 785, "topicname": "21.6 Variational Bayes EM"}, {"keywordlist": ["rich get richer", "mixGaussVbDemoFaithful", "VBEM"], "level": 3, "startpage": 780, "endpage": 785, "topicname": "21.6.1 Example: VBEM for mixtures of Gaussians *"}, {"keywordlist": ["VIBES", "variational message passing", "local variational approximation", "VMP", "BUGS"], "level": 2, "startpage": 786, "endpage": 786, "topicname": "21.7 Variational message passing and VIBES"}, {"keywordlist": ["multivariate delta method", "sigmoidLowerBounds", "correlated topic model", "VIBES", "variational message passing", "local variational approximation", "topic model", "VMP", "JJ bound", "BUGS", "lse", "sigmoid belief nets"], "level": 2, "startpage": 786, "endpage": 796, "topicname": "21.8 Local variational bounds *"}, {"keywordlist": ["correlated topic model", "VIBES", "variational message passing", "local variational approximation", "topic model", "VMP", "BUGS", "lse"], "level": 3, "startpage": 786, "endpage": 787, "topicname": "21.8.1 Motivating applications"}, {"keywordlist": [], "level": 3, "startpage": 788, "endpage": 789, "topicname": "21.8.2 Bohning\u2019s quadratic bound to the log-sum-exp function"}, {"keywordlist": ["sigmoidLowerBounds", "JJ bound"], "level": 3, "startpage": 790, "endpage": 791, "topicname": "21.8.3 Bounds for the sigmoid function"}, {"keywordlist": [], "level": 3, "startpage": 792, "endpage": 792, "topicname": "21.8.4 Other bounds and approximations to the log-sum-exp function"}, {"keywordlist": ["multivariate delta method", "sigmoid belief nets"], "level": 3, "startpage": 793, "endpage": 796, "topicname": "21.8.5 Variational inference based on upper bounds"}, {"keywordlist": ["INDEX TO KEYWORDS local consistency", "associative MRF", "linear programming relaxtion", "Bethe free energy", "clutter problem", "factor graph", "Kikuchi free energy", "distance transform", "master", "inner approximation", "max \ufb02ow/min cut", "alpha-beta swap", "Bradley Terry", "error correcting codes", "beliefPropagation", "synchronous updates", "Bethe", "edge appearance probability", "INDEX TO KEYWORDS convex belief propagation", "Expectation propagation", "residual belief propagation", "trueskillDemo", "attractive MRF", "max product linear programming", "mean \ufb01eld energy functional", "cascade", "Lagrangian relaxation", "strong local optimum", "submodular", "asynchronous updates", "locally decodable", "TRBP-S", "slaves", "double loop algorithms", "TRW-S", "cluster variational method", "low density parity check", "INDEX TO CODE trueskillPlot", "damping", "Mobious numbers", "tree reweighted belief propagation", "TRW", "Cardinality constraints", "marginal polytope", "max-product belief propagation", "outer approximation", "supermodular", "LDPC", "pseudo marginals", "tree EP", "inferet", "spanning tree polytope", "TRBP", "sequential TRBP", "convex hull", "branch and bound", "dual decomposition", "graphcuts", "computation tree", "FFT", "alpha expansion", "tree reparameterization", "Bethe energy functional", "coarse-to-\ufb01ne grid", "zero temperature limit", "multi-grid techniques", "LBP", "turbo codes", "standard overcomplete representation", "overcounting number", "generalized belief propagation", "metric MRF"], "level": 1, "startpage": 797, "endpage": 844, "topicname": "22 More Variational Inference"}, {"keywordlist": ["LBP"], "level": 2, "startpage": 797, "endpage": 797, "topicname": "22.1 Introduction"}, {"keywordlist": ["factor graph", "distance transform", "error correcting codes", "beliefPropagation", "synchronous updates", "residual belief propagation", "asynchronous updates", "double loop algorithms", "low density parity check", "damping", "LDPC", "computation tree", "FFT", "tree reparameterization", "coarse-to-\ufb01ne grid", "multi-grid techniques", "LBP", "turbo codes"], "level": 2, "startpage": 797, "endpage": 805, "topicname": "22.2 Loopy belief propagation: algorithmic issues"}, {"keywordlist": ["LBP"], "level": 3, "startpage": 797, "endpage": 797, "topicname": "22.2.1 A brief history"}, {"keywordlist": ["error correcting codes", "beliefPropagation", "low density parity check", "LDPC", "turbo codes"], "level": 3, "startpage": 798, "endpage": 798, "topicname": "22.2.2 LBP on pairwise models"}, {"keywordlist": ["factor graph"], "level": 3, "startpage": 799, "endpage": 800, "topicname": "22.2.3 LBP on a factor graph"}, {"keywordlist": ["synchronous updates", "double loop algorithms", "damping", "computation tree"], "level": 3, "startpage": 801, "endpage": 803, "topicname": "22.2.4 Convergence"}, {"keywordlist": ["residual belief propagation", "asynchronous updates", "tree reparameterization"], "level": 3, "startpage": 804, "endpage": 804, "topicname": "22.2.5 Accuracy of LBP"}, {"keywordlist": ["distance transform", "FFT", "coarse-to-\ufb01ne grid", "multi-grid techniques"], "level": 3, "startpage": 805, "endpage": 805, "topicname": "22.2.6 Other speedup tricks for LBP *"}, {"keywordlist": ["INDEX TO KEYWORDS local consistency", "Bethe free energy", "inner approximation", "Bethe", "mean \ufb01eld energy functional", "cascade", "marginal polytope", "outer approximation", "pseudo marginals", "convex hull", "Bethe energy functional", "standard overcomplete representation"], "level": 2, "startpage": 806, "endpage": 812, "topicname": "22.3 Loopy belief propagation: theoretical issues *"}, {"keywordlist": ["cascade", "standard overcomplete representation"], "level": 3, "startpage": 806, "endpage": 806, "topicname": "22.3.1 UGMs represented in exponential family form"}, {"keywordlist": ["marginal polytope", "convex hull"], "level": 3, "startpage": 807, "endpage": 807, "topicname": "22.3.2 The marginal polytope"}, {"keywordlist": [], "level": 3, "startpage": 808, "endpage": 808, "topicname": "22.3.3 Exact inference as a variational optimization problem"}, {"keywordlist": ["inner approximation", "mean \ufb01eld energy functional"], "level": 3, "startpage": 809, "endpage": 809, "topicname": "22.3.4 Mean field as a variational optimization problem"}, {"keywordlist": ["INDEX TO KEYWORDS local consistency", "Bethe free energy", "inner approximation", "Bethe", "mean \ufb01eld energy functional", "outer approximation", "pseudo marginals", "Bethe energy functional"], "level": 3, "startpage": 809, "endpage": 812, "topicname": "22.3.5 LBP as a variational optimization problem"}, {"keywordlist": ["cluster variational method"], "level": 3, "startpage": 813, "endpage": 813, "topicname": "22.3.6 Loopy BP vs mean field"}, {"keywordlist": ["Kikuchi free energy", "edge appearance probability", "INDEX TO KEYWORDS convex belief propagation", "cluster variational method", "Mobious numbers", "tree reweighted belief propagation", "spanning tree polytope", "overcounting number", "generalized belief propagation"], "level": 2, "startpage": 813, "endpage": 816, "topicname": "22.4 Extensions of belief propagation *"}, {"keywordlist": ["Kikuchi free energy", "cluster variational method", "Mobious numbers", "overcounting number"], "level": 3, "startpage": 813, "endpage": 814, "topicname": "22.4.1 Generalized belief propagation"}, {"keywordlist": ["edge appearance probability", "INDEX TO KEYWORDS convex belief propagation", "tree reweighted belief propagation", "spanning tree polytope", "generalized belief propagation"], "level": 3, "startpage": 815, "endpage": 816, "topicname": "22.4.2 Convex belief propagation"}, {"keywordlist": ["clutter problem", "Bradley Terry", "Expectation propagation", "trueskillDemo", "INDEX TO CODE trueskillPlot", "TRW", "tree EP", "TRBP"], "level": 2, "startpage": 817, "endpage": 828, "topicname": "22.5 Expectation propagation"}, {"keywordlist": ["clutter problem"], "level": 3, "startpage": 818, "endpage": 818, "topicname": "22.5.1 EP as a variational inference p"}, {"keywordlist": [], "level": 3, "startpage": 819, "endpage": 820, "topicname": "22.5.2 Optimizing the EP objective using moment matching"}, {"keywordlist": [], "level": 3, "startpage": 821, "endpage": 821, "topicname": "22.5.3 EP for the clutter problem"}, {"keywordlist": [], "level": 3, "startpage": 822, "endpage": 822, "topicname": "22.5.4 LBP is a special case of EP"}, {"keywordlist": ["Bradley Terry", "trueskillDemo", "INDEX TO CODE trueskillPlot", "tree EP"], "level": 3, "startpage": 823, "endpage": 828, "topicname": "22.5.5 Ranking players using TrueSkill"}, {"keywordlist": ["inferet"], "level": 3, "startpage": 829, "endpage": 829, "topicname": "22.5.6 Other applications of EP"}, {"keywordlist": ["associative MRF", "linear programming relaxtion", "master", "max \ufb02ow/min cut", "alpha-beta swap", "attractive MRF", "max product linear programming", "Lagrangian relaxation", "strong local optimum", "submodular", "locally decodable", "TRBP-S", "slaves", "TRW-S", "Cardinality constraints", "max-product belief propagation", "supermodular", "inferet", "sequential TRBP", "branch and bound", "dual decomposition", "graphcuts", "alpha expansion", "zero temperature limit", "metric MRF"], "level": 2, "startpage": 829, "endpage": 844, "topicname": "22.6 MAP state estimation"}, {"keywordlist": ["inferet"], "level": 3, "startpage": 829, "endpage": 829, "topicname": "22.6.1 Linear programming relaxation"}, {"keywordlist": ["linear programming relaxtion", "max-product belief propagation", "zero temperature limit"], "level": 3, "startpage": 830, "endpage": 830, "topicname": "22.6.2 Max-product belief propagation"}, {"keywordlist": ["associative MRF", "max \ufb02ow/min cut", "attractive MRF", "submodular", "TRBP-S", "TRW-S", "supermodular", "sequential TRBP", "graphcuts", "alpha expansion", "metric MRF"], "level": 3, "startpage": 831, "endpage": 833, "topicname": "22.6.3 Graphcuts"}, {"keywordlist": ["alpha-beta swap", "strong local optimum"], "level": 3, "startpage": 834, "endpage": 835, "topicname": "22.6.4 Experimental comparison of graphcuts and BP"}, {"keywordlist": ["master", "max product linear programming", "Lagrangian relaxation", "locally decodable", "slaves", "Cardinality constraints", "branch and bound", "dual decomposition"], "level": 3, "startpage": 836, "endpage": 844, "topicname": "22.6.5 Dual decomposition"}, {"keywordlist": ["proposal distribution", "Bhattacharya distance", "bootstrap \ufb01lter", "Monte Carlo localization", "super efficient", "RBPF", "tracking by detection", "rejuvenation", "likelihood weighting", "simulation based", "rejectionSamplingDemo", "sampleCdf", "logic sampling", "global localization", "rbpfManeuverDemo", "rejection sampling", "pseudo random number generator", "Box-Muller", "resample-move", "tracking", "importance weights", "INDEX TO KEYWORDS stochastic volatility", "adaptive rejection Metropolis sampling", "condensation", "SIR", "rbpfSlamDemo", "data-driven proposals", "residual resampling", "strati\ufb01ed sampling", "look-ahead RBPF", "adaptive rejection sampling", "systematic resampling", "ancestral sampling", "multinomial resampling", "Particle \ufb01ltering", "importance sampling", "perceptual aliasing", "regularized particle \ufb01lter", "unscented particle \ufb01lter", "adaptive importance sampling", "arsEnvelope", "sample impoverishment", "maneuvering target tracking", "collapsed particles", "arsDemo", "Rao-Blackwellised particle \ufb01ltering", "distributional particles", "occupancy grid", "survival of the \ufb01ttest", "Markov Chain Monte Carlo", "degeneracy problem", "mixture of Kalman \ufb01lters", "pfColorTrackerDemo", "sampling importance resampling", "inverse probability transform"], "level": 1, "startpage": 845, "endpage": 866, "topicname": "23 Monte Carlo Inference"}, {"keywordlist": ["Markov Chain Monte Carlo", "inverse probability transform"], "level": 2, "startpage": 845, "endpage": 845, "topicname": "23.1 Introduction"}, {"keywordlist": ["sampleCdf", "pseudo random number generator", "Markov Chain Monte Carlo", "inverse probability transform"], "level": 2, "startpage": 845, "endpage": 846, "topicname": "23.2 Sampling from standard distributions"}, {"keywordlist": ["sampleCdf", "pseudo random number generator", "Markov Chain Monte Carlo", "inverse probability transform"], "level": 3, "startpage": 845, "endpage": 846, "topicname": "23.2.1 Using the cdf"}, {"keywordlist": ["proposal distribution", "rejection sampling", "Box-Muller"], "level": 3, "startpage": 847, "endpage": 847, "topicname": "23.2.2 Sampling from a Gaussian (Box-Muller method)"}, {"keywordlist": ["proposal distribution", "rejectionSamplingDemo", "rejection sampling", "Box-Muller", "arsEnvelope", "arsDemo"], "level": 2, "startpage": 847, "endpage": 849, "topicname": "23.3 Rejection sampling"}, {"keywordlist": ["proposal distribution", "rejection sampling", "Box-Muller"], "level": 3, "startpage": 847, "endpage": 847, "topicname": "23.3.1 Basic idea"}, {"keywordlist": ["rejectionSamplingDemo"], "level": 3, "startpage": 848, "endpage": 848, "topicname": "23.3.2 Example"}, {"keywordlist": ["arsEnvelope", "arsDemo"], "level": 3, "startpage": 849, "endpage": 849, "topicname": "23.3.3 Application to Bayesian statistics"}, {"keywordlist": ["arsEnvelope", "arsDemo"], "level": 3, "startpage": 849, "endpage": 849, "topicname": "23.3.4 Adaptive rejection sampling"}, {"keywordlist": ["super efficient", "adaptive rejection Metropolis sampling", "adaptive rejection sampling", "importance sampling"], "level": 3, "startpage": 850, "endpage": 850, "topicname": "23.3.5 Rejection sampling in high dimensions"}, {"keywordlist": ["super efficient", "likelihood weighting", "logic sampling", "importance weights", "adaptive rejection Metropolis sampling", "adaptive rejection sampling", "ancestral sampling", "importance sampling", "adaptive importance sampling"], "level": 2, "startpage": 850, "endpage": 852, "topicname": "23.4 Importance sampling"}, {"keywordlist": ["super efficient", "adaptive rejection Metropolis sampling", "adaptive rejection sampling", "importance sampling"], "level": 3, "startpage": 850, "endpage": 850, "topicname": "23.4.1 Basic idea"}, {"keywordlist": ["importance weights", "adaptive importance sampling"], "level": 3, "startpage": 851, "endpage": 851, "topicname": "23.4.2 Handling unnormalized distributions"}, {"keywordlist": ["likelihood weighting", "logic sampling", "ancestral sampling"], "level": 3, "startpage": 852, "endpage": 852, "topicname": "23.4.3 Importance sampling for a DGM: likelihood weighting"}, {"keywordlist": ["likelihood weighting", "logic sampling", "ancestral sampling"], "level": 3, "startpage": 852, "endpage": 852, "topicname": "23.4.4 Sampling importance resampling (SIR)"}, {"keywordlist": ["Bhattacharya distance", "bootstrap \ufb01lter", "Monte Carlo localization", "tracking by detection", "rejuvenation", "simulation based", "global localization", "resample-move", "tracking", "condensation", "SIR", "data-driven proposals", "residual resampling", "strati\ufb01ed sampling", "systematic resampling", "multinomial resampling", "Particle \ufb01ltering", "perceptual aliasing", "regularized particle \ufb01lter", "unscented particle \ufb01lter", "sample impoverishment", "occupancy grid", "survival of the \ufb01ttest", "degeneracy problem", "pfColorTrackerDemo", "sampling importance resampling"], "level": 2, "startpage": 853, "endpage": 860, "topicname": "23.5 Particle filtering"}, {"keywordlist": [], "level": 3, "startpage": 854, "endpage": 854, "topicname": "23.5.1 Sequential importance sampling"}, {"keywordlist": ["rejuvenation", "survival of the \ufb01ttest", "degeneracy problem"], "level": 3, "startpage": 855, "endpage": 855, "topicname": "23.5.2 The degeneracy problem"}, {"keywordlist": ["rejuvenation", "residual resampling", "strati\ufb01ed sampling", "systematic resampling", "multinomial resampling", "sample impoverishment", "survival of the \ufb01ttest", "degeneracy problem"], "level": 3, "startpage": 855, "endpage": 856, "topicname": "23.5.3 The resampling step"}, {"keywordlist": ["bootstrap \ufb01lter", "resample-move", "condensation", "regularized particle \ufb01lter"], "level": 3, "startpage": 857, "endpage": 857, "topicname": "23.5.4 The proposal distribution"}, {"keywordlist": ["Bhattacharya distance", "Monte Carlo localization", "global localization", "data-driven proposals", "perceptual aliasing", "unscented particle \ufb01lter", "occupancy grid"], "level": 3, "startpage": 858, "endpage": 858, "topicname": "23.5.5 Application: robot localization"}, {"keywordlist": ["Bhattacharya distance", "Monte Carlo localization", "tracking by detection", "global localization", "data-driven proposals", "perceptual aliasing", "unscented particle \ufb01lter", "occupancy grid", "pfColorTrackerDemo"], "level": 3, "startpage": 858, "endpage": 860, "topicname": "23.5.6 Application: visual object tracking"}, {"keywordlist": ["RBPF", "INDEX TO KEYWORDS stochastic volatility", "collapsed particles", "Rao-Blackwellised particle \ufb01ltering", "distributional particles", "mixture of Kalman \ufb01lters"], "level": 3, "startpage": 861, "endpage": 861, "topicname": "23.5.7 Application: time series forecasting"}, {"keywordlist": ["RBPF", "rbpfManeuverDemo", "INDEX TO KEYWORDS stochastic volatility", "rbpfSlamDemo", "look-ahead RBPF", "maneuvering target tracking", "collapsed particles", "Rao-Blackwellised particle \ufb01ltering", "distributional particles", "mixture of Kalman \ufb01lters"], "level": 2, "startpage": 861, "endpage": 866, "topicname": "23.6 Rao-Blackwellised particle filtering (RBPF)"}, {"keywordlist": ["RBPF", "INDEX TO KEYWORDS stochastic volatility", "collapsed particles", "Rao-Blackwellised particle \ufb01ltering", "distributional particles", "mixture of Kalman \ufb01lters"], "level": 3, "startpage": 861, "endpage": 861, "topicname": "23.6.1 RBPF for switching LG-SSMs"}, {"keywordlist": ["look-ahead RBPF", "maneuvering target tracking"], "level": 3, "startpage": 862, "endpage": 863, "topicname": "23.6.2 Application: tracking a maneuvering target"}, {"keywordlist": ["rbpfManeuverDemo", "rbpfSlamDemo"], "level": 3, "startpage": 864, "endpage": 866, "topicname": "23.6.3 Application: Fast SLAM"}, {"keywordlist": ["annealed importance sampling", "Rao-Blackwellisation", "in\ufb01nite mixture models", "adaptive MCMC", "conductance", "parallel tempering", "Simulated annealing", "single site updating", "bond variables", "collapsed Gibbs sampler", "fmGibbs", "sticky", "data-driven MCMC", "symmetric", "randomWalk0o20Demo", "saDemoPeaks", "overdispersed", "trans-dimensional MCMC", "auxiliary variables", "random walk Metropolis algorithm", "Hamiltonian MCMC", "ESS", "Candidate method", "MH", "detailed balance", "blocked Gibbs sampling", "annealing", "EPSR", "random walk proposal", "Metropolis-Hastings algorithm", "critical temperature", "sliceSamplingDemo1d", "Imputation Posterior", "multilevelLinregDemo", "mixing time", "burn-in phase", "blocking Gibbs sampling", "thinning", "IP", "stochastic algorithm", "independence sampler", "autocorrelation function", "sliceSamplingDemo2d", "pilot runs", "accept", "Glauber dynamics", "JAGS", "propose", "stepping out", "Hastings correction", "converge", "burned in", "hybrid MCMC", "multi-level modeling", "partitioning", "logregSatMhDemo", "mcmcGmmDemo", "Rao-Blackwell", "slice sampling", "heat bath", "gibbsGaussDemo", "RJMCMC", "estimated potential scale reduction", "mixture proposal", "frustrated", "eigengap", "exponential cooling schedule", "Metropolis Hastings", "trace plot", "Kolmogorov Smirnov", "Swendsen Wang", "gaussMissingFitGibbs", "leapfrog steps", "cooling schedule", "generate and test"], "level": 1, "startpage": 867, "endpage": 904, "topicname": "24 Markov Chain Monte Carlo (MCMC) Inference"}, {"keywordlist": [], "level": 2, "startpage": 867, "endpage": 867, "topicname": "24.1 Introduction"}, {"keywordlist": ["Rao-Blackwellisation", "in\ufb01nite mixture models", "single site updating", "collapsed Gibbs sampler", "fmGibbs", "Imputation Posterior", "multilevelLinregDemo", "IP", "Glauber dynamics", "JAGS", "burned in", "multi-level modeling", "partitioning", "Rao-Blackwell", "heat bath", "gaussMissingFitGibbs"], "level": 2, "startpage": 868, "endpage": 877, "topicname": "24.2 Gibbs sampling"}, {"keywordlist": ["Glauber dynamics", "burned in", "heat bath"], "level": 3, "startpage": 868, "endpage": 868, "topicname": "24.2.1 Basic idea"}, {"keywordlist": ["Glauber dynamics", "burned in", "heat bath"], "level": 3, "startpage": 868, "endpage": 869, "topicname": "24.2.2 Example: Gibbs sampling for the Ising model"}, {"keywordlist": ["gaussMissingFitGibbs"], "level": 3, "startpage": 870, "endpage": 870, "topicname": "24.2.3 Example: Gibbs sampling for inferring the parameters of a GMM"}, {"keywordlist": ["Rao-Blackwellisation", "in\ufb01nite mixture models", "collapsed Gibbs sampler", "fmGibbs", "partitioning", "Rao-Blackwell"], "level": 3, "startpage": 871, "endpage": 873, "topicname": "24.2.4 Collapsed Gibbs sampling *"}, {"keywordlist": ["multilevelLinregDemo", "multi-level modeling"], "level": 3, "startpage": 874, "endpage": 875, "topicname": "24.2.5 Gibbs sampling for hierarchical GLMs"}, {"keywordlist": [], "level": 3, "startpage": 876, "endpage": 876, "topicname": "24.2.6 BUGS and JAGS"}, {"keywordlist": ["single site updating", "Imputation Posterior", "IP", "JAGS"], "level": 3, "startpage": 877, "endpage": 877, "topicname": "24.2.7 The Imputation Posterior (IP) algorithm"}, {"keywordlist": ["single site updating", "Imputation Posterior", "IP", "JAGS"], "level": 3, "startpage": 877, "endpage": 877, "topicname": "24.2.8 Blocking Gibbs sampling"}, {"keywordlist": ["adaptive MCMC", "sticky", "data-driven MCMC", "symmetric", "trans-dimensional MCMC", "random walk Metropolis algorithm", "MH", "detailed balance", "blocked Gibbs sampling", "annealing", "blocking Gibbs sampling", "independence sampler", "pilot runs", "accept", "propose", "Hastings correction", "logregSatMhDemo", "mcmcGmmDemo", "gibbsGaussDemo", "RJMCMC", "mixture proposal", "Metropolis Hastings", "generate and test"], "level": 2, "startpage": 878, "endpage": 885, "topicname": "24.3 Metropolis Hastings algorithm"}, {"keywordlist": ["random walk Metropolis algorithm", "MH", "blocked Gibbs sampling", "blocking Gibbs sampling", "independence sampler", "accept", "propose", "gibbsGaussDemo", "Metropolis Hastings"], "level": 3, "startpage": 878, "endpage": 878, "topicname": "24.3.1 Basic idea"}, {"keywordlist": ["symmetric", "Hastings correction"], "level": 3, "startpage": 879, "endpage": 879, "topicname": "24.3.2 Gibbs sampling is a special case of MH"}, {"keywordlist": ["sticky", "pilot runs", "logregSatMhDemo", "mcmcGmmDemo"], "level": 3, "startpage": 880, "endpage": 882, "topicname": "24.3.3 Proposal distributions"}, {"keywordlist": ["adaptive MCMC", "data-driven MCMC", "annealing", "mixture proposal", "generate and test"], "level": 3, "startpage": 883, "endpage": 883, "topicname": "24.3.4 Adaptive MCMC"}, {"keywordlist": ["detailed balance"], "level": 3, "startpage": 884, "endpage": 884, "topicname": "24.3.5 Initialization and mode hopping"}, {"keywordlist": ["detailed balance"], "level": 3, "startpage": 884, "endpage": 884, "topicname": "24.3.6 Why MH works *"}, {"keywordlist": ["trans-dimensional MCMC", "RJMCMC"], "level": 3, "startpage": 885, "endpage": 885, "topicname": "24.3.7 Reversible jump (trans-dimensional) MCMC *"}, {"keywordlist": ["conductance", "parallel tempering", "randomWalk0o20Demo", "overdispersed", "ESS", "EPSR", "mixing time", "burn-in phase", "thinning", "autocorrelation function", "converge", "estimated potential scale reduction", "eigengap", "trace plot"], "level": 2, "startpage": 886, "endpage": 892, "topicname": "24.4 Speed and accuracy of MCMC"}, {"keywordlist": ["randomWalk0o20Demo", "burn-in phase"], "level": 3, "startpage": 886, "endpage": 886, "topicname": "24.4.1 The burn-in phase"}, {"keywordlist": ["mixing time", "converge", "eigengap"], "level": 3, "startpage": 887, "endpage": 887, "topicname": "24.4.2 Mixing rates of Markov chains *"}, {"keywordlist": ["conductance", "parallel tempering", "overdispersed", "EPSR", "estimated potential scale reduction", "trace plot"], "level": 3, "startpage": 888, "endpage": 889, "topicname": "24.4.3 Practical convergence diagnostic"}, {"keywordlist": [], "level": 3, "startpage": 890, "endpage": 891, "topicname": "24.4.4 Accuracy of MCMC"}, {"keywordlist": ["ESS", "thinning", "autocorrelation function"], "level": 3, "startpage": 892, "endpage": 892, "topicname": "24.4.5 How many chains?"}, {"keywordlist": ["bond variables", "auxiliary variables", "sliceSamplingDemo1d", "sliceSamplingDemo2d", "stepping out", "slice sampling", "Kolmogorov Smirnov", "Swendsen Wang"], "level": 2, "startpage": 893, "endpage": 897, "topicname": "24.5 Auxiliary variable MCMC *"}, {"keywordlist": ["auxiliary variables"], "level": 3, "startpage": 893, "endpage": 893, "topicname": "24.5.1 Auxiliary variable sampling for logistic regression"}, {"keywordlist": ["sliceSamplingDemo1d", "sliceSamplingDemo2d", "slice sampling", "Kolmogorov Smirnov"], "level": 3, "startpage": 894, "endpage": 895, "topicname": "24.5.2 Slice sampling"}, {"keywordlist": ["bond variables", "stepping out", "Swendsen Wang"], "level": 3, "startpage": 896, "endpage": 897, "topicname": "24.5.3 Swendsen Wang"}, {"keywordlist": ["Hamiltonian MCMC", "critical temperature", "hybrid MCMC", "frustrated", "leapfrog steps"], "level": 3, "startpage": 898, "endpage": 898, "topicname": "24.5.4 Hybrid/Hamiltonian MCMC *"}, {"keywordlist": ["annealed importance sampling", "Simulated annealing", "saDemoPeaks", "Hamiltonian MCMC", "random walk proposal", "Metropolis-Hastings algorithm", "critical temperature", "stochastic algorithm", "hybrid MCMC", "frustrated", "exponential cooling schedule", "leapfrog steps", "cooling schedule"], "level": 2, "startpage": 898, "endpage": 901, "topicname": "24.6 Annealing methods"}, {"keywordlist": ["Simulated annealing", "saDemoPeaks", "random walk proposal", "Metropolis-Hastings algorithm", "stochastic algorithm", "exponential cooling schedule", "cooling schedule"], "level": 3, "startpage": 899, "endpage": 900, "topicname": "24.6.1 Simulated annealing"}, {"keywordlist": ["annealed importance sampling"], "level": 3, "startpage": 901, "endpage": 901, "topicname": "24.6.2 Annealed importance sampling"}, {"keywordlist": ["annealed importance sampling"], "level": 3, "startpage": 901, "endpage": 901, "topicname": "24.6.3 Parallel tempering"}, {"keywordlist": ["Candidate method"], "level": 2, "startpage": 902, "endpage": 904, "topicname": "24.7 Approximating the marginal likelihood"}, {"keywordlist": ["Candidate method"], "level": 3, "startpage": 902, "endpage": 902, "topicname": "24.7.1 The candidate method"}, {"keywordlist": ["Candidate method"], "level": 3, "startpage": 902, "endpage": 902, "topicname": "24.7.2 Harmonic mean estimate"}, {"keywordlist": [], "level": 3, "startpage": 903, "endpage": 904, "topicname": "24.7.3 Annealed importance sampling"}, {"keywordlist": ["graph Laplacian", "complete link clustering", "compactness", "leaves", "nearest neighbor clustering", "perturbation theory", "Dirchlet process", "Clustering", "divisive clustering", "feature-based clustering", "normalized mutual information", "Blackwell-MacQueen", "multi-clust", "biclustering", "K-centers", "bisecting K-means", "purity", "Index to keywords A star search", "random probability measure", "Bayesian hierarchical clustering", "feature matrix", "non-parametric prior", "base measure", "agglomerative clustering", "categorical variables", "Pitman-Yor process", "Index to code agglomDemo", "neutral process", "hclustYeastDemo", "similarity-based clustering", "in\ufb01nite relational model", "CRP", "partitional clustering", "\ufb02at clustering", "furthest neighbor clustering", "dissimilarity analysis", "distance matrix", "concentration parameter", "Chinese restaurant process", "discrete with probability one", "average link clustering", "dissimilarity matrix", "normalized cut", "graph cuts", "adjusted Rand index", "dpmSampleDemo", "stickBreakingDemo", "model-based approach, xxvii model-based clustering", "dendrogram", "binary tree", "hamming distance", "hierarchical clustering", "partitions of the integers", "\ufb01nite mixture model", "spectral clustering", "variation of information", "crosscat", "city block distance", "dpmGauss2dDemo", "single link clustering", "ordinal variables", "minimum spanning tree", "spectralClusteringDemo", "non-parametric Bayes", "spectral graph theory", "Rand index", "coclustering", "affinity propagation", "stick-breaking construction", "views"], "level": 1, "startpage": 905, "endpage": 936, "topicname": "25 Clustering"}, {"keywordlist": ["Clustering", "feature-based clustering", "purity", "feature matrix", "categorical variables", "similarity-based clustering", "partitional clustering", "\ufb02at clustering", "distance matrix", "dissimilarity matrix", "adjusted Rand index", "hamming distance", "hierarchical clustering", "city block distance", "ordinal variables", "Rand index"], "level": 2, "startpage": 905, "endpage": 908, "topicname": "25.1 Introduction"}, {"keywordlist": ["Clustering", "feature-based clustering", "feature matrix", "similarity-based clustering", "partitional clustering", "\ufb02at clustering", "distance matrix", "dissimilarity matrix", "hierarchical clustering"], "level": 3, "startpage": 905, "endpage": 905, "topicname": "25.1.1 Measuring (dis)similarity"}, {"keywordlist": ["purity", "categorical variables", "adjusted Rand index", "hamming distance", "city block distance", "ordinal variables", "Rand index"], "level": 3, "startpage": 906, "endpage": 908, "topicname": "25.1.2 Evaluating the output of clustering methods *"}, {"keywordlist": ["normalized mutual information", "Blackwell-MacQueen", "random probability measure", "non-parametric prior", "base measure", "Pitman-Yor process", "neutral process", "CRP", "concentration parameter", "Chinese restaurant process", "discrete with probability one", "dpmSampleDemo", "stickBreakingDemo", "model-based approach, xxvii model-based clustering", "partitions of the integers", "\ufb01nite mixture model", "variation of information", "non-parametric Bayes", "stick-breaking construction"], "level": 2, "startpage": 909, "endpage": 916, "topicname": "25.2 Dirichlet process mixture models"}, {"keywordlist": ["normalized mutual information", "random probability measure", "non-parametric prior", "dpmSampleDemo", "model-based approach, xxvii model-based clustering", "\ufb01nite mixture model", "variation of information", "non-parametric Bayes"], "level": 3, "startpage": 909, "endpage": 911, "topicname": "25.2.1 From finite to infinite mixture models"}, {"keywordlist": ["Blackwell-MacQueen", "base measure", "neutral process", "CRP", "concentration parameter", "Chinese restaurant process", "discrete with probability one", "stickBreakingDemo", "stick-breaking construction"], "level": 3, "startpage": 912, "endpage": 914, "topicname": "25.2.2 The Dirichlet process"}, {"keywordlist": ["Pitman-Yor process", "partitions of the integers"], "level": 3, "startpage": 915, "endpage": 915, "topicname": "25.2.3 Applying Dirichlet processes to mixture modeling"}, {"keywordlist": [], "level": 3, "startpage": 916, "endpage": 916, "topicname": "25.2.4 Fitting a DP mixture model"}, {"keywordlist": ["K-centers", "Index to keywords A star search", "dpmGauss2dDemo", "affinity propagation"], "level": 2, "startpage": 917, "endpage": 919, "topicname": "25.3 Affinity propagation"}, {"keywordlist": ["graph Laplacian", "perturbation theory", "normalized cut", "graph cuts", "spectral clustering", "spectral graph theory"], "level": 2, "startpage": 920, "endpage": 922, "topicname": "25.4 Spectral clustering"}, {"keywordlist": ["graph Laplacian", "normalized cut", "spectral clustering", "spectral graph theory"], "level": 3, "startpage": 921, "endpage": 921, "topicname": "25.4.1 Graph Laplacian"}, {"keywordlist": ["perturbation theory"], "level": 3, "startpage": 922, "endpage": 922, "topicname": "25.4.2 Normalized graph Laplacian"}, {"keywordlist": ["divisive clustering", "agglomerative clustering", "spectralClusteringDemo"], "level": 3, "startpage": 923, "endpage": 923, "topicname": "25.4.3 Example"}, {"keywordlist": ["complete link clustering", "compactness", "leaves", "nearest neighbor clustering", "divisive clustering", "bisecting K-means", "Bayesian hierarchical clustering", "agglomerative clustering", "Index to code agglomDemo", "hclustYeastDemo", "furthest neighbor clustering", "dissimilarity analysis", "average link clustering", "dendrogram", "binary tree", "single link clustering", "minimum spanning tree", "spectralClusteringDemo"], "level": 2, "startpage": 923, "endpage": 930, "topicname": "25.5 Hierarchical clustering"}, {"keywordlist": ["complete link clustering", "compactness", "leaves", "nearest neighbor clustering", "furthest neighbor clustering", "average link clustering", "dendrogram", "binary tree", "single link clustering", "minimum spanning tree"], "level": 3, "startpage": 925, "endpage": 927, "topicname": "25.5.1 Agglomerative clustering"}, {"keywordlist": ["bisecting K-means", "dissimilarity analysis"], "level": 3, "startpage": 928, "endpage": 928, "topicname": "25.5.2 Divisive clustering"}, {"keywordlist": ["Bayesian hierarchical clustering"], "level": 3, "startpage": 929, "endpage": 929, "topicname": "25.5.3 Choosing the number of clusters"}, {"keywordlist": ["Bayesian hierarchical clustering"], "level": 3, "startpage": 929, "endpage": 930, "topicname": "25.5.4 Bayesian hierarchical clustering"}, {"keywordlist": ["Dirchlet process", "multi-clust", "biclustering", "in\ufb01nite relational model", "crosscat", "coclustering", "views"], "level": 2, "startpage": 931, "endpage": 936, "topicname": "25.6 Clustering datapoints and features"}, {"keywordlist": ["Dirchlet process", "biclustering", "in\ufb01nite relational model", "coclustering"], "level": 3, "startpage": 933, "endpage": 933, "topicname": "25.6.1 Biclustering"}, {"keywordlist": ["Dirchlet process", "multi-clust", "biclustering", "in\ufb01nite relational model", "crosscat", "coclustering", "views"], "level": 3, "startpage": 933, "endpage": 936, "topicname": "25.6.2 Multi-view clustering"}, {"keywordlist": ["Markov equivalence", "depnetFit", "conditional Gaussian", "ggmFitDemo", "associative", "thin junction trees", "relevanceNetworkNewsgroupDemo", "NP-complete", "maximum weight spanning tree", "do calculus", "chowliuTreeDemo", "partially directed acyclic graph", "constraint-based approach", "essential graph", "Prim\u2019s algorithm", "simpsonsParadoxGraph", "nonparanormal", "structural equation model", "adjust for", "confounding variable", "faithful", "ggmFitMinfunc", "Causal models", "interventional data", "phylogenetic tree", "hierarchical latent class model", "Simpon\u2019s paradox", "context-speci\ufb01c independence", "likelihood equivalence", "causal Markov assumption", "graph surgery", "Kruskal\u2019s algorithm", "fat hand", "relevance network", "AdSense", "structural EM", "deep", "perfect intervention", "AdWords", "Bayesian network structure learning", "Cheeseman-Stutz approximation", "mixture of trees", "recursive", "covariance selection", "PDAG", "confounders", "global prior parameter independence", "mixed directed graphs", "agglomerative hierarchical clustering", "maximal branching", "causality", "path diagrams", "BDeu", "LISREL", "Markov equivalent", "backdoor path", "feedback loops", "matrix tree theorem", "manifest", "compelled edges", "dependency network", "Gaussian copulas", "complete data assumption", "hill climbing", "interventions", "pseudo-likelihood", "gene knockout experiment", "stable", "local prior parameter independence", "circuit complexity", "K2 algorithm", "Gaussian random \ufb01elds", "directed mixed graph", "permanent", "ggmFitHtf", "graphical lasso", "parameter modularity", "equivalence class", "causal sufficiency", "pattern", "determinism", "structural signatures", "Glasso", "greedy equivalence search", "ggmLassoHtf", "augmented DAG", "latent class model", "BDe", "IDA", "\ufb02ow cytometry", "Rephil"], "level": 1, "startpage": 937, "endpage": 974, "topicname": "26 Graphical Model Structure Learning"}, {"keywordlist": [], "level": 2, "startpage": 937, "endpage": 937, "topicname": "26.1 Introduction"}, {"keywordlist": ["depnetFit", "relevanceNetworkNewsgroupDemo", "relevance network", "dependency network"], "level": 2, "startpage": 938, "endpage": 939, "topicname": "26.2 Structure learning for knowledge discovery"}, {"keywordlist": ["relevanceNetworkNewsgroupDemo", "relevance network"], "level": 3, "startpage": 938, "endpage": 938, "topicname": "26.2.1 Relevance networks"}, {"keywordlist": ["depnetFit", "dependency network"], "level": 3, "startpage": 939, "endpage": 939, "topicname": "26.2.2 Dependency networks"}, {"keywordlist": ["maximum weight spanning tree", "chowliuTreeDemo", "Prim\u2019s algorithm", "Kruskal\u2019s algorithm", "maximal branching"], "level": 2, "startpage": 940, "endpage": 943, "topicname": "26.3 Learning tree structures"}, {"keywordlist": [], "level": 3, "startpage": 941, "endpage": 941, "topicname": "26.3.1 Directed or undirected tree?"}, {"keywordlist": ["maximum weight spanning tree", "Prim\u2019s algorithm", "Kruskal\u2019s algorithm"], "level": 3, "startpage": 942, "endpage": 942, "topicname": "26.3.2 Chow-Liu algorithm for finding the ML tree structure"}, {"keywordlist": ["maximum weight spanning tree", "chowliuTreeDemo", "Prim\u2019s algorithm", "Kruskal\u2019s algorithm", "maximal branching"], "level": 3, "startpage": 942, "endpage": 943, "topicname": "26.3.3 Finding the MAP forest"}, {"keywordlist": ["Bayesian network structure learning", "mixture of trees", "matrix tree theorem", "complete data assumption"], "level": 3, "startpage": 944, "endpage": 944, "topicname": "26.3.4 Mixtures of trees"}, {"keywordlist": ["conditional Gaussian", "NP-complete", "partially directed acyclic graph", "essential graph", "likelihood equivalence", "Bayesian network structure learning", "mixture of trees", "global prior parameter independence", "causality", "BDeu", "Markov equivalent", "matrix tree theorem", "compelled edges", "complete data assumption", "hill climbing", "local prior parameter independence", "K2 algorithm", "parameter modularity", "equivalence class", "pattern", "BDe"], "level": 2, "startpage": 944, "endpage": 951, "topicname": "26.4 Learning DAG structures"}, {"keywordlist": ["partially directed acyclic graph", "essential graph", "Bayesian network structure learning", "mixture of trees", "Markov equivalent", "matrix tree theorem", "compelled edges", "complete data assumption", "equivalence class", "pattern"], "level": 3, "startpage": 944, "endpage": 945, "topicname": "26.4.1 Markov equivalence"}, {"keywordlist": ["likelihood equivalence", "global prior parameter independence", "causality", "BDeu", "local prior parameter independence", "parameter modularity", "BDe"], "level": 3, "startpage": 946, "endpage": 949, "topicname": "26.4.2 Exact structural inference"}, {"keywordlist": ["conditional Gaussian", "NP-complete", "hill climbing", "K2 algorithm"], "level": 3, "startpage": 950, "endpage": 951, "topicname": "26.4.3 Scaling up to larger graphs"}, {"keywordlist": ["constraint-based approach", "structural equation model", "phylogenetic tree", "hierarchical latent class model", "AdSense", "structural EM", "deep", "AdWords", "Cheeseman-Stutz approximation", "recursive", "agglomerative hierarchical clustering", "path diagrams", "LISREL", "feedback loops", "manifest", "directed mixed graph", "structural signatures", "latent class model", "Rephil"], "level": 2, "startpage": 952, "endpage": 960, "topicname": "26.5 Learning DAG structure with latent variables"}, {"keywordlist": ["constraint-based approach", "Cheeseman-Stutz approximation"], "level": 3, "startpage": 952, "endpage": 954, "topicname": "26.5.1 Approximating the marginal likelihood when we have missing data"}, {"keywordlist": ["phylogenetic tree", "structural EM"], "level": 3, "startpage": 955, "endpage": 955, "topicname": "26.5.2 Structural EM"}, {"keywordlist": ["hierarchical latent class model", "agglomerative hierarchical clustering", "structural signatures", "latent class model"], "level": 3, "startpage": 956, "endpage": 957, "topicname": "26.5.3 Discovering hidden variables"}, {"keywordlist": ["AdSense", "AdWords", "Rephil"], "level": 3, "startpage": 958, "endpage": 958, "topicname": "26.5.4 Case study: Google\u2019s Rephil"}, {"keywordlist": ["structural equation model", "deep", "recursive", "path diagrams", "LISREL", "feedback loops", "manifest", "directed mixed graph"], "level": 3, "startpage": 959, "endpage": 960, "topicname": "26.5.5 Structural equation models *"}, {"keywordlist": ["Markov equivalence", "associative", "do calculus", "simpsonsParadoxGraph", "adjust for", "confounding variable", "faithful", "Causal models", "interventional data", "Simpon\u2019s paradox", "causal Markov assumption", "graph surgery", "fat hand", "perfect intervention", "PDAG", "confounders", "mixed directed graphs", "backdoor path", "interventions", "gene knockout experiment", "stable", "causal sufficiency", "greedy equivalence search", "augmented DAG", "IDA", "\ufb02ow cytometry"], "level": 2, "startpage": 961, "endpage": 967, "topicname": "26.6 Learning causal DAGs"}, {"keywordlist": ["associative", "do calculus", "Causal models", "causal Markov assumption", "graph surgery", "perfect intervention", "confounders", "mixed directed graphs", "interventions", "gene knockout experiment", "causal sufficiency", "augmented DAG"], "level": 3, "startpage": 961, "endpage": 962, "topicname": "26.6.1 Causal interpretation of DAGs"}, {"keywordlist": ["simpsonsParadoxGraph", "adjust for", "confounding variable", "Simpon\u2019s paradox", "fat hand", "backdoor path"], "level": 3, "startpage": 963, "endpage": 964, "topicname": "26.6.2 Using causal DAGs to resolve Simpson\u2019s paradox"}, {"keywordlist": ["Markov equivalence", "faithful", "interventional data", "PDAG", "stable", "greedy equivalence search", "IDA", "\ufb02ow cytometry"], "level": 3, "startpage": 965, "endpage": 967, "topicname": "26.6.3 Learning causal DAG structures"}, {"keywordlist": ["ggmFitDemo", "ggmFitMinfunc", "covariance selection", "Gaussian random \ufb01elds", "ggmFitHtf", "graphical lasso", "Glasso", "ggmLassoHtf"], "level": 2, "startpage": 968, "endpage": 971, "topicname": "26.7 Learning undirected Gaussian graphical models"}, {"keywordlist": ["covariance selection", "Gaussian random \ufb01elds"], "level": 3, "startpage": 968, "endpage": 968, "topicname": "26.7.1 MLE for a GGM"}, {"keywordlist": ["ggmFitDemo", "ggmFitMinfunc", "ggmFitHtf", "graphical lasso", "Glasso", "ggmLassoHtf"], "level": 3, "startpage": 969, "endpage": 970, "topicname": "26.7.2 Graphical lasso"}, {"keywordlist": [], "level": 3, "startpage": 971, "endpage": 971, "topicname": "26.7.3 Bayesian inference for GGM structure *"}, {"keywordlist": ["nonparanormal", "Gaussian copulas", "permanent"], "level": 3, "startpage": 972, "endpage": 972, "topicname": "26.7.4 Handling non-Gaussian data using copulas *"}, {"keywordlist": ["thin junction trees", "nonparanormal", "context-speci\ufb01c independence", "Gaussian copulas", "pseudo-likelihood", "circuit complexity", "permanent", "determinism"], "level": 2, "startpage": 972, "endpage": 974, "topicname": "26.8 Learning undirected discrete graphical models"}, {"keywordlist": ["nonparanormal", "Gaussian copulas", "pseudo-likelihood", "permanent"], "level": 3, "startpage": 972, "endpage": 973, "topicname": "26.8.1 Graphical lasso for MRFs/CRFs"}, {"keywordlist": ["thin junction trees", "context-speci\ufb01c independence", "circuit complexity", "determinism"], "level": 3, "startpage": 974, "endpage": 974, "topicname": "26.8.2 Thin junction trees"}, {"keywordlist": ["LSI", "Dirichlet multinomial regression LDA", "ontological uncertainty", "harmonium", "root mean square error", "grandmother cells", "in\ufb01nite hidden relational model", "net\ufb02ixResultsPlot", "fuzzy clustering", "matrix factorization", "corpus", "supervised LDA", "tokens", "LSA", "mPCA", "bottleneck layer", "distributed encoding", "CD", "GaP", "discriminative LDA", "relational topic model", "multinomial PCA", "product of experts", "branching factor", "TASA", "mixed membership model", "perplexity", "polysemy", "Facebook", "topic", "exponential family harmonium", "bleiLDAperplexityPlot", "multinomial regression LDA", "impression log", "replicated softmax model", "image tagging", "gist", "protein-protein interaction networks", "IRM", "conditional Gamma Poisson", "probabilistic latent semantic indexing", "admixture mixture", "latent Dirichlet allocation", "simplex factor model", "ontology", "random effects mixture of experts", "unigrams", "Gaussian RBM", "ensemble", "side information", "monks", "EP", "auto-encoders", "RBM", "relation", "Uni\ufb01ed Medical Language System", "clamped phase", "collapsed Gibbs sampling", "implicit feedback", "dynamic topic model", "localist encoding", "semantic network", "LDA-HMM", "restricted Boltzmann machine", "persistent CD", "exponential family PCA", "fantasy data", "user rating pro\ufb01le", "stochastic process", "sentiment analysis", "mixed membership stochastic block model", "partially labeled LDA", "conditional topic random \ufb01eld", "statistical relational learning", "epistemological uncertainty", "tuples", "disease transmission", "social networks", "annealing importance sampling", "multi label classi\ufb01cation", "unclamped phase", "co-clustering", "labeled LDA", "dyadic", "cross-language information retrieval", "free energy", "ePCA", "Microsoft", "stochastic block model", "PLSI"], "level": 1, "startpage": 975, "endpage": 1024, "topicname": "27 Latent Variable Models for Discrete Data"}, {"keywordlist": ["tokens"], "level": 2, "startpage": 975, "endpage": 975, "topicname": "27.1 Introduction"}, {"keywordlist": ["LSI", "matrix factorization", "LSA", "mPCA", "GaP", "multinomial PCA", "topic", "conditional Gamma Poisson", "probabilistic latent semantic indexing", "latent Dirichlet allocation", "simplex factor model", "exponential family PCA", "user rating pro\ufb01le", "ePCA", "PLSI"], "level": 2, "startpage": 976, "endpage": 979, "topicname": "27.2 Distributed state LVMs for discrete data"}, {"keywordlist": ["topic"], "level": 3, "startpage": 976, "endpage": 976, "topicname": "27.2.1 Mixture models"}, {"keywordlist": ["LSI", "LSA", "exponential family PCA", "ePCA"], "level": 3, "startpage": 977, "endpage": 977, "topicname": "27.2.2 Exponential family PCA"}, {"keywordlist": ["matrix factorization", "mPCA", "multinomial PCA"], "level": 3, "startpage": 978, "endpage": 978, "topicname": "27.2.3 LDA and mPCA"}, {"keywordlist": ["GaP", "conditional Gamma Poisson", "probabilistic latent semantic indexing", "latent Dirichlet allocation", "simplex factor model", "user rating pro\ufb01le", "PLSI"], "level": 3, "startpage": 979, "endpage": 979, "topicname": "27.2.4 GaP model and non-negative matrix factorization"}, {"keywordlist": ["corpus", "branching factor", "TASA", "mixed membership model", "perplexity", "polysemy", "bleiLDAperplexityPlot", "admixture mixture", "unigrams", "collapsed Gibbs sampling", "stochastic process", "labeled LDA"], "level": 2, "startpage": 980, "endpage": 990, "topicname": "27.3 Latent Dirichlet allocation (LDA)"}, {"keywordlist": ["TASA", "mixed membership model", "polysemy", "admixture mixture"], "level": 3, "startpage": 980, "endpage": 982, "topicname": "27.3.1 Basics"}, {"keywordlist": ["corpus", "perplexity", "unigrams", "stochastic process", "labeled LDA"], "level": 3, "startpage": 983, "endpage": 983, "topicname": "27.3.2 Unsupervised discovery of topics"}, {"keywordlist": ["corpus", "branching factor", "perplexity", "unigrams", "stochastic process", "labeled LDA"], "level": 3, "startpage": 983, "endpage": 984, "topicname": "27.3.3 Quantitatively evaluating LDA as a language model"}, {"keywordlist": ["bleiLDAperplexityPlot"], "level": 3, "startpage": 985, "endpage": 985, "topicname": "27.3.4 Fitting using (collapsed) Gibbs sampling"}, {"keywordlist": ["collapsed Gibbs sampling"], "level": 3, "startpage": 986, "endpage": 986, "topicname": "27.3.5 Example"}, {"keywordlist": [], "level": 3, "startpage": 987, "endpage": 988, "topicname": "27.3.6 Fitting using batch variational inference"}, {"keywordlist": [], "level": 3, "startpage": 989, "endpage": 989, "topicname": "27.3.7 Fitting using online variational inference"}, {"keywordlist": [], "level": 3, "startpage": 990, "endpage": 990, "topicname": "27.3.8 Determining the number of topics"}, {"keywordlist": ["Dirichlet multinomial regression LDA", "supervised LDA", "discriminative LDA", "multinomial regression LDA", "image tagging", "gist", "random effects mixture of experts", "dynamic topic model", "LDA-HMM", "sentiment analysis", "partially labeled LDA", "conditional topic random \ufb01eld", "cross-language information retrieval"], "level": 2, "startpage": 991, "endpage": 999, "topicname": "27.4 Extensions of LDA"}, {"keywordlist": [], "level": 3, "startpage": 991, "endpage": 991, "topicname": "27.4.1 Correlated topic model"}, {"keywordlist": ["dynamic topic model"], "level": 3, "startpage": 992, "endpage": 992, "topicname": "27.4.2 Dynamic topic model"}, {"keywordlist": ["gist", "LDA-HMM", "cross-language information retrieval"], "level": 3, "startpage": 993, "endpage": 996, "topicname": "27.4.3 LDA-HMM"}, {"keywordlist": ["Dirichlet multinomial regression LDA", "supervised LDA", "discriminative LDA", "multinomial regression LDA", "image tagging", "random effects mixture of experts", "sentiment analysis", "partially labeled LDA", "conditional topic random \ufb01eld"], "level": 3, "startpage": 997, "endpage": 999, "topicname": "27.4.4 Supervised LDA"}, {"keywordlist": ["ontological uncertainty", "fuzzy clustering", "bottleneck layer", "relational topic model", "Facebook", "protein-protein interaction networks", "monks", "mixed membership stochastic block model", "epistemological uncertainty", "disease transmission", "social networks", "multi label classi\ufb01cation", "stochastic block model"], "level": 2, "startpage": 1000, "endpage": 1004, "topicname": "27.5 LVMs for graph-structured data"}, {"keywordlist": ["stochastic block model"], "level": 3, "startpage": 1001, "endpage": 1002, "topicname": "27.5.1 Stochastic block model"}, {"keywordlist": ["ontological uncertainty", "fuzzy clustering", "mixed membership stochastic block model", "epistemological uncertainty"], "level": 3, "startpage": 1003, "endpage": 1003, "topicname": "27.5.2 Mixed membership stochastic block model"}, {"keywordlist": ["relational topic model", "Facebook", "monks"], "level": 3, "startpage": 1004, "endpage": 1004, "topicname": "27.5.3 Relational topic model"}, {"keywordlist": ["root mean square error", "in\ufb01nite hidden relational model", "net\ufb02ixResultsPlot", "IRM", "ontology", "ensemble", "side information", "relation", "Uni\ufb01ed Medical Language System", "semantic network", "statistical relational learning", "tuples", "co-clustering", "dyadic"], "level": 2, "startpage": 1005, "endpage": 1012, "topicname": "27.6 LVMs for relational data"}, {"keywordlist": ["in\ufb01nite hidden relational model", "IRM", "ontology", "Uni\ufb01ed Medical Language System", "semantic network", "statistical relational learning", "dyadic"], "level": 3, "startpage": 1006, "endpage": 1008, "topicname": "27.6.1 Infinite relational model"}, {"keywordlist": ["root mean square error", "net\ufb02ixResultsPlot", "ensemble", "side information", "co-clustering"], "level": 3, "startpage": 1009, "endpage": 1012, "topicname": "27.6.2 Probabilistic matrix factorization for collaborative filtering"}, {"keywordlist": ["harmonium", "grandmother cells", "distributed encoding", "CD", "product of experts", "exponential family harmonium", "impression log", "replicated softmax model", "Gaussian RBM", "EP", "auto-encoders", "RBM", "clamped phase", "implicit feedback", "localist encoding", "restricted Boltzmann machine", "persistent CD", "fantasy data", "annealing importance sampling", "unclamped phase", "free energy", "Microsoft"], "level": 2, "startpage": 1013, "endpage": 1024, "topicname": "27.7 Restricted Boltzmann machines (RBMs)"}, {"keywordlist": ["exponential family harmonium", "Gaussian RBM"], "level": 3, "startpage": 1015, "endpage": 1016, "topicname": "27.7.1 Varieties of RBMs"}, {"keywordlist": ["CD", "auto-encoders", "clamped phase", "fantasy data", "unclamped phase", "free energy"], "level": 3, "startpage": 1017, "endpage": 1020, "topicname": "27.7.2 Learning RBMs"}, {"keywordlist": ["replicated softmax model", "persistent CD", "annealing importance sampling"], "level": 3, "startpage": 1021, "endpage": 1024, "topicname": "27.7.3 Applications of RBMs"}, {"keywordlist": ["deep Boltzmann machine", "DBM", "and-or graphs", "inverted indices", "score matching", "MFCC", "convolutional neural nets", "complementary prior", "phonemes", "invariant features", "auto-encoder", "up-down", "deep directed networks", "visual words", "convolutional DBNs", "stacked denoising auto-encoder", "DeeBNs", "back-propagation", "max pooling", "generative pre-training", "principal components", "denoising auto-encoder", "semantic hashing", "deep auto-encoders", "DyBNs", "AI", "symbol grounding", "signal-to-symbol", "vanishing gradient", "standard model", "deep belief network", "GPUs"], "level": 1, "startpage": 1025, "endpage": 1038, "topicname": "28 Deep Learning"}, {"keywordlist": ["standard model"], "level": 2, "startpage": 1025, "endpage": 1025, "topicname": "28.1 Introduction"}, {"keywordlist": ["deep Boltzmann machine", "DBM", "complementary prior", "up-down", "deep directed networks", "DeeBNs", "DyBNs", "standard model", "deep belief network"], "level": 2, "startpage": 1025, "endpage": 1028, "topicname": "28.2 Deep generative models"}, {"keywordlist": ["deep Boltzmann machine", "DBM", "deep directed networks"], "level": 3, "startpage": 1026, "endpage": 1026, "topicname": "28.2.1 Deep directed networks"}, {"keywordlist": ["deep Boltzmann machine", "DBM", "deep directed networks"], "level": 3, "startpage": 1026, "endpage": 1026, "topicname": "28.2.2 Deep Boltzmann machines"}, {"keywordlist": ["complementary prior", "DeeBNs", "DyBNs", "deep belief network"], "level": 3, "startpage": 1027, "endpage": 1027, "topicname": "28.2.3 Deep belief networks"}, {"keywordlist": ["up-down"], "level": 3, "startpage": 1028, "endpage": 1028, "topicname": "28.2.4 Greedy layer-wise learning of DBNs"}, {"keywordlist": ["auto-encoder", "back-propagation", "generative pre-training", "principal components", "deep auto-encoders", "vanishing gradient"], "level": 2, "startpage": 1029, "endpage": 1030, "topicname": "28.3 Deep neural networks"}, {"keywordlist": ["back-propagation", "generative pre-training", "vanishing gradient"], "level": 3, "startpage": 1029, "endpage": 1029, "topicname": "28.3.1 Deep multi-layer perceptrons"}, {"keywordlist": ["auto-encoder", "principal components", "deep auto-encoders"], "level": 3, "startpage": 1030, "endpage": 1030, "topicname": "28.3.2 Deep auto-encoders"}, {"keywordlist": ["score matching", "stacked denoising auto-encoder", "denoising auto-encoder"], "level": 3, "startpage": 1031, "endpage": 1031, "topicname": "28.3.3 Stacked denoising auto-encoders"}, {"keywordlist": ["inverted indices", "score matching", "convolutional neural nets", "invariant features", "convolutional DBNs", "stacked denoising auto-encoder", "denoising auto-encoder", "semantic hashing"], "level": 2, "startpage": 1031, "endpage": 1034, "topicname": "28.4 Applications of deep networks"}, {"keywordlist": ["score matching", "stacked denoising auto-encoder", "denoising auto-encoder"], "level": 3, "startpage": 1031, "endpage": 1031, "topicname": "28.4.1 Handwritten digit classification using DBNs"}, {"keywordlist": [], "level": 3, "startpage": 1032, "endpage": 1032, "topicname": "28.4.2 Data visualization and feature discovery using deep auto-encoders"}, {"keywordlist": ["semantic hashing"], "level": 3, "startpage": 1033, "endpage": 1033, "topicname": "28.4.3 Information retrieval using deep auto-encoders (semantic hashing)"}, {"keywordlist": ["inverted indices", "convolutional neural nets", "invariant features", "convolutional DBNs"], "level": 3, "startpage": 1034, "endpage": 1034, "topicname": "28.4.4 Learning audio features using 1d convolutional DBNs"}, {"keywordlist": ["MFCC", "phonemes", "max pooling"], "level": 3, "startpage": 1035, "endpage": 1035, "topicname": "28.4.5 Learning image features using 2d convolutional DBNs"}, {"keywordlist": ["and-or graphs", "MFCC", "phonemes", "visual words", "max pooling", "AI", "symbol grounding", "signal-to-symbol", "GPUs"], "level": 2, "startpage": 1035, "endpage": 1038, "topicname": "28.5 Discussion"}, {"keywordlist": [], "level": 1, "startpage": 1039, "endpage": 1044, "topicname": "Notation"}, {"keywordlist": [], "level": 1, "startpage": 1045, "endpage": 1076, "topicname": "Bibliography"}, {"keywordlist": [], "level": 1, "startpage": 1077, "endpage": 1079, "topicname": "Index to Code"}, {"keywordlist": [], "level": 1, "startpage": 1080, "endpage": 1097, "topicname": "Index to Keywords"}]